{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN News Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords # remove stopword\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Vectorization classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "        \"\"\"\n",
    "\n",
    "        # news_vocab._token_to_idx: {'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'jobs': 4, 'tax': 5, 'cuts': 6,  \n",
    "        #                             ......, 'shiite': 3407, 'ghraib': 3408}\n",
    "        # category_vocab._token_to_idx: {'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}\n",
    "        \n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token             # for paddding, e.g., Wall St. Bears Claw Back Into the Black (Reuters)\n",
    "                                                  #               -> [2, 5, 6, 10, 10, 8, 7, 9, 19, ......., 3, 0, 0, 0, ..., 0]\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)            # mask_index is 0\n",
    "        self.unk_index = self.add_token(self._unk_token)              # unk_index is 1\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)  # begin_seq_index is 2\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)      # end_seq_index is 3\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
    "    def __init__(self, news_vocab, category_vocab):\n",
    "        self.news_vocab = news_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "\n",
    "    def vectorize(self, text, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text (str): the string of words separated by a space\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        Returns:\n",
    "            the vetorized text (numpy.array)\n",
    "        \"\"\"\n",
    "        \"\"\"    \n",
    "        mask_index is 0\n",
    "        unk_index is 1\n",
    "        begin_seq_index is 2\n",
    "        end_seq_index is 3\n",
    "        \n",
    "        When text is \"Wall St. Bears Claw Back Into the Black (Reuters)\"; max vector length is 29 in current dataset \n",
    "        \n",
    "        out_vector = [2, 5, 6, 10, 10, 8, 7, 9, 19, ......., 3, 0, 0, 0, ..., 0]\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        indices = [self.news_vocab.begin_seq_index]\n",
    "        indices.extend(self.news_vocab.lookup_token(token) \n",
    "                       for token in text.split(\" \"))\n",
    "        indices.append(self.news_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.news_vocab.mask_index\n",
    "\n",
    "        return out_vector\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, news_df, cutoff=25):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            news_df (pandas.DataFrame): the target dataset\n",
    "            cutoff (int): frequency threshold for including in Vocabulary \n",
    "        Returns:\n",
    "            an instance of the NewsVectorizer\n",
    "        \"\"\"\n",
    "        category_vocab = Vocabulary()        \n",
    "        for category in sorted(set(news_df.category)):\n",
    "            category_vocab.add_token(category)\n",
    "\n",
    "        word_counts = Counter()\n",
    "        for text in news_df.text:\n",
    "            for token in text.split(\" \"):\n",
    "                if token not in string.punctuation:\n",
    "                    word_counts[token] += 1\n",
    "        \n",
    "        news_vocab = SequenceVocabulary()\n",
    "        for word, word_count in word_counts.items():\n",
    "            if word_count >= cutoff:\n",
    "                news_vocab.add_token(word)\n",
    "        \n",
    "        return cls(news_vocab, category_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glaxo settle paxil suicide pill suit new york reuters glaxosmithkline plc href target stock quickinfo fullquote l agreed release clinical study drug settle lawsuit accused withholding negative information antidepressant paxil new york attorney general office said thursday'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_preprocessing(text):\n",
    "    text = text.lower() # case folding\n",
    "    text = re.sub('&\\w*\\;\\w*', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub(r\"[^a-z]+\", r\" \", text) # Regulation, remove special charecters\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    # remove stopwords and lemmatization\n",
    "    result = [lemmatizer.lemmatize(i) for i in tokens if not i in stop_words]\n",
    "    result = result[:1000]\n",
    "    '''\n",
    "    # bigram\n",
    "    bigram_result = []\n",
    "    bigram_list = ngrams(result,2)\n",
    "    for word_set in bigram_list:\n",
    "        for word in word_set:\n",
    "            bigram_result.append(word)\n",
    "    '''\n",
    "    return result\n",
    "\n",
    "test_str_1 = \"This is sentence to test the effect of preprocessing... Yeah~\\nCool!fac  feae ge fe ga ðŸª£ðŸ›€ðŸŽ€ â˜â˜¢ï¸Žâ¥â˜âŽ (>â•¹Ï‰â•¹<)å–µ\"\n",
    "test_str_2 = \"Glaxo Settles Paxil 'Suicide Pill' Suit.  NEW YORK (Reuters) - GlaxoSmithKline Plc &lt;A HREF=http://www.investor.reuters.com/FullQuote.aspx?ticker=GSK.L target=/stocks/quickinfo/fullquote\"\"&gt;GSK.L&lt;/A&gt; has agreed  to release all clinical studies of its drugs to settle a  lawsuit that accused it of withholding negative information  about the antidepressant Paxil, the New York Attorney General's  office said on Thursday.\"\n",
    "list = text_preprocessing(test_str_2)\n",
    "' '.join(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, news_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            news_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (NewsVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.news_df = news_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        # +1 if only using begin_seq, +2 if using both begin and end seq tokens\n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, news_df.text)) + 2\n",
    "        \n",
    "\n",
    "        self.train_df = self.news_df[self.news_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.news_df[self.news_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.news_df[self.news_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "        # Class weights\n",
    "        class_counts = news_df.category.value_counts().to_dict()\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.category_vocab.lookup_token(item[0])\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, news_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            surname_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of SurnameDataset\n",
    "        \"\"\"\n",
    "        news_df = pd.read_csv(news_csv)\n",
    "        \n",
    "        for index, text in enumerate(news_df.text):\n",
    "            processed_list = text_preprocessing(text)\n",
    "            news_df.text[index] = ' '.join(processed_list)\n",
    "\n",
    "        train_news_df = news_df[news_df.split=='train']\n",
    "        return cls(news_df, NewsVectorizer.from_dataframe(train_news_df))\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        news_vector = \\\n",
    "            self._vectorizer.vectorize(row.text, self._max_seq_length)\n",
    "\n",
    "        category_index = \\\n",
    "            self._vectorizer.category_vocab.lookup_token(row.category)\n",
    "\n",
    "        return {'x_data': news_vector,     # e.g., \"Wall St. Bears Claw Back Into the Black (Reuters)\" \n",
    "                                            # -> [2, 5, 6, 10, 10, 8, 7, 9, 19, ......., 3, 0, 0, 0, ..., 0]\n",
    "                'y_target': category_index} # e.g., 2\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model: NewsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "    def __init__(self, embedding_size, num_embeddings, num_channels, \n",
    "                 hidden_dim, num_classes, dropout_p, \n",
    "                 pretrained_embeddings=None, padding_idx=0, emb_freeze=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_size (int): size of the embedding vectors\n",
    "            num_embeddings (int): number of embedding vectors\n",
    "            filter_width (int): width of the convolutional kernels\n",
    "            num_channels (int): number of convolutional kernels per layer\n",
    "            hidden_dim (int): the size of the hidden dimension\n",
    "            num_classes (int): the number of classes in classification\n",
    "            dropout_p (float): a dropout parameter \n",
    "            pretrained_embeddings (numpy.array): previously trained word embeddings\n",
    "                default is None. If provided, \n",
    "            padding_idx (int): an index representing a null position\n",
    "        \"\"\"\n",
    "        super(NewsClassifier, self).__init__()\n",
    "        \n",
    "        if pretrained_embeddings is None:\n",
    "            self.emb = nn.Embedding(embedding_dim=embedding_size,   # 100\n",
    "                                    num_embeddings=num_embeddings,  # 3409\n",
    "                                    padding_idx=padding_idx)        \n",
    "            self.emb.weight.requires_grad = True\n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.emb = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=emb_freeze) # when freeze=True (default), \n",
    "                                                                           # the tensor does not get updated in the learning process\n",
    "                             \n",
    "        # in_channels: embedding_size; out_channels: # of filters; kernel_size = n-gram size\n",
    "        # number of parameters: (# of filters, embedding_size, n-gram size), (100, 100, 2) for 2-gram\n",
    "        self.conv1d_4gram = nn.Conv1d(in_channels=embedding_size, out_channels=num_channels, kernel_size=4)       \n",
    "        self.conv1d_3gram = nn.Conv1d(in_channels=embedding_size, out_channels=num_channels, kernel_size=3)                          \n",
    "        self.conv1d_2gram = nn.Conv1d(in_channels=embedding_size, out_channels=num_channels, kernel_size=2)                   \n",
    "\n",
    "        self._dropout_p = dropout_p\n",
    "        self.fc1 = nn.Linear(num_channels*3, hidden_dim) # input:concatination of conv1d_4gram, conv1d_3gram, conv1d_2gram outputs \n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, dataset._max_seq_length)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, num_classes)\n",
    "        \"\"\"\n",
    "        \n",
    "        # embed and permute so features are channels\n",
    "        x_embedded = self.emb(x_in).permute(0, 2, 1)    # (batch, seq_len) -> (batch, seq_len, features)\n",
    "                                                        # rearange (batch, seq_len, features) to (batch, features, seq_len) \n",
    "                                                        # E.g.,    (128,   29,      100)      to (128,   100,      29)\n",
    "\n",
    "        features = F.elu(self.conv1d_4gram(x_embedded)) # features: (batch, num_channels, ?); e.g., (128, 100, ?)\n",
    "                                                        # activation function similar to leaky RELU(); can use F.relu() instead\n",
    "        # max/average and remove the extra dimension\n",
    "        remaining_size = features.size(dim=2)          # remaining_size: ? in (batch, num_channels, ?)\n",
    "        features_4gram = F.max_pool1d(features, remaining_size).squeeze(dim=2) # features_4gram: (batch, num_channels);kernel_size=remaining_size   \n",
    "        #features_4gram = F.avg_pool1d(features, remaining_size).squeeze(dim=2)   \n",
    "        \n",
    "        features = F.elu(self.conv1d_3gram(x_embedded)) # features: (batch, num_channels, ?); e.g., (128, 100, ?)\n",
    "        remaining_size = features.size(dim=2)          # remaining_size: ? in (batch, num_channels, ?)\n",
    "        features_3gram = F.max_pool1d(features, remaining_size).squeeze(dim=2)    # features_3gram: (batch, num_channels)\n",
    "\n",
    "        features = F.elu(self.conv1d_2gram(x_embedded)) # features: (batch, num_channels, ?); e.g., (128, 100, ?)\n",
    "        remaining_size = features.size(dim=2)          # remaining_size: ? in (batch, num_channels, ?)\n",
    "        features_2gram = F.max_pool1d(features, remaining_size).squeeze(dim=2)    # features_2gram: (batch, num_channels) \n",
    " \n",
    "        features = torch.cat([features_4gram, features_3gram, features_2gram], dim=1)\n",
    "            \n",
    "        features = F.dropout(features, p=self._dropout_p, training=self.training)\n",
    "        \n",
    "        # mlp classifier\n",
    "        intermediate_vector = F.dropout(F.relu(self.fc1(features)), p=self._dropout_p, training=self.training)\n",
    "        prediction_vector = self.fc2(intermediate_vector)  # (batch, num_classes)\n",
    "\n",
    "        if apply_softmax:\n",
    "            prediction_vector = F.softmax(prediction_vector, dim=1)\n",
    "\n",
    "        return prediction_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t  # update 'early_stopping_best_val'\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### general utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda, mps):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    try:\n",
    "        if mps:\n",
    "            torch.mps.manual_seed(seed)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "        \n",
    "def load_glove_from_file(glove_filepath):\n",
    "    \"\"\"\n",
    "    Load the GloVe embeddings \n",
    "    \n",
    "    Args:\n",
    "        glove_filepath (str): path to the glove embeddings file \n",
    "    Returns:\n",
    "        word_to_index (dict), embeddings (numpy.ndarary)\n",
    "    \"\"\"\n",
    "\n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(glove_filepath, \"r\", encoding='utf8') as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \") # each line: word num1 num2 ...\n",
    "            word_to_index[line[0]] = index # word = line[0] \n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    return word_to_index, np.stack(embeddings)\n",
    "\n",
    "def make_embedding_matrix(glove_filepath, words):\n",
    "    \"\"\"\n",
    "    Create embedding matrix for a specific set of words.\n",
    "    \n",
    "    Args:\n",
    "        glove_filepath (str): file path to the glove embeddigns\n",
    "        words (list): list of words in the dataset\n",
    "    \"\"\"\n",
    "    word_to_idx, glove_embeddings = load_glove_from_file(glove_filepath)\n",
    "    embedding_size = glove_embeddings.shape[1]\n",
    "    \n",
    "    final_embeddings = np.zeros((len(words), embedding_size))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word in word_to_idx:\n",
    "            final_embeddings[i, :] = glove_embeddings[word_to_idx[word]]\n",
    "        else:\n",
    "            embedding_i = torch.ones(1, embedding_size)\n",
    "            torch.nn.init.xavier_uniform_(embedding_i)\n",
    "            final_embeddings[i, :] = embedding_i\n",
    "\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings and some prep work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\t../model_storage/News_Category\\model_cnn_News_Category.pth\n",
      "Using CUDA: True\n",
      "Using MPS: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and Path hyper parameters\n",
    "    news_csv=\"../data/processed/News_Category_Dataset_with_splits.csv\",\n",
    "    model_state_file=\"model_cnn_News_Category.pth\",\n",
    "    save_dir=\"../model_storage/News_Category\",\n",
    "    # Model hyper parameters\n",
    "    glove_filepath='../data/glove/glove.6B.100d.txt', \n",
    "    use_glove=True,\n",
    "    embedding_size=100, \n",
    "    hidden_dim=100, \n",
    "    num_channels=100, \n",
    "    # Training hyper parameter\n",
    "    seed=1337, \n",
    "    learning_rate=0.001, \n",
    "    dropout_p=0.1, \n",
    "    batch_size=64, \n",
    "    num_epochs=100, \n",
    "    emb_freeze=True,\n",
    "    early_stopping_criteria=5, \n",
    "    # Runtime option\n",
    "    cuda=True,\n",
    "    mps=True, \n",
    "    catch_keyboard_interrupt=True, \n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True\n",
    ") \n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA for Nvidia\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "# Check MPS for Mac\n",
    "if not torch.backends.mps.is_available():\n",
    "    args.mps = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"mps\" if args.mps else \"cpu\")\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "print(\"Using MPS: {}\".format(args.mps))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda, args.mps)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-trained embeddings\n"
     ]
    }
   ],
   "source": [
    "# create dataset and vectorizer\n",
    "dataset = NewsDataset.load_dataset_and_make_vectorizer(args.news_csv)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# Use GloVe or randomly initialized embeddings\n",
    "if args.use_glove:\n",
    "    words = vectorizer.news_vocab._token_to_idx.keys()  # 3409 unique words\n",
    "    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath,     # embeddings: (3409, 100)\n",
    "                                       words=words)\n",
    "    print(\"Using pre-trained embeddings\")\n",
    "else:\n",
    "    print(\"Not using pre-trained embeddings\")\n",
    "    embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'sue': 4, 'drug': 5, 'republican': 6, 'governor': 7, 'bush': 8, 'administration': 9, 'policy': 10, 'federal': 11, 'court': 12, 'yesterday': 13, 'first': 14, 'time': 15, 'state': 16, 'legal': 17, 'battle': 18, 'canadian': 19, 'uk': 20, 'poor': 21, 'nation': 22, 'debt': 23, 'brown': 24, 'say': 25, 'share': 26, 'world': 27, 'country': 28, 'bank': 29, 'two': 30, 'hurricane': 31, 'many': 32, 'area': 33, 'suffered': 34, 'double': 35, 'blow': 36, 'france': 37, 'struck': 38, 'financial': 39, 'one': 40, 'insurance': 41, 'selling': 42, 'news': 43, 'international': 44, 'inc': 45, 'quote': 46, 'profile': 47, 'research': 48, 'jumped': 49, 'percent': 50, 'since': 51, 'early': 52, 'last': 53, 'week': 54, 'gun': 55, 'maker': 56, 'issued': 57, 'announcement': 58, 'brand': 59, 'offer': 60, 'billion': 61, 'update': 62, 'largest': 63, 'offered': 64, 'cash': 65, 'acquire': 66, 'robert': 67, 'corp': 68, 'lower': 69, 'price': 70, 'amp': 71, 'p': 72, 'slide': 73, 'nasdaq': 74, 'dow': 75, 'rise': 76, 'standard': 77, 'stock': 78, 'index': 79, 'three': 80, 'year': 81, 'high': 82, 'energy': 83, 'including': 84, 'crude': 85, 'oil': 86, 'dropped': 87, 'almost': 88, 'month': 89, 'buyer': 90, 'interest': 91, 'irish': 92, 'sydney': 93, 'national': 94, 'australia': 95, 'ltd': 96, 'biggest': 97, 'struggling': 98, 'prepared': 99, 'part': 100, 'european': 101, 'market': 102, 'u': 103, 'want': 104, 'named': 105, 'united': 106, 'pension': 107, 'aug': 108, 'ap': 109, 'airline': 110, 'plan': 111, 'company': 112, 'labor': 113, 'department': 114, 'said': 115, 'tuesday': 116, 'air': 117, 'pilot': 118, 'union': 119, 'benefit': 120, 'cut': 121, 'leader': 122, 'rebel': 123, 'group': 124, 'airway': 125, 'charged': 126, 'much': 127, 'employee': 128, 'oracle': 129, 'sweet': 130, 'peoplesoft': 131, 'hostile': 132, 'bid': 133, 'rival': 134, 'business': 135, 'software': 136, 'increase': 137, 'aimed': 138, 'long': 139, 'running': 140, 'takeover': 141, 'economic': 142, 'declined': 143, 'july': 144, 'measure': 145, 'future': 146, 'activity': 147, 'fell': 148, 'second': 149, 'consecutive': 150, 'evidence': 151, 'recovery': 152, 'general': 153, 'motor': 154, 'europe': 155, 'job': 156, 'gm': 157, 'n': 158, 'around': 159, 'fifth': 160, 'american': 161, 'eagle': 162, 'reach': 163, 'deal': 164, 'division': 165, 'contract': 166, 'agreement': 167, 'pay': 168, 'raise': 169, 'agree': 170, 'hotel': 171, 'bankruptcy': 172, 'thursday': 173, 'approved': 174, 'dollar': 175, 'record': 176, 'low': 177, 'euro': 178, 'currency': 179, 'gas': 180, 'supply': 181, 'data': 182, 'due': 183, 'san': 184, 'francisco': 185, 'cbs': 186, 'mw': 187, 'rally': 188, 'fresh': 189, 'gain': 190, 'four': 191, 'session': 192, 'pulled': 193, 'barrel': 194, 'higher': 195, 'wednesday': 196, 'ibm': 197, 'sell': 198, 'pc': 199, 'stake': 200, 'china': 201, 'computer': 202, 'today': 203, 'machine': 204, 'personal': 205, 'chinese': 206, 'acquisition': 207, 'ever': 208, 'profit': 209, 'good': 210, 'co': 211, 'monday': 212, 'posted': 213, 'better': 214, 'expected': 215, 'sending': 216, 'near': 217, 'heavy': 218, 'product': 219, 'sale': 220, 'flat': 221, 'retail': 222, 'opened': 223, 'little': 224, 'concern': 225, 'corporate': 226, 'investor': 227, 'also': 228, 'income': 229, 'take': 230, 'hit': 231, 'family': 232, 'become': 233, 'victim': 234, 'fannie': 235, 'mae': 236, 'official': 237, 'mission': 238, 'rate': 239, 'capital': 240, 'available': 241, 'mortgage': 242, 'loan': 243, 'panel': 244, 'seek': 245, 'limit': 246, 'commission': 247, 'industry': 248, 'executive': 249, 'issue': 250, 'report': 251, 'call': 252, 'linked': 253, 'global': 254, 'set': 255, 'fuel': 256, 'economy': 257, 'nuclear': 258, 'power': 259, 'outside': 260, 'milan': 261, 'judge': 262, 'ruled': 263, 'former': 264, 'stand': 265, 'trial': 266, 'january': 267, 'collapse': 268, 'italian': 269, 'food': 270, 'sec': 271, 'charge': 272, 'ex': 273, 'fraud': 274, 'washington': 275, 'reuters': 276, 'security': 277, 'exchange': 278, 'filed': 279, 'civil': 280, 'six': 281, 'senior': 282, 'officer': 283, 'system': 284, 'href': 285, 'target': 286, 'quickinfo': 287, 'fullquote': 288, 'cover': 289, 'massive': 290, 'accounting': 291, 'technology': 292, 'fda': 293, 'vioxx': 294, 'result': 295, 'expert': 296, 'agency': 297, 'study': 298, 'showing': 299, 'potential': 300, 'anti': 301, 'credit': 302, 'card': 303, 'keep': 304, 'eye': 305, 'may': 306, 'northwest': 307, 'ticket': 308, 'fee': 309, 'suit': 310, 'travel': 311, 'network': 312, 'district': 313, 'minnesota': 314, 'make': 315, 'carrier': 316, 'worker': 317, 'germany': 318, 'hold': 319, 'major': 320, 'protest': 321, 'ahead': 322, 'talk': 323, 'thousand': 324, 'german': 325, 'car': 326, 'giant': 327, 'held': 328, 'crucial': 329, 'round': 330, 'work': 331, 'council': 332, 'eu': 333, 'clear': 334, 'water': 335, 'row': 336, 'trade': 337, 'chief': 338, 'peter': 339, 'threatened': 340, 'action': 341, 'aid': 342, 'airbus': 343, 'friday': 344, 'toshiba': 345, 'image': 346, 'chip': 347, 'firm': 348, 'tokyo': 349, 'oct': 350, 'manufacturing': 351, 'end': 352, 'semiconductor': 353, 'expects': 354, 'think': 355, 'entertainment': 356, 'nyse': 357, 'could': 358, 'late': 359, 'operator': 360, 'merger': 361, 'partner': 362, 'social': 363, 'reform': 364, 'fund': 365, 'new': 366, 'york': 367, 'believe': 368, 'president': 369, 'handed': 370, 'mutual': 371, 'fall': 372, 'warns': 373, 'drop': 374, 'quarterly': 375, 'warned': 376, 'top': 377, 'strike': 378, 'southern': 379, 'california': 380, 'front': 381, 'page': 382, 'v': 383, 'main': 384, 'reason': 385, 'people': 386, 'quot': 387, 'look': 388, 'million': 389, 'mining': 390, 'resource': 391, 'agreed': 392, 'worth': 393, 'retailer': 394, 'post': 395, 'holiday': 396, 'england': 397, 'right': 398, 'test': 399, 'hand': 400, 'face': 401, 'store': 402, 'sunday': 403, 'nov': 404, 'david': 405, 'management': 406, 'television': 407, 'production': 408, 'studio': 409, 'joint': 410, 'venture': 411, 'limited': 412, 'value': 413, 'crm': 414, 'congress': 415, 'told': 416, 'failed': 417, 'public': 418, 'merck': 419, 'america': 420, 'another': 421, 'researcher': 422, 'fired': 423, 'bad': 424, 'half': 425, 'forecast': 426, 'fix': 427, 'meet': 428, 'paris': 429, 'discus': 430, 'ipo': 431, 'board': 432, 'meeting': 433, 'consider': 434, 'private': 435, 'independent': 436, 'investment': 437, 'buy': 438, 'google': 439, 'debut': 440, 'seattle': 441, 'made': 442, 'awaited': 443, 'rising': 444, 'sharply': 445, 'initial': 446, 'offering': 447, 'die': 448, 'delta': 449, 'line': 450, 'latest': 451, 'show': 452, 'point': 453, 'analyst': 454, 'must': 455, 'decide': 456, 'file': 457, 'daily': 458, 'michael': 459, 'appeared': 460, 'day': 461, 'shareholder': 462, 'lawsuit': 463, 'package': 464, 'ask': 465, 'emergency': 466, 'reached': 467, 'arthritis': 468, 'would': 469, 'stop': 470, 'found': 471, 'patient': 472, 'risk': 473, 'heart': 474, 'attack': 475, 'stroke': 476, 'added': 477, 'september': 478, 'unemployment': 479, 'according': 480, 'survey': 481, 'still': 482, 'q': 483, 'b': 484, 'despite': 485, 'effort': 486, 'growth': 487, 'domestic': 488, 'per': 489, 'cent': 490, 'quarter': 491, 'government': 492, 'reported': 493, 'bell': 494, 'army': 495, 'kick': 496, 'annual': 497, 'red': 498, 'program': 499, 'growing': 500, 'number': 501, 'best': 502, 'moved': 503, 'trading': 504, 'rose': 505, 'august': 506, 'previous': 507, 'inventory': 508, 'decline': 509, 'ceo': 510, 'leaf': 511, 'troubled': 512, 'aircraft': 513, 'saw': 514, 'toronto': 515, 'announced': 516, 'paul': 517, 'ford': 518, 'give': 519, 'lift': 520, 'blue': 521, 'advanced': 522, 'raised': 523, 'earnings': 524, 'wireless': 525, 'provider': 526, 'saying': 527, 'review': 528, 'reduce': 529, 'cisco': 530, 'lead': 531, 'tech': 532, 'doubt': 533, 'brokerage': 534, 'slow': 535, 'next': 536, 'dec': 537, 'bit': 538, 'though': 539, 'condition': 540, 'sound': 541, 'india': 542, 'unit': 543, 'electric': 544, 'indian': 545, 'arm': 546, 'chicago': 547, 'club': 548, 'cost': 549, 'possible': 550, 'war': 551, 'fate': 552, 'along': 553, 'way': 554, 'side': 555, 'regulator': 556, 'houston': 557, 'plant': 558, 'device': 559, 'broker': 560, 'shot': 561, 'called': 562, 'investigation': 563, 'turned': 564, 'old': 565, 'truck': 566, 'soldier': 567, 'wife': 568, 'decided': 569, 'bring': 570, 'back': 571, 'virginia': 572, 'home': 573, 'jump': 574, 'defense': 575, 'third': 576, 'led': 577, 'big': 578, 'rebound': 579, 'stay': 580, 'rich': 581, 'likely': 582, 'demand': 583, 'head': 584, 'move': 585, 'seeking': 586, 'money': 587, 'paid': 588, 'book': 589, 'protection': 590, 'owner': 591, 'help': 592, 'like': 593, 'amazon': 594, 'com': 595, 'mean': 596, 'change': 597, 'october': 598, 'start': 599, 'phone': 600, 'planning': 601, 'huge': 602, 'project': 603, 'sanction': 604, 'following': 605, 'export': 606, 'tax': 607, 'net': 608, 'enron': 609, 'get': 610, 'full': 611, 'nearly': 612, 'see': 613, 'thanks': 614, 'pressure': 615, 'corporation': 616, 'kodak': 617, 'team': 618, 'camera': 619, 'rating': 620, 'ny': 621, 'develop': 622, 'mass': 623, 'consumer': 624, 'digital': 625, 'kansa': 626, 'begin': 627, 'recent': 628, 'name': 629, 'ring': 630, 'resident': 631, 'local': 632, 'candidate': 633, 'room': 634, 'debate': 635, 'electronics': 636, 'manufacturer': 637, 'stronger': 638, 'electronic': 639, 'zealand': 640, 'jones': 641, 'current': 642, 'hope': 643, 'sprint': 644, 'asset': 645, 'traditional': 646, 'le': 647, 'marketing': 648, 'service': 649, 'victory': 650, 'wall': 651, 'street': 652, 'threw': 653, 'even': 654, 'control': 655, 'surge': 656, 'picked': 657, 'speed': 658, 'improving': 659, 'strong': 660, 'spending': 661, 'performance': 662, 'paper': 663, 'loses': 664, 'jet': 665, 'lost': 666, 'regional': 667, 'key': 668, 'saturday': 669, 'developing': 670, 'turn': 671, 'decade': 672, 'continue': 673, 'solid': 674, 'expansion': 675, 'beating': 676, 'expectation': 677, 'r': 678, 'van': 679, 'associate': 680, 'manager': 681, 'connection': 682, 'singapore': 683, 'violence': 684, 'iraq': 685, 'find': 686, 'county': 687, 'producer': 688, 'game': 689, 'ago': 690, 'boost': 691, 'processor': 692, 'option': 693, 'open': 694, 'opec': 695, 'iran': 696, 'tehran': 697, 'cutting': 698, 'minister': 699, 'response': 700, 'sharp': 701, 'final': 702, 'presidential': 703, 'election': 704, 'toy': 705, 'safety': 706, 'child': 707, 'received': 708, 'breaking': 709, 'five': 710, 'started': 711, 'broken': 712, 'city': 713, 'used': 714, 'sought': 715, 'dog': 716, 'park': 717, 'let': 718, 'run': 719, 'without': 720, 'appeal': 721, 'reject': 722, 'asbestos': 723, 'settlement': 724, 'rejected': 725, 'swiss': 726, 'win': 727, 'boosted': 728, 'health': 729, 'defence': 730, 'seen': 731, 'george': 732, 'w': 733, 'advance': 734, 'bond': 735, 'th': 736, 'amid': 737, 'fourth': 738, 'related': 739, 'sent': 740, 'highest': 741, 'level': 742, 'go': 743, 'getting': 744, 'every': 745, 'ready': 746, 'night': 747, 'rest': 748, 'dream': 749, 'britain': 750, 'british': 751, 'began': 752, 'office': 753, 'defending': 754, 'afp': 755, 'facing': 756, 'track': 757, 'revenue': 758, 'doctor': 759, 'dozen': 760, 'relief': 761, 'flight': 762, 'schedule': 763, 'philadelphia': 764, 'create': 765, 'fla': 766, 'settle': 767, 'sept': 768, 'banking': 769, 'brother': 770, 'holding': 771, 'trader': 772, 'source': 773, 'familiar': 774, 'case': 775, 'announces': 776, 'australian': 777, 'customer': 778, 'indianapolis': 779, 'filing': 780, 'alliance': 781, 'proposed': 782, 'fan': 783, 'boston': 784, 'rule': 785, 'taking': 786, 'foot': 787, 'add': 788, 'adding': 789, 'slightly': 790, 'twice': 791, 'web': 792, 'search': 793, 'leading': 794, 'based': 795, 'reportedly': 796, 'alleged': 797, 'conflict': 798, 'sign': 799, 'house': 800, 'property': 801, 'canada': 802, 'looking': 803, 'whether': 804, 'patch': 805, 'decision': 806, 'information': 807, 'fcc': 808, 'mobile': 809, 'use': 810, 'although': 811, 'cell': 812, 'ban': 813, 'remained': 814, 'place': 815, 'given': 816, 'confidence': 817, 'middle': 818, 'ease': 819, 'remain': 820, 'earlier': 821, 'increased': 822, 'fighting': 823, 'nigeria': 824, 'forced': 825, 'several': 826, 'fiscal': 827, 'helped': 828, 'witness': 829, 'lawyer': 830, 'client': 831, 'scandal': 832, 'message': 833, 'site': 834, 'staff': 835, 'release': 836, 'non': 837, 'later': 838, 'g': 839, 'worry': 840, 'peace': 841, 'thought': 842, 'warning': 843, 'operation': 844, 'short': 845, 'estimate': 846, 'advertising': 847, 'loss': 848, 'impact': 849, 'newspaper': 850, 'florida': 851, 'georgia': 852, 'deficit': 853, 'budget': 854, 'step': 855, 'support': 856, 'weather': 857, 'competition': 858, 'vehicle': 859, 'road': 860, 'auto': 861, 'f': 862, 'gold': 863, 'lifted': 864, 'london': 865, 'seven': 866, 'finance': 867, 'inflation': 868, 'fear': 869, 'close': 870, 'welcome': 871, 'black': 872, 'french': 873, 'disney': 874, 'tv': 875, 'los': 876, 'angeles': 877, 'walt': 878, 'movie': 879, 'stewart': 880, 'try': 881, 'base': 882, 'damage': 883, 'falling': 884, 'class': 885, 'opening': 886, 'treatment': 887, 'disease': 888, 'developer': 889, 'mark': 890, 'plc': 891, 'sea': 892, 'dutch': 893, 'grew': 894, 'pace': 895, 'expand': 896, 'capacity': 897, 'iraqi': 898, 'st': 899, 'eight': 900, 'south': 901, 'korean': 902, 'ivory': 903, 'coast': 904, 'kept': 905, 'edge': 906, 'reserve': 907, 'course': 908, 'matter': 909, 'hearing': 910, 'pact': 911, 'making': 912, 'japan': 913, 'come': 914, 'drive': 915, 'yen': 916, 'nikkei': 917, 'japanese': 918, 'sector': 919, 'additional': 920, 'e': 921, 'march': 922, 'already': 923, 'suspension': 924, 'michigan': 925, 'allow': 926, 'communication': 927, 'internet': 928, 'terrorist': 929, 'attorney': 930, 'l': 931, 'secret': 932, 'jersey': 933, 'term': 934, 'hospital': 935, 'special': 936, 'carry': 937, 'saving': 938, 'medical': 939, 'ivan': 940, 'popular': 941, 'traffic': 942, 'wake': 943, 'material': 944, 'great': 945, 'return': 946, 'aol': 947, 'online': 948, 'law': 949, 'known': 950, 'instant': 951, 'account': 952, 'photo': 953, 'film': 954, 'lab': 955, 'focus': 956, 'order': 957, 'saudi': 958, 'large': 959, 'indonesia': 960, 'seventh': 961, 'accused': 962, 'insurer': 963, 'push': 964, 'airport': 965, 'weekend': 966, 'linux': 967, 'shift': 968, 'camp': 969, 'tough': 970, 'microsoft': 971, 'operating': 972, 'steve': 973, 'ballmer': 974, 'bos': 975, 'verizon': 976, 'nextel': 977, 'opposition': 978, 'vice': 979, 'chairman': 980, 'charles': 981, 'university': 982, 'school': 983, 'launched': 984, 'desktop': 985, 'sold': 986, 'bn': 987, 'confirmed': 988, 'hard': 989, 'kmart': 990, 'super': 991, 'chain': 992, 'celtic': 993, 'auction': 994, 'russia': 995, 'faster': 996, 'showed': 997, 'gave': 998, 'peer': 999, 'africa': 1000, 'needed': 1001, 'foreign': 1002, 'baltimore': 1003, 'quit': 1004, 'putting': 1005, 'history': 1006, 'delay': 1007, 'commissioner': 1008, 'dispute': 1009, 'boeing': 1010, 'hike': 1011, 'detroit': 1012, 'model': 1013, 'force': 1014, 'white': 1015, 'asked': 1016, 'justice': 1017, 'secretary': 1018, 'james': 1019, 'proposal': 1020, 'backed': 1021, 'rescue': 1022, 'deputy': 1023, 'took': 1024, 'intel': 1025, 'defeat': 1026, 'amd': 1027, 'attempt': 1028, 'trust': 1029, 'asian': 1030, 'mixed': 1031, 'hong': 1032, 'kong': 1033, 'finished': 1034, 'positive': 1035, 'outlook': 1036, 'successful': 1037, 'ad': 1038, 'era': 1039, 'effect': 1040, 'owned': 1041, 'became': 1042, 'newly': 1043, 'steel': 1044, 'separate': 1045, 'continues': 1046, 'behind': 1047, 'play': 1048, 'bill': 1049, 'gate': 1050, 'hoping': 1051, 'among': 1052, 'style': 1053, 'young': 1054, 'student': 1055, 'parent': 1056, 'fire': 1057, 'spanish': 1058, 'buying': 1059, 'nine': 1060, 'central': 1061, 'preliminary': 1062, 'approval': 1063, 'wal': 1064, 'mart': 1065, 'member': 1066, 'build': 1067, 'john': 1068, 'passenger': 1069, 'warner': 1070, 'medium': 1071, 'inquiry': 1072, 'strategy': 1073, 'louis': 1074, 'publisher': 1075, 'arizona': 1076, 'considering': 1077, 'interview': 1078, 'output': 1079, 'au': 1080, 'quickly': 1081, 'link': 1082, 'race': 1083, 'generation': 1084, 'howard': 1085, 'stern': 1086, 'satellite': 1087, 'radio': 1088, 'shock': 1089, 'industrial': 1090, 'toward': 1091, 'looked': 1092, 'brazil': 1093, 'brazilian': 1094, 'suspended': 1095, 'pfizer': 1096, 'professional': 1097, 'campaign': 1098, 'director': 1099, 'leaving': 1100, 'cancer': 1101, 'left': 1102, 'raising': 1103, 'zone': 1104, 'fed': 1105, 'plea': 1106, 'southeast': 1107, 'morning': 1108, 'position': 1109, 'committee': 1110, 'problem': 1111, 'range': 1112, 'struggle': 1113, 'building': 1114, 'coming': 1115, 'commercial': 1116, 'announce': 1117, 'form': 1118, 'korea': 1119, 'preparing': 1120, 'read': 1121, 'channel': 1122, 'view': 1123, 'november': 1124, 'cross': 1125, 'border': 1126, 'confirms': 1127, 'average': 1128, 'away': 1129, 'declared': 1130, 'regular': 1131, 'status': 1132, 'whose': 1133, 'fine': 1134, 'probe': 1135, 'tell': 1136, 'continued': 1137, 'speculation': 1138, 'threat': 1139, 'starting': 1140, 'aim': 1141, 'slip': 1142, 'surprise': 1143, 'urge': 1144, 'terror': 1145, 'guard': 1146, 'fight': 1147, 'video': 1148, 'hot': 1149, 'driver': 1150, 'spain': 1151, 'yet': 1152, 'engine': 1153, 'afternoon': 1154, 'field': 1155, 'revealed': 1156, 'hat': 1157, 'jr': 1158, 'june': 1159, 'prison': 1160, 'cable': 1161, 'enterprise': 1162, 'pull': 1163, 'ireland': 1164, 'ruling': 1165, 'losing': 1166, 'formula': 1167, 'well': 1168, 'summer': 1169, 'shopping': 1170, 'pound': 1171, 'ending': 1172, 'mouse': 1173, 'real': 1174, 'might': 1175, 'christmas': 1176, 'tree': 1177, 'reporter': 1178, 'memory': 1179, 'serious': 1180, 'least': 1181, 'tie': 1182, 'closing': 1183, 'put': 1184, 'stem': 1185, 'region': 1186, 'note': 1187, 'turkish': 1188, 'progress': 1189, 'turkey': 1190, 'longer': 1191, 'block': 1192, 'ended': 1193, 'storm': 1194, 'mid': 1195, 'brought': 1196, 'moment': 1197, 'finding': 1198, 'perhaps': 1199, 'antitrust': 1200, 'smith': 1201, 'purchase': 1202, 'figure': 1203, 'expect': 1204, 'remains': 1205, 'signed': 1206, 'development': 1207, 'total': 1208, 'enough': 1209, 'increasing': 1210, 'chance': 1211, 'winning': 1212, 'closed': 1213, 'texas': 1214, 'introduced': 1215, 'pitch': 1216, 'provide': 1217, 'mac': 1218, 'straight': 1219, 'lack': 1220, 'cold': 1221, 'december': 1222, 'care': 1223, 'johnson': 1224, 'word': 1225, 'founder': 1226, 'associated': 1227, 'subscriber': 1228, 'vote': 1229, 'appears': 1230, 'son': 1231, 'promise': 1232, 'political': 1233, 'code': 1234, 'rock': 1235, 'forward': 1236, 'negotiation': 1237, 'labour': 1238, 'planned': 1239, 'period': 1240, 'giving': 1241, 'north': 1242, 'watchdog': 1243, 'others': 1244, 'tool': 1245, 'factory': 1246, 'star': 1247, 'partnership': 1248, 'unless': 1249, 'ally': 1250, 'far': 1251, 'deep': 1252, 'turning': 1253, 'rout': 1254, 'bus': 1255, 'improve': 1256, 'tour': 1257, 'got': 1258, 'version': 1259, 'wi': 1260, 'fi': 1261, 'successor': 1262, 'access': 1263, 'putin': 1264, 'russian': 1265, 'vladimir': 1266, 'telephone': 1267, 'sure': 1268, 'land': 1269, 'mar': 1270, 'challenge': 1271, 'woman': 1272, 'deadline': 1273, 'pass': 1274, 'free': 1275, 'complete': 1276, 'currently': 1277, 'instead': 1278, 'hour': 1279, 'season': 1280, 'send': 1281, 'lawmaker': 1282, 'grand': 1283, 'jury': 1284, 'success': 1285, 'produce': 1286, 'life': 1287, 'authority': 1288, 'important': 1289, 'prime': 1290, 'display': 1291, 'symantec': 1292, 'storage': 1293, 'soon': 1294, 'calling': 1295, 'person': 1296, 'worldwide': 1297, 'designed': 1298, 'green': 1299, 'wave': 1300, 'going': 1301, 'critical': 1302, 'treasury': 1303, 'astronaut': 1304, 'moon': 1305, 'beyond': 1306, 'asia': 1307, 'eastern': 1308, 'released': 1309, 'break': 1310, 'small': 1311, 'list': 1312, 'shopper': 1313, 'carolina': 1314, 'edition': 1315, 'yukos': 1316, 'application': 1317, 'apple': 1318, 'hundred': 1319, 'equipment': 1320, 'resigned': 1321, 'avoid': 1322, 'speech': 1323, 'forest': 1324, 'retirement': 1325, 'statement': 1326, 'phelps': 1327, 'mine': 1328, 'process': 1329, 'allegation': 1330, 'allowed': 1331, 'certain': 1332, 'recall': 1333, 'body': 1334, 'organization': 1335, 'stage': 1336, 'idea': 1337, 'chart': 1338, 'claim': 1339, 'supercomputer': 1340, 'fastest': 1341, 'developed': 1342, 'cingular': 1343, 'hurt': 1344, 'admitted': 1345, 'controversial': 1346, 'al': 1347, 'played': 1348, 'caused': 1349, 'rocket': 1350, 'science': 1351, 'cause': 1352, 'wide': 1353, 'ebay': 1354, 'recently': 1355, 'sony': 1356, 'portable': 1357, 'launch': 1358, 'claimed': 1359, 'helping': 1360, 'ground': 1361, 'age': 1362, 'taken': 1363, 'beat': 1364, 'c': 1365, 'created': 1366, 'association': 1367, 'gap': 1368, 'bay': 1369, 'kerry': 1370, 'easy': 1371, 'ranked': 1372, 'sixth': 1373, 'royal': 1374, 'winner': 1375, 'lot': 1376, 'voice': 1377, 'telecom': 1378, 'african': 1379, 'dramatic': 1380, 'tap': 1381, 'larry': 1382, 'lay': 1383, 'criminal': 1384, 'chase': 1385, 'west': 1386, 'king': 1387, 'spokesman': 1388, 'surgery': 1389, 'jose': 1390, 'calif': 1391, 'size': 1392, 'came': 1393, 'closer': 1394, 'goal': 1395, 'belief': 1396, 'pm': 1397, 'urged': 1398, 'argentina': 1399, 'document': 1400, 'space': 1401, 'different': 1402, 'protect': 1403, 'samsung': 1404, 'safe': 1405, 'halo': 1406, 'score': 1407, 'broke': 1408, 'licensing': 1409, 'supreme': 1410, 'winter': 1411, 'ok': 1412, 'save': 1413, 'picture': 1414, 'fish': 1415, 'mile': 1416, 'river': 1417, 'pacific': 1418, 'j': 1419, 'suggests': 1420, 'cp': 1421, 'setting': 1422, 'injury': 1423, 'detail': 1424, 'replace': 1425, 'plus': 1426, 'light': 1427, 'self': 1428, 'senate': 1429, 'guilty': 1430, 'within': 1431, 'interim': 1432, 'pre': 1433, 'check': 1434, 'century': 1435, 'act': 1436, 'allows': 1437, 'bar': 1438, 'dvd': 1439, 'together': 1440, 'bridge': 1441, 'oakland': 1442, 'plane': 1443, 'northern': 1444, 'dell': 1445, 'extended': 1446, 'donald': 1447, 'suicide': 1448, 'join': 1449, 'crowd': 1450, 'thing': 1451, 'town': 1452, 'titan': 1453, 'illegal': 1454, 'internal': 1455, 'practice': 1456, 'terrorism': 1457, 'comment': 1458, 'tomorrow': 1459, 'suspected': 1460, 'format': 1461, 'box': 1462, 'server': 1463, 'ball': 1464, 'bowl': 1465, 'kid': 1466, 'individual': 1467, 'discovered': 1468, 'question': 1469, 'nortel': 1470, 'facility': 1471, 'sun': 1472, 'moscow': 1473, 'battery': 1474, 'man': 1475, 'mp': 1476, 'twin': 1477, 'nintendo': 1478, 'handheld': 1479, 'upgrade': 1480, 'know': 1481, 'press': 1482, 'conference': 1483, 'user': 1484, 'testing': 1485, 'spot': 1486, 'cabinet': 1487, 'philippine': 1488, 'living': 1489, 'mexico': 1490, 'watch': 1491, 'hear': 1492, 'extend': 1493, 'attention': 1494, 'fast': 1495, 'community': 1496, 'walk': 1497, 'mount': 1498, 'leave': 1499, 'using': 1500, 'negotiator': 1501, 'series': 1502, 'western': 1503, 'previously': 1504, 'express': 1505, 'port': 1506, 'virgin': 1507, 'went': 1508, 'ministry': 1509, 'shell': 1510, 'tom': 1511, 'mother': 1512, 'er': 1513, 'lee': 1514, 'station': 1515, 'need': 1516, 'patent': 1517, 'overhaul': 1518, 'creating': 1519, 'dallas': 1520, 'jail': 1521, 'human': 1522, 'scientist': 1523, 'published': 1524, 'agrees': 1525, 'verdana': 1526, 'm': 1527, 'sans': 1528, 'serif': 1529, 'arial': 1530, 'helvetica': 1531, 'color': 1532, 'font': 1533, 'past': 1534, 'feature': 1535, 'death': 1536, 'flu': 1537, 'italy': 1538, 'tim': 1539, 'apparently': 1540, 'miami': 1541, 'voting': 1542, 'miss': 1543, 'improved': 1544, 'missed': 1545, 'classic': 1546, 'music': 1547, 'pick': 1548, 'networking': 1549, 'prosecutor': 1550, 'count': 1551, 'beijing': 1552, 'draw': 1553, 'similar': 1554, 'trying': 1555, 'able': 1556, 'ordered': 1557, 'core': 1558, 'diego': 1559, 'worst': 1560, 'crisis': 1561, 'title': 1562, 'bear': 1563, 'live': 1564, 'vendor': 1565, 'screen': 1566, 'wounded': 1567, 'piracy': 1568, 'sharing': 1569, 'copyright': 1570, 'event': 1571, 'x': 1572, 'scheduled': 1573, 'center': 1574, 'master': 1575, 'suspect': 1576, 'opportunity': 1577, 'host': 1578, 'choice': 1579, 'weapon': 1580, 'hole': 1581, 'beginning': 1582, 'notebook': 1583, 'un': 1584, 'resolution': 1585, 'roundup': 1586, 'never': 1587, 'story': 1588, 'crash': 1589, 'request': 1590, 'tennessee': 1591, 'la': 1592, 'agent': 1593, 'resume': 1594, 'deadly': 1595, 'date': 1596, 'ten': 1597, 'enter': 1598, 'nobel': 1599, 'dominated': 1600, 'prize': 1601, 'hall': 1602, 'ipod': 1603, 'broadband': 1604, 'unveiled': 1605, 'smaller': 1606, 'flying': 1607, 'yahoo': 1608, 'content': 1609, 'killing': 1610, 'killed': 1611, 'visit': 1612, 'ran': 1613, 'troop': 1614, 'glazer': 1615, 'died': 1616, 'wait': 1617, 'recording': 1618, 'crime': 1619, 'passed': 1620, 'smart': 1621, 'laden': 1622, 'east': 1623, 'champion': 1624, 'song': 1625, 'wrap': 1626, 'across': 1627, 'hollywood': 1628, 'failure': 1629, 'done': 1630, 'download': 1631, 'stadium': 1632, 'eighth': 1633, 'powerful': 1634, 'cap': 1635, 'mail': 1636, 'feared': 1637, 'really': 1638, 'moving': 1639, 'lose': 1640, 'ohio': 1641, 'microsystems': 1642, 'colorado': 1643, 'bomb': 1644, 'military': 1645, 'jakarta': 1646, 'venezuela': 1647, 'cardinal': 1648, 'spyware': 1649, 'seat': 1650, 'athens': 1651, 'olympics': 1652, 'threatening': 1653, 'novell': 1654, 'martin': 1655, 'placed': 1656, 'fly': 1657, 'wind': 1658, 'province': 1659, 'abuse': 1660, 'preview': 1661, 'palmone': 1662, 'built': 1663, 'player': 1664, 'ship': 1665, 'bringing': 1666, 'fox': 1667, 'ray': 1668, 'palestinian': 1669, 'working': 1670, 'direct': 1671, 'surface': 1672, 'offensive': 1673, 'wrong': 1674, 'believed': 1675, 'something': 1676, 'friend': 1677, 'browser': 1678, 'najaf': 1679, 'sport': 1680, 'pro': 1681, 'oklahoma': 1682, 'priority': 1683, 'secure': 1684, 'blair': 1685, 'tony': 1686, 'indiana': 1687, 'dead': 1688, 'missing': 1689, 'flood': 1690, 'opponent': 1691, 'tonight': 1692, 'flaw': 1693, 'voter': 1694, 'poll': 1695, 'veteran': 1696, 'party': 1697, 'myanmar': 1698, 'broadcast': 1699, 'single': 1700, 'arrested': 1701, 'college': 1702, 'democratic': 1703, 'saddam': 1704, 'door': 1705, 'manchester': 1706, 'blame': 1707, 'finish': 1708, 'worm': 1709, 'finally': 1710, 'website': 1711, 'davis': 1712, 'spent': 1713, 'shanghai': 1714, 'premier': 1715, 'appear': 1716, 'disc': 1717, 'streak': 1718, 'men': 1719, 'israel': 1720, 'gaza': 1721, 'strip': 1722, 'returned': 1723, 'democracy': 1724, 'attacked': 1725, 'headquarters': 1726, 'intelligence': 1727, 'police': 1728, 'extra': 1729, 'orleans': 1730, 'virus': 1731, 'dual': 1732, 'bangladesh': 1733, 'console': 1734, 'identity': 1735, 'theft': 1736, 'earth': 1737, 'accept': 1738, 'window': 1739, 'met': 1740, 'kill': 1741, 'israeli': 1742, 'sex': 1743, 'trip': 1744, 'clash': 1745, 'crew': 1746, 'convention': 1747, 'engineer': 1748, 'armed': 1749, 'roll': 1750, 'de': 1751, 'ryder': 1752, 'coalition': 1753, 'jeff': 1754, 'sen': 1755, 'joe': 1756, 'heat': 1757, 'sox': 1758, 'league': 1759, 'baseball': 1760, 'role': 1761, 'wood': 1762, 'republic': 1763, 'leg': 1764, 'atlanta': 1765, 'gary': 1766, 'toll': 1767, 'wanted': 1768, 'officially': 1769, 'hp': 1770, 'hewlett': 1771, 'nfl': 1772, 'xp': 1773, 'cleveland': 1774, 'island': 1775, 'madrid': 1776, 'singh': 1777, 'arrived': 1778, 'usatoday': 1779, 'par': 1780, 'unveils': 1781, 'throw': 1782, 'gone': 1783, 'prince': 1784, 'voip': 1785, 'nokia': 1786, 'seoul': 1787, 'ninth': 1788, 'career': 1789, 'gene': 1790, 'rare': 1791, 'rover': 1792, 'ii': 1793, 'adobe': 1794, 'taiwan': 1795, 'standing': 1796, 'inside': 1797, 'journalist': 1798, 'williams': 1799, 'blast': 1800, 'raid': 1801, 'specie': 1802, 'training': 1803, 'pas': 1804, 'commander': 1805, 'award': 1806, 'draft': 1807, 'el': 1808, 'historic': 1809, 'showdown': 1810, 'defensive': 1811, 'explosive': 1812, 'computing': 1813, 'abu': 1814, 'fighter': 1815, 'climate': 1816, 'olympic': 1817, 'lineup': 1818, 'democrat': 1819, 'nasa': 1820, 'spacecraft': 1821, 'trojan': 1822, 'earthquake': 1823, 'shuttle': 1824, 'father': 1825, 'explorer': 1826, 'firefox': 1827, 'solar': 1828, 'washingtonpost': 1829, 'hacker': 1830, 'assassination': 1831, 'remote': 1832, 'greek': 1833, 'dy': 1834, 'graphic': 1835, 'itunes': 1836, 'gunman': 1837, 'capable': 1838, 'platform': 1839, 'newsfactor': 1840, 'captain': 1841, 'cup': 1842, 'o': 1843, 'wild': 1844, 'saturn': 1845, 'bird': 1846, 'violent': 1847, 'spam': 1848, 'cassini': 1849, 'shark': 1850, 'parliament': 1851, 'msn': 1852, 'tiger': 1853, 'sp': 1854, 'assault': 1855, 'dna': 1856, 'playing': 1857, 'receiver': 1858, 'mozilla': 1859, 'girl': 1860, 'boy': 1861, 'planet': 1862, 'cub': 1863, 'mike': 1864, 'minute': 1865, 'arrest': 1866, 'diplomat': 1867, 'athlete': 1868, 'guy': 1869, 'blog': 1870, 'match': 1871, 'bryant': 1872, 'nba': 1873, 'thailand': 1874, 'seed': 1875, 'powell': 1876, 'ballot': 1877, 'yankee': 1878, 'beckham': 1879, 'football': 1880, 'hill': 1881, 'beslan': 1882, 'zimbabwe': 1883, 'baghdad': 1884, 'marine': 1885, 'soccer': 1886, 'contest': 1887, 'yard': 1888, 'arsenal': 1889, 'insurgent': 1890, 'holy': 1891, 'medal': 1892, 'atomic': 1893, 'explosion': 1894, 'meter': 1895, 'exploded': 1896, 'captured': 1897, 'english': 1898, 'dolphin': 1899, 'upset': 1900, 'rain': 1901, 'doping': 1902, 'congo': 1903, 'egyptian': 1904, 'sweep': 1905, 'tennis': 1906, 'championship': 1907, 'tournament': 1908, 'greece': 1909, 'golf': 1910, 'aide': 1911, 'jackson': 1912, 'darfur': 1913, 'nascar': 1914, 'pittsburgh': 1915, 'colin': 1916, 'scored': 1917, 'hockey': 1918, 'torn': 1919, 'knee': 1920, 'coach': 1921, 'trophy': 1922, 'basketball': 1923, 'inning': 1924, 'cricket': 1925, 'angel': 1926, 'injured': 1927, 'rookie': 1928, 'newcastle': 1929, 'nl': 1930, 'pedro': 1931, 'mets': 1932, 'martinez': 1933, 'pitcher': 1934, 'silver': 1935, 'homer': 1936, 'opener': 1937, 'astros': 1938, 'roger': 1939, 'nhl': 1940, 'quarterback': 1941, 'chelsea': 1942, 'jay': 1943, 'patriot': 1944, 'hewitt': 1945, 'semifinal': 1946, 'pacer': 1947, 'colt': 1948, 'striker': 1949, 'premiership': 1950, 'scoring': 1951, 'touchdown': 1952, 'prix': 1953, 'notre': 1954, 'dame': 1955, 'playoff': 1956, 'mauresmo': 1957, 'ichiro': 1958, 'embassy': 1959, 'jason': 1960, 'hamm': 1961, 'pakistan': 1962, 'qualifying': 1963, 'mariner': 1964, 'jacques': 1965, 'schilling': 1966, 'manning': 1967, 'redskin': 1968, 'brave': 1969, 'federer': 1970, 'egypt': 1971, 'arab': 1972, 'ukraine': 1973, 'sri': 1974, 'kidnapper': 1975, 'bomber': 1976, 'hostage': 1977, 'islamic': 1978, 'muslim': 1979, 'murder': 1980, 'missile': 1981, 'bin': 1982, 'kidnapped': 1983, 'coup': 1984, 'sharon': 1985, 'jerusalem': 1986, 'ariel': 1987, 'hamas': 1988, 'kabul': 1989, 'afghanistan': 1990, 'afghan': 1991, 'refugee': 1992, 'sudanese': 1993, 'sudan': 1994, 'uranium': 1995, 'arafat': 1996, 'yasser': 1997, 'bombing': 1998, 'cleric': 1999, 'militant': 2000, 'fallujah': 2001, 'prisoner': 2002, 'musharraf': 2003, 'hamid': 2004, 'karzai': 2005, 'sadr': 2006, 'mosque': 2007, 'wounding': 2008, 'qaeda': 2009, 'haiti': 2010, 'pakistani': 2011, 'kashmir': 2012, 'shiite': 2013}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.news_vocab._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.category_vocab._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._max_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_for_fine_tune(embedding_size, num_channels, hidden_dim, dropout_p, pretrained_embeddings, emb_freeze, batch_size):\n",
    "    set_seed_everywhere(args.seed, args.cuda, args.mps)\n",
    "    \n",
    "    args.batch_size = batch_size\n",
    "    classifier = NewsClassifier(embedding_size=embedding_size,          # e.g, 100\n",
    "                                num_embeddings=len(vectorizer.news_vocab),  # e.g., 3409\n",
    "                                num_channels=num_channels,              # e.g., 100\n",
    "                                hidden_dim=args.hidden_dim,                  # e.g., 100\n",
    "                                num_classes=len(vectorizer.category_vocab),  # e.g., 4\n",
    "                                dropout_p=dropout_p,                    # e.g., 0.1\n",
    "                                pretrained_embeddings=pretrained_embeddings,\n",
    "                                padding_idx=0,\n",
    "                                emb_freeze=emb_freeze)\n",
    "    \n",
    "    if pretrained_embeddings is None:\n",
    "        is_pretrained_embeddings = False\n",
    "    else:\n",
    "        is_pretrained_embeddings = True\n",
    "        \n",
    "    classifier = classifier.to(args.device)\n",
    "    dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "        \n",
    "    loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "    train_state = make_train_state(args)\n",
    "\n",
    "    epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "    dataset.set_split('train')\n",
    "    train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "    dataset.set_split('val')\n",
    "    val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "    try:\n",
    "        for epoch_index in range(args.num_epochs):\n",
    "            train_state['epoch_index'] = epoch_index\n",
    "\n",
    "            # Iterate over training dataset\n",
    "\n",
    "            # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "\n",
    "            dataset.set_split('train')\n",
    "            batch_generator = generate_batches(dataset, \n",
    "                                            batch_size=args.batch_size, \n",
    "                                            device=args.device)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            classifier.train()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "                # the training routine is these 5 steps:\n",
    "\n",
    "                # --------------------------------------\n",
    "                # step 1. zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # step 2. compute the output\n",
    "                y_pred = classifier(batch_dict['x_data']) # (batch, seq_len) -> (batch, num_classes)\n",
    "\n",
    "                # step 3. compute the loss\n",
    "                loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "                loss_t = loss.item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # step 4. use loss to produce gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # step 5. use optimizer to take gradient step\n",
    "                optimizer.step()\n",
    "                # -----------------------------------------\n",
    "                # compute the accuracy\n",
    "                acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "                # update bar\n",
    "                train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                   epoch=epoch_index)\n",
    "                train_bar.update()\n",
    "\n",
    "            train_state['train_loss'].append(running_loss)\n",
    "            train_state['train_acc'].append(running_acc)\n",
    "\n",
    "            # Iterate over val dataset\n",
    "\n",
    "            # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "            dataset.set_split('val')\n",
    "            batch_generator = generate_batches(dataset, \n",
    "                                            batch_size=args.batch_size, \n",
    "                                            device=args.device)\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "            classifier.eval()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "                # compute the output\n",
    "                y_pred =  classifier(batch_dict['x_data'])\n",
    "\n",
    "                # step 3. compute the loss\n",
    "                loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "                loss_t = loss.item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # compute the accuracy\n",
    "                acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "                val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                epoch=epoch_index)\n",
    "                val_bar.update()\n",
    "\n",
    "            train_state['val_loss'].append(running_loss)\n",
    "            train_state['val_acc'].append(running_acc)\n",
    "\n",
    "            train_state = update_train_state(args=args, model=classifier,\n",
    "                                            train_state=train_state)\n",
    "\n",
    "            scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "            if train_state['stop_early']:\n",
    "                break\n",
    "\n",
    "            train_bar.n = 0\n",
    "            val_bar.n = 0\n",
    "            epoch_bar.update()\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Exiting loop\")\n",
    "\n",
    "    acc = train_state['train_acc']\n",
    "    val_acc = train_state['val_acc']\n",
    "    loss = train_state['train_loss']\n",
    "    val_loss = train_state['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    # compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "    classifier.load_state_dict(torch.load(train_state['model_filename'])) # load the best model\n",
    "\n",
    "    classifier = classifier.to(args.device)\n",
    "    dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "    dataset.set_split('test')\n",
    "    batch_generator = generate_batches(dataset, \n",
    "                                    batch_size=args.batch_size, \n",
    "                                    device=args.device)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    classifier.eval()\n",
    "\n",
    "    y_pred_list = []         # store predicted values for confusion matrix\n",
    "    y_category_list = []  # ground truth value\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # compute the output\n",
    "        y_pred =  classifier(batch_dict['x_data'])\n",
    "        \n",
    "        # store predicted values and ground truth values for calculating confusion matrix\n",
    "        y_pred_list.extend(y_pred.max(dim=1)[1].cpu().numpy())\n",
    "        y_category_list.extend(batch_dict['y_target'].cpu().numpy())\n",
    "        \n",
    "        # compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        # compute the accuracy\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "    train_state['test_loss'] = running_loss\n",
    "    train_state['test_acc'] = running_acc\n",
    "    \n",
    "    set_seed_everywhere(args.seed, args.cuda, args.mps)\n",
    "    \n",
    "    return [embedding_size, num_channels, hidden_dim, dropout_p, is_pretrained_embeddings, emb_freeze, batch_size, train_state['val_loss'][-1], train_state['val_acc'][-1], train_state['test_loss'], train_state['test_acc']]\n",
    "\n",
    "def simple_grid_search(embedding_size_values, num_channels_values, hidden_dim_values, dropout_p_values, batch_size_values, pretrained_embeddings_values, emb_freeze_values):    \n",
    "    print(\"embedding_size_values:\", embedding_size_values)\n",
    "    print(\"num_channels_values:\", num_channels_values)\n",
    "    print(\"hidden_dim_values:\", hidden_dim_values)\n",
    "    print(\"dropout_p_values:\", dropout_p_values)\n",
    "    print(\"batch_size_values: \", batch_size_values)\n",
    "    \n",
    "    best_by_val_loss = []\n",
    "    best_by_val_acc = []\n",
    "    best_by_test_loss = []\n",
    "    best_by_test_acc = []\n",
    "    \n",
    "    log_path = 'Log_CNN_News_Category.txt'\n",
    "    if os.path.exists(log_path):\n",
    "        os.remove(log_path)\n",
    "        \n",
    "    with open(log_path, 'a') as log:\n",
    "        for pretrained_embeddings_value in pretrained_embeddings_values:\n",
    "            if pretrained_embeddings_value is not None:\n",
    "                print(\"------------Use Pretrain------------\")\n",
    "                log.write(\"------------Use Pretrain------------\\n\")\n",
    "                for emb_freeze_value in emb_freeze_values:\n",
    "                    for num_channels_value in num_channels_values:  \n",
    "                        for hidden_dim_value in hidden_dim_values:\n",
    "                            for dropout_p_value in dropout_p_values:\n",
    "                                for batch_size_value in batch_size_values:\n",
    "                                    print(f\"------args-----\\nnum_channels: {num_channels_value} | hidden_dim: {hidden_dim_value} | dropout_p: {dropout_p_value} | batch_size: {batch_size_value} | emb_freeze: {emb_freeze_value}\")\n",
    "                                    log.write(f\"------args-----\\nnum_channels: {num_channels_value} | hidden_dim: {hidden_dim_value} | dropout_p: {dropout_p_value} | batch_size: {batch_size_value} | emb_freeze: {emb_freeze_value}\\n\")\n",
    "                                    start_time = time.time()\n",
    "                                    result = train_for_fine_tune(100, num_channels_value, hidden_dim_value, dropout_p_value, pretrained_embeddings_value, emb_freeze_value, batch_size_value)\n",
    "                                    end_time = time.time()\n",
    "                                    torch.cuda.empty_cache()\n",
    "                                    if best_by_val_loss == [] or best_by_val_loss[7] > result[7]:\n",
    "                                        best_by_val_loss = result\n",
    "                                    if best_by_val_acc == [] or best_by_val_acc[8] < result[8]:\n",
    "                                        best_by_val_acc = result\n",
    "                                    if best_by_test_loss == [] or best_by_test_loss[9] > result[9]:\n",
    "                                        best_by_test_loss = result\n",
    "                                    if best_by_test_acc == [] or best_by_test_acc[10] < result[10]:\n",
    "                                        best_by_test_acc = result\n",
    "                                    elapsed_time = end_time - start_time\n",
    "                                    print(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\")\n",
    "                                    print(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\")\n",
    "                                    log.write(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\\n\")\n",
    "                                    log.write(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\\n\")\n",
    "            else:\n",
    "                print(\"------Not Use Pretrain------\")\n",
    "                log.write(\"------------Not Use Pretrain------------\\n\")\n",
    "                for embedding_size_value in embedding_size_values:\n",
    "                    for hidden_dim_value in hidden_dim_values:\n",
    "                        for num_channels_value in num_channels_values:  \n",
    "                            for hidden_dim_value in hidden_dim_values:\n",
    "                                for dropout_p_value in dropout_p_values:\n",
    "                                    for batch_size_value in batch_size_values:\n",
    "                                        print(f\"------args-----\\nembedding_size: {embedding_size_value} | num_channels: {num_channels_value} | hidden_dim: {hidden_dim_value} | dropout_p: {dropout_p_value} | batch_size: {batch_size_value}\")\n",
    "                                        log.write(f\"------args-----\\nembedding_size: {embedding_size_value} | num_channels: {num_channels_value} | hidden_dim: {hidden_dim_value} | dropout_p: {dropout_p_value} | batch_size: {batch_size_value}\")\n",
    "                                        start_time = time.time()\n",
    "                                        result = train_for_fine_tune(embedding_size_value, num_channels_value, hidden_dim_value, dropout_p_value, pretrained_embeddings_value, True, batch_size_value)\n",
    "                                        end_time = time.time()\n",
    "                                        torch.cuda.empty_cache()\n",
    "                                        if best_by_val_loss == [] or best_by_val_loss[7] > result[7]:\n",
    "                                            best_by_val_loss = result\n",
    "                                        if best_by_val_acc == [] or best_by_val_acc[8] < result[8]:\n",
    "                                            best_by_val_acc = result\n",
    "                                        if best_by_test_loss == [] or best_by_test_loss[9] > result[9]:\n",
    "                                            best_by_test_loss = result\n",
    "                                        if best_by_test_acc == [] or best_by_test_acc[10] < result[10]:\n",
    "                                            best_by_test_acc = result\n",
    "                                        elapsed_time = end_time - start_time\n",
    "                                        print(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\")\n",
    "                                        print(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\")\n",
    "                                        log.write(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\\n\")\n",
    "                                        log.write(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\\n\")\n",
    "                                                                  \n",
    "        print(\"--------------Best Val Loss--------------\")\n",
    "        print(f\"embedding_size: {best_by_val_loss[0]}\\nnum_channels: {best_by_val_loss[1]}\\nhidden_dim: {best_by_val_loss[2]}\\ndropout_p: {best_by_val_loss[3]}\\nis_pretrained_embeddings: {best_by_val_loss[4]}\\nemb_freeze: {best_by_val_loss[5]}\\nbatch_size: {best_by_val_loss[6]}\\n\")\n",
    "        \n",
    "        print(\"--------------Best Val Acc--------------\")\n",
    "        print(f\"embedding_size: {best_by_val_acc[0]}\\nnum_channels: {best_by_val_acc[1]}\\nhidden_dim: {best_by_val_acc[2]}\\ndropout_p: {best_by_val_acc[3]}\\nis_pretrained_embeddings: {best_by_val_acc[4]}\\nemb_freeze: {best_by_val_acc[5]}\\nbatch_size: {best_by_val_acc[6]}\\n\")\n",
    "        \n",
    "        print(\"--------------Best Test Loss--------------\")\n",
    "        print(f\"embedding_size: {best_by_test_loss[0]}\\nnum_channels: {best_by_test_loss[1]}\\nhidden_dim: {best_by_test_loss[2]}\\ndropout_p: {best_by_test_loss[3]}\\nis_pretrained_embeddings: {best_by_test_loss[4]}\\nemb_freeze: {best_by_test_loss[5]}\\nbatch_size: {best_by_test_loss[6]}\\n\")\n",
    "        \n",
    "        print(\"--------------Best Test Acc--------------\")\n",
    "        print(f\"embedding_size: {best_by_test_acc[0]}\\nnum_channels: {best_by_test_acc[1]}\\nhidden_dim: {best_by_test_acc[2]}\\ndropout_p: {best_by_test_acc[3]}\\nis_pretrained_embeddings: {best_by_test_acc[4]}\\nemb_freeze: {best_by_test_acc[5]}\\nbatch_size: {best_by_test_acc[6]}\\n\")\n",
    "\n",
    "        log.write(\"--------------Best Val Loss--------------\\n\")\n",
    "        log.write(f\"embedding_size: {best_by_val_loss[0]}\\nnum_channels: {best_by_val_loss[1]}\\nhidden_dim: {best_by_val_loss[2]}\\ndropout_p: {best_by_val_loss[3]}\\nis_pretrained_embeddings: {best_by_val_loss[4]}\\nemb_freeze: {best_by_val_loss[5]}\\nbatch_size: {best_by_val_loss[6]}\\n\\n\")\n",
    "        \n",
    "        log.write(\"--------------Best Val Acc--------------\\n\")\n",
    "        log.write(f\"embedding_size: {best_by_val_acc[0]}\\nnum_channels: {best_by_val_acc[1]}\\nhidden_dim: {best_by_val_acc[2]}\\ndropout_p: {best_by_val_acc[3]}\\nis_pretrained_embeddings: {best_by_val_acc[4]}\\nemb_freeze: {best_by_val_acc[5]}\\nbatch_size: {best_by_val_acc[6]}\\n\\n\")\n",
    "        \n",
    "        log.write(\"--------------Best Test Loss--------------\\n\")\n",
    "        log.write(f\"embedding_size: {best_by_test_loss[0]}\\nnum_channels: {best_by_test_loss[1]}\\nhidden_dim: {best_by_test_loss[2]}\\ndropout_p: {best_by_test_loss[3]}\\nis_pretrained_embeddings: {best_by_test_loss[4]}\\nemb_freeze: {best_by_test_loss[5]}\\nbatch_size: {best_by_test_loss[6]}\\n\\n\")\n",
    "        \n",
    "        log.write(\"--------------Best Test Acc--------------\\n\")\n",
    "        log.write(f\"embedding_size: {best_by_test_acc[0]}\\nnum_channels: {best_by_test_acc[1]}\\nhidden_dim: {best_by_test_acc[2]}\\ndropout_p: {best_by_test_acc[3]}\\nis_pretrained_embeddings: {best_by_test_acc[4]}\\nemb_freeze: {best_by_test_acc[5]}\\nbatch_size: {best_by_test_acc[6]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_size_values: [100, 200]\n",
      "num_channels_values: [100, 200]\n",
      "hidden_dim_values: [64, 128]\n",
      "dropout_p_values: [0.1, 0.2]\n",
      "batch_size_values:  [64, 128]\n",
      "------Not Use Pretrain------\n",
      "------args-----\n",
      "embedding_size: 100 | num_channels: 100 | hidden_dim: 64 | dropout_p: 0.1 | batch_size: 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efefc9d341546189462e7ced28e66b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a965ff0b45154926a3e0205ffcfa17c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f645d9914582486289ce4525d40b706d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting loop\n",
      "------perf.-----\n",
      "val_loss: 0.5692976502811208 | val_acc: 80.00919117647061\n",
      "test_loss: 0.5588167704203549 | test_acc: 80.97426470588236\n",
      "took 26.36 seconds.\n",
      "best by va_loss: [100, 100, 64, 0.1, False, True, 64] | best by va_acc: [100, 100, 64, 0.1, False, True, 64]\n",
      "best by te_loss: [100, 100, 64, 0.1, False, True, 64] | best by te_acc: [100, 100, 64, 0.1, False, True, 64]\n",
      "\n",
      "------args-----\n",
      "embedding_size: 100 | num_channels: 100 | hidden_dim: 64 | dropout_p: 0.1 | batch_size: 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df0982cb9a74843a13e7a46b410dab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5b17339b154c4580fe1d0df4aaf996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a370afe420446858c720e7aa2aca81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_size_values = [i for i in range(64, 161, 32)]\n",
    "num_channels_values = [i for i in range(50, 201, 50)]\n",
    "dropout_p_values = [0.2, 0.5]\n",
    "hidden_dim_values = [i for i in range(64, 513, 64)]\n",
    "batch_size_values = [i for i in range(64, 193, 32)]\n",
    "pretrained_embeddings_values = [embeddings, None]\n",
    "emb_freeze_values = [True, False]\n",
    "\n",
    "simple_grid_search(embedding_size_values, num_channels_values, hidden_dim_values, dropout_p_values, batch_size_values, pretrained_embeddings_values, emb_freeze_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.embedding_size=100\n",
    "args.num_channels=128\n",
    "args.hidden_dim=4\n",
    "args.dropout_p=0.1\n",
    "args.use_glove=True\n",
    "args.emb_freeze=False\n",
    "args.batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GloVe or randomly initialized embeddings\n",
    "set_seed_everywhere(args.seed, args.cuda, args.mps)\n",
    "\n",
    "if args.use_glove:\n",
    "    words = vectorizer.news_vocab._token_to_idx.keys()  # 3409 unique words\n",
    "    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath,     # embeddings: (3409, 100)\n",
    "                                       words=words)\n",
    "    print(\"Using pre-trained embeddings\")\n",
    "else:\n",
    "    print(\"Not using pre-trained embeddings\")\n",
    "    embeddings = None\n",
    "    \n",
    "classifier = NewsClassifier(embedding_size=args.embedding_size,          # e.g, 100\n",
    "                            num_embeddings=len(vectorizer.news_vocab),  # e.g., 3409\n",
    "                            num_channels=args.num_channels,              # e.g., 100\n",
    "                            hidden_dim=args.hidden_dim,                  # e.g., 100\n",
    "                            num_classes=len(vectorizer.category_vocab),  # e.g., 4\n",
    "                            dropout_p=args.dropout_p,                    # e.g., 0.1\n",
    "                            pretrained_embeddings=embeddings,\n",
    "                            padding_idx=0,\n",
    "                            emb_freeze=args.emb_freeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f674c91b4ede4d238e71cd7233286276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5402c583b9014740a6b7b47b1bcf11e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e17eb53e0e4f318a1947873419b8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed_everywhere(args.seed, args.cuda, args.mps)\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------\n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(batch_dict['x_data']) # (batch, seq_len) -> (batch, num_classes)\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                  epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "            # compute the output\n",
    "            y_pred =  classifier(batch_dict['x_data'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "set_seed_everywhere(args.seed, args.cuda, args.mps)\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename'])) # load the best model\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_category_list = []  # ground truth value\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_data'])\n",
    "    \n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_list.extend(y_pred.max(dim=1)[1].cpu().numpy())\n",
    "    y_category_list.extend(batch_dict['y_target'].cpu().numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.24122860814843858;\n",
      "Test Accuracy: 92.07589285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FAKE', 'REAL']\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "for i in range(len(dataset._vectorizer.category_vocab)):\n",
    "    classes.append(dataset._vectorizer.category_vocab.lookup_index(i))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True       FAKE  REAL\n",
      "Predicted            \n",
      "FAKE        426    48\n",
      "REAL         23   399\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_category_list, y_pred_list)\n",
    "cm_df = pd.DataFrame(cm.T, index=classes, columns=classes)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       449\n",
      "           1       0.95      0.89      0.92       447\n",
      "\n",
      "    accuracy                           0.92       896\n",
      "   macro avg       0.92      0.92      0.92       896\n",
      "weighted avg       0.92      0.92      0.92       896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_category_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the reviews\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(title, classifier, vectorizer, max_length):\n",
    "    \"\"\"Predict a News category for a new title\n",
    "    \n",
    "    Args:\n",
    "        title (str): a raw title string\n",
    "        classifier (NewsClassifier): an instance of the trained classifier\n",
    "        vectorizer (NewsVectorizer): the corresponding vectorizer\n",
    "        max_length (int): the max sequence length\n",
    "            Note: CNNs are sensitive to the input data tensor size. \n",
    "                  This ensures to keep it the same size as the training data\n",
    "    \"\"\"\n",
    "    title = preprocess_text(title)\n",
    "    vectorized_title = \\\n",
    "        torch.tensor(vectorizer.vectorize(title, vector_length=max_length))\n",
    "    result = classifier(vectorized_title.unsqueeze(0), apply_softmax=True)\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    predicted_category = vectorizer.category_vocab.lookup_index(indices.item())\n",
    "\n",
    "    return {'category': predicted_category, \n",
    "            'probability': probability_values.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples():\n",
    "    samples = {}\n",
    "    for cat in dataset.val_df.category.unique():\n",
    "        samples[cat] = dataset.val_df.text[dataset.val_df.category==cat].tolist()[:5]\n",
    "    return samples\n",
    "\n",
    "val_samples = get_samples() # first 5 titles of each category from validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Category: FAKE\n",
      "==============================\n",
      "Prediction: FAKE (p=1.00)\n",
      "\t + Sample: hillary clinton postapocalyptic hellscape plan hillary clinton postapocalyptic hellscape plan important avoid age peace hillary clinton postapocalyptic hellscape plan b look email even com wrong comdingdangaramaramaflimflam mail question comment site godlike production glp registered trademark zero point ltd godlike website design copyright godlikeproductions com page generated query\n",
      "Prediction: FAKE (p=1.00)\n",
      "\t + Sample: russophobia war party propaganda information russophobia war party propaganda world reactionary regime head chopping terror sponsoring saudi arabian kleptocracy awarded chair un human right council russia kicked travesty engineered superpower lie punish moscow resisting u led war sectarian massacre regime change syria war party march cheer corporate medium hillary even elected yet margaret kimberley attempt stop fighting rejected u nato sealed fate syrian people november information clearing house bar russia invade iraq kill one million people russia greater percentage population behind bar country world russia occupy haiti kidnapping president russian police allowed shoot child death without fear repercussion russia entering th year terror war people somalia crime take place direction united state yet full force propaganda influence world opinion directed russia whatever shortcoming hold candle america violating human right danger presented hillary clinton presidency overstated war party steadily working towards goal defies logic risk life earth regime change modus operandi hope make reality russia nearly every claim russian evil lie ruse meant put american fighting mood lose fear nuclear conflagration clear clinton rest would warrior actually realize risking mushroom cloud perhaps believe vladimir putin easily pushed around evidence point contrary unproven allegation interference presidential election casting blame russia sole cause suffering syria meant desensitize public age old ploy make war acceptable deemed necessity usual suspect helping eagerly corporate medium led newspaper like new york time washington post front center pushing tale russian villainy human right watch organization care nothing abuse committed united state ally also playing usual role choosing next regime change victim russia lost seat united nation human right council part american pressure public relation assistance human right industrial complex unhrc chaired saudi arabia saudi arabia absolute monarchy fund jihadist terrorist group caused syrian death saudi causing dislocation death starvation yemen american ally little opposition misdeed openly bigoted donald trump perfect foil hillary clinton rest democratic party leadership preferred rival made case discredited lesser evilism argument sensible statement avoiding enmity russia made even useful united state ally cause syria destruction effort overthrow president assad created humanitarian disaster complete isi al nusra fighter love chop head entertainment far cause catastrophe russia left ally fight alone four year even made overture negotiate assad fate united state attempt stop fighting rejected u nato sealed fate syrian people people east aleppo shelled american ally one know reading pass journalism newspaper television american role slaughter barely mentioned excused effort protect civilian population bloodshed made u could end government wanted anti russian propaganda effort worked perfection nato massing troop russia border clear provocation yet putin labeled bad guy said menacing country join threatening nation united state make phony claim russian war crime despite blood hand latest human right watch canard prosecuting assad come straight white house state department nothing concern syrian living fifth year hell lesser evil hillary clinton donald trump fully supported war party desire muscular foreign policy bizarre term mean death starvation million people clinton win landslide must denied victory magnitude opportunity claim mandate peace loving people must give vote green party ticket jill stein ajamu baraka alone rejecting premise imperialist country endless war united state dangerous country world reckless war loving president threat becomes existential prospect face hillary clinton presidency role villain cast world stage star show margaret kimberley freedom rider column appears weekly bar widely reprinted elsewhere maintains frequently updated blog well m kimberley life new york city reached via e mail margaret kimberley blackagendareport com russia kill civilian u promotes democracy washington mantra domestic consumption\n",
      "Prediction: FAKE (p=0.99)\n",
      "\t + Sample: world champion boxer manny pacquiao build home poor filipino earning million fighting floyd mayweather boxer politician used portion earnings construct home poor family hometown manny pacquiao world class athlete filipino politician compassionate activist paid home built help underprivileged family hometown via anonews earlier year pacquiao proclaimed good deed facebook happy giving house free constituent sarangani province pocket thousand family beneficiary star report born christian inspired help poor family duking floyd mayweather though lost boxing match still earned million dollar fight century felt duty give back wrote faithful steward god grace various form use whatever gift received serve others still building always believe bible say offer hospitality one another without grumbling act compassion could nothing calculated political move nonetheless family secure living space thanks senator generosity believe worth celebrating\n",
      "Prediction: FAKE (p=0.58)\n",
      "\t + Sample: hillary era coming worry photo veni cc trust one noticed rural area economically distressed neighborhood town city lawn sign donald trump everywhere hillary sign rarer tesla maseratis think understand trump sign cry defiance hillary supporter harder figure suspect would soon advertise intention november even think way stop trump understand voting hillary embarrassing lawn sign apart evidence trump kaput overwhelming seems finally done campaign extent even diehard anti trump fear monger concede inevitability clinton return white house trump campaign life support week pussy grabbing tape surfaced followed seemingly endless stream woman dozen already accusing donald groping worse third debate trump announced would wait see accepting legitimacy clinton victory seems final straw bona fide deplorables writing wall hillary win surely sun rise tomorrow well quite almost reason rejoice victory trump defeat even obvious seems hillary probably lesser evil thing considered trump likely le dangerous two man adolescent septuagenarian body tendency act least russophobe neocon humanitarian intervener intent regime change country resist american domination would include usual victim country incapable harming united state militarily russia china well relevant supposed lesser evil committed neoliberal wall street toady trump crooked hillary taunt hit target often consideration others like cause concern fine lesser evil voting general think threshold beneath lesser evil consideration apply need agonize issue however case trump became republican nominee lesser evil argument became moot would still case even voter quite willfully blind danger inherent clinton determination maintain american world domination mean necessary fondness military solution lesser evil consideration irrelevant trump always bound lose democrat even pressing point corollary anti trump hysteria distraction day one recently month ago hardly anyone agreed dollar every time taken task seeing parallel trump phenomenon rise nazism final year weimar republic would rich man today recognized trump chance becoming president practical purpose nil one pressing line day used limb longer would natural take pleasure turn event would fact trump defeat implies clinton victory prospect best slightly le nightmarish worse seem matter flagrant worrywart finally concede never president trump liberal centrist even foolish leftist still going hillary dead center soft left consensus view still time boost knock hillary campaign especially dozen state electoral college outcome could determined year ago absolute certainty remarkable many people let anti trump hysteria go focused trump misogyny temperamental instability narcissistic blather see thing need fear trump concerned speak fear however hillary case really something fear become commander chief lethal military force history world point supporter denial even people know better support sake remain determined waste vote adding total apparently think way send message trumpian fascism shall pas much better would would use vote build alternative neoliberal perpetual war regime hillary bill co thinker helped fashion best chance point jill stein campaign green party ticket stein win course vote protest vote nothing wrong hillary need know mandate end world know one many way convey message pundit claim otherwise dead wrong pile hillary wasting vote protest vote aimed hillary wasted would imagine least trump voter thinking along similar line racism nativism islamophobia candidate tarnish message vote convey therefore register real clarity message protest vote stein convey hand clear distinct garner least five percent total vote cast green access federal funding future election much easier time gaining ballot access fifty state would make much political revolution even bernie sander highly attenuated sense term would make future election le mind numbing degrading could ultimately lead far reaching transformation political scene trump killed gop duopoly party system jeopardy kind political realignments last become feasible contrarian went limb trump chance confidence way based inference polling data statistical extrapolation let blogosphere political junky corporate medium talking head knock useful entertaining people care horse race aspect presidential election distressing many american indulge spectator sport essentially apolitical confident right trump chance knew people tell pollster election seems far basically irrelevant predicting election outcome information people like voted past relevant much especially true case disdain one candidate dispositive factor many voter mind also fairly sure rightly wrongly people fear loathe trump fear loathe hillary outset would long trump certain undermine much dirt donald sleazy connection moral turpitude even god fearing republican capable believing almost nonsense bound eventually repulsed suspected trump never really wanted president got race promote brand egotist publicity hound trump hate lose however especially like hillary point must decided give campaign even meant bringing trump brand come shed crocodile tear brood ivanka especially worthwhile thing month ahead would work make happen everything possible assure damage done thing trump irreversible delightful irony would plenty hillary hater donald base hate hillary consider embodiment coercive goody goodyism think disdainful people like people deplorables demographic think leftwing idea leftwing nonsense course nearly leftwing enough anyone would think otherwise testament medium ability shape public perception degree political ignorance rampant quarter american electorate vast rightwing conspiracy hillary hater spot right rest two three bad even better reason dread prospect clinton presidency service hillary done go miscreant control commanding height america world capitalist order untrammeled ideologically driven bellicosity hillary know game system bill know benefit vaunted experience clueless world although fan boast pragmatism woman seriously inept undertakes ill conceived nearly turn badly short lesser evil great evil indeed take long move back white house start putting stamp empire depredation scale fall eye gullible supporter even sure trump defeat take even le joy proved right lie ahead hillary control horrible contemplate join debate facebook andrew levine senior scholar institute policy study author recently american ideology routledge political key word blackwell well many book article political philosophy recent book bad faith wrong opium people professor philosophy university wisconsin madison research professor philosophy university maryland college park contributor hopeless barack obama politics illusion ak press\n",
      "Prediction: FAKE (p=1.00)\n",
      "\t + Sample: connect series webinar oct financial market news cover dominating theme market share pattern analysis perspective empower member make better investment decision\n",
      "------------------------------\n",
      "\n",
      "True Category: REAL\n",
      "==============================\n",
      "Prediction: FAKE (p=0.89)\n",
      "\t + Sample: common core quietly war argentine president mauricio macri office rebutting report argentinian journalist set wave american medium\n",
      "Prediction: REAL (p=1.00)\n",
      "\t + Sample: u face call walk away iran talk leading republican critic iranian nuclear talk calling u walk away table negotiator missed key deadline lawmaker joined voicing concern iran could extract critical final hour concession scramble salvage agreement negotiation resumed switzerland wednesday almost immediately beset competing claim hour diplomat abandoned march deadline reach outline deal agreed press latest round hit week mark three six foreign minister involved left talk prospect agreement remaining uncertain amid confusion sen tom cotton r ark told fox news concerned framework deal could allow iran keep uranium stockpile continue enrich uranium underground bunker willing walk away table reapply leverage iran cotton said fact willing still sitting switzerland negotiating three negotiating partner already left demonstrates iran continue demand dangerous concession west speaking msnbc former democratic presidential candidate howard dean seemed agree said president obama right seek deal might time step away table make clear u backing key position including iran uranium stockpile pace sanction relief worried dean said rep martha mcsally r ariz also told fox news potentially nuclear infrastructure added know exactly behind closed door despite side agreeing blow deadline pursuit rough agreement even white house threatened abandon talk iran budge unwilling make kind commitment give u assurance u mean united state mean international community walk away negotiating table consider option may available u certainly possibility could happen white house press secretary josh earnest said tuesday earnest indicated wednesday still option called scenario hypothetical talk making progress said talk continue productive yet received specific tangible commitment international community require tuesday negotiator trying agree simply joint statement could justify talk continuing final june deadline iran deputy foreign minister abbas araghchi told reporter side make progress text joint statement could issued end day suggested statement would contain specific senior western official quickly pushed back saying nothing statement decided iran negotiating partner would accept document contained detail german foreign ministry tweeted nothing agreed although progress visible araghchi named difference sanction relief country one dispute along dispute iran uranium enrichment related research development definitely research development program high end centrifuge continue told iranian television u negotiating partner want crimp iranian effort improve performance centrifuge enrich uranium advancing technology could let iran produce material could used arm nuclear weapon much quickly present exchange reflected significant gap side came shortly end first post deadline meeting u secretary state john kerry british german counterpart iranian foreign minister mohammed javad zarif swiss town lausanne team continuing marathon effort bridge still significant gap hammer framework accord would serve basis final agreement end june eager avoid collapse discussion united state others claimed late tuesday enough progress made warrant extension six day intense bartering foreign minister china france russia departed lausanne overnight although significance absence clear kerry postponed planned tuesday departure stay lausanne iranian negotiator said team would stay long necessary clear remaining hurdle official say intention produce joint statement outlining general political commitment resolving concern iran nuclear program exchange sanction relief addition trying fashion document would lay detail step must take june meet goal additional document would allow side make case next round talk simply continuation negotiation already twice extended since interim agreement iran united state russia china britain france germany concluded november obama leader including iran said interested third extension party agree broad framework leaf key detail unresolved obama expect stiff opposition home member congress want move forward new stiffer iran sanction lawmaker agreed hold measure march party negotiated white house say new sanction would scuttle diplomatic effort contain iran nuclear work possibly lead israel act threat use military force accomplish goal israeli prime minister benjamin netanyahu continued question course talk wednesday said iran view israel destruction non negotiable evidently giving iran murderous regime clear path bomb negotiable unconscionable said time iran accelerating campaign terror subjugation conquest throughout region recently yemen netanyahu said better deal would significantly roll back iran nuclear infrastructure link lifting restriction nuclear program change iran behavior associated press contributed report\n",
      "Prediction: FAKE (p=0.53)\n",
      "\t + Sample: gun control becomes litmus test democratic primary move would make easier trump administration demolish exchange\n",
      "Prediction: REAL (p=0.99)\n",
      "\t + Sample: house gop budget gimmick six men green tie took stage house television studio tuesday house budget committee chairman tom price slight leprechaun man silver hair dark eyebrow approached microphone good mor top mornin ya price announced happy st patrick day altogether fitting republican rolled budget festival inebriation honor man magically apocryphally banished snake ireland republican done budget le fantastic employed lucky charm mystical pot gold make appear sober balancing budget actually rely gimmick creative accounting trick balance budget house republican say introduction fiscal budget true budget rely gimmick budget gimmick pretend keep strict limit defense spending called sequestration pump ten billion extra dollar slush fund called overseas contingency operation mean fund count emergency spending part pentagon budget assumes current tax cut allowed expire scheduled would amount billion tax increase nobody belief would allowed go effect proposes repeal obamacare count revenue saving obamacare law remained effect claim save trillion year fine print budget plan instruction committee asks identify billion saving time assumes trillion cut category known mandatory program specify cut would relies billion additional revenue dynamic scoring generous accounting method account billion plan negotiated increase doctor payment medicare extend child health care program difficulty concealing sleight hand might explain price hurry leave news conference tuesday predecessor rep paul ryan r wi liked give lengthy seminar conservative budgeting theory price took question six minute aide hollered last question chairman gone minute later reporter gave chase leprechaun budget pas one asked think price said locating confidence sure absolutely latest instance republican discovering difficult govern unified control congress past four year budget debut academic exercise would never agreement republican house democratic senate budget might actually mean something firebrand elected past three election need show would handle country finance turn govern much like came legislative smoke mirror rep rob woodall r ga one stage observed folk playing opportunity first time short congressional career actually bring budget united state playing good verb occasion price georgia republican ran conservative republican study committee delivered long statement imparting assurance believe america least three time held page budget camera minute preamble questioning quickly got tricky price ask committee come billion saving floor ceiling price said adding something opportunity provide positive solution american people desire andy taylor associated press asked billion tax increase obamacare revenue assumed budget believe american people believe growth replied price predicting higher expected economic growth would boost tax revenue jonathan weisman new york time asked price would detail trillion mandatory cut budget identify take peek balanced budget stronger america price replied holding budget camera looking weisman said specify sort trick republican longer get away charge read dana milbank archive follow twitter subscribe update facebook\n",
      "Prediction: REAL (p=0.95)\n",
      "\t + Sample: identity isi terrorist known jihadi john reportedly revealed true identity isi terrorist known jihadi john appeared several video showing beheading hostage reportedly revealed washington post first reported thursday citing friend human right worker familiar case man real name mohammed emwazi west london man detained counterterror official britain least two u government source spoke reuters thursday said investigator believe man emwazi according washington post bbc emwazi born kuwait studied computer programming university westminster university confirmed student name graduated allegation true shocked sickened news university said statement emwazi also thought traveled syria sometime around bbc reported british intelligence previously identified man chosen disclose name operational reason commander richard walton london metropolitan police counter terrorism command released statement saying previously asked medium outlet speculate detail investigation basis life risk going confirm identity anyone stage give update progress live counter terrorism investigation london based cage work muslim conflict british intelligence service said thursday research director asim qureshi saw strong similarity emwazi jihadi john hood worn militant way could percent certain center study radicalization political violence king college london closely track fighter syria also said believed identification correct masked hooded terrorist achieved instant notoriety appeared video released isi last august showed beheading american journalist james foley time many commentator analyst remarked man distinct london accent man believed appeared video showed beheading hostage including american journalist steven sotloff british aid worker david haines british taxi driver alan henning american aid worker peter kassig known abdul rahman apparent conversion islam captivity man recent appearance came last month video japanese hostage kenji goto haruna yukawa men also killed terror group terrorist given nickname jihadi john interview former isi hostage revealed part group british jihadist guarded hostage dubbed beatles bbc reported emwazi believed associate known terror suspect traveled somalia allegedly linked funding network somali based militant group al shabaab cage said contact emwazi two year accused british intelligence service harassing said alleged british spy preventing traveling country birth kuwait planned marry one answered door brick row house west london emwazi family alleged lived neighbor surrounding area public housing project either declined comment said know family neighbor janine kintenda said lived area year shocked news oh god told associated press lifting hand mouth bad bad shiraz maher king college radicalization center said investigating whether emwazi among group young west londoner traveled syria many dead including mohammad el araj ibrahim al mazwagi choukri ellekhlifi killed said emwazi background similar british jihadis disproved idea guy impoverished coming deprived background large upwardly mobile people well educated said associated press contributed report\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#title = input(\"Enter a news title to classify: \")\n",
    "classifier = classifier.to(\"cpu\")\n",
    "\n",
    "for truth, sample_group in val_samples.items():\n",
    "    print(f\"True Category: {truth}\")\n",
    "    print(\"=\"*30)\n",
    "    for sample in sample_group:\n",
    "        prediction = predict_category(sample, classifier, \n",
    "                                      vectorizer, dataset._max_seq_length)\n",
    "        print(\"Prediction: {} (p={:0.2f})\".format(prediction['category'],\n",
    "                                                  prediction['probability']))\n",
    "        print(\"\\t + Sample: {}\".format(sample))\n",
    "    print(\"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise:\n",
    "\n",
    "1. Change F.max_pool1d() to F.avg_pool1d().\n",
    "2. Change use_glove=True to use_glove=False.\n",
    "3. Change other hyperparameters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": "5",
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
