{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN News Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords # remove stopword\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Vectorization classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "        \"\"\"\n",
    "\n",
    "        # news_vocab._token_to_idx: {'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'jobs': 4, 'tax': 5, 'cuts': 6,  \n",
    "        #                             ......, 'shiite': 3407, 'ghraib': 3408}\n",
    "        # category_vocab._token_to_idx: {'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}\n",
    "        \n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token             # for paddding, e.g., Wall St. Bears Claw Back Into the Black (Reuters)\n",
    "                                                  #               -> [2, 5, 6, 10, 10, 8, 7, 9, 19, ......., 3, 0, 0, 0, ..., 0]\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)            # mask_index is 0\n",
    "        self.unk_index = self.add_token(self._unk_token)              # unk_index is 1\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)  # begin_seq_index is 2\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)      # end_seq_index is 3\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
    "    def __init__(self, news_vocab, category_vocab):\n",
    "        self.news_vocab = news_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "\n",
    "    def vectorize(self, text, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text (str): the string of words separated by a space\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        Returns:\n",
    "            the vetorized text (numpy.array)\n",
    "        \"\"\"\n",
    "        \"\"\"    \n",
    "        mask_index is 0\n",
    "        unk_index is 1\n",
    "        begin_seq_index is 2\n",
    "        end_seq_index is 3\n",
    "        \n",
    "        When text is \"Wall St. Bears Claw Back Into the Black (Reuters)\"; max vector length is 29 in current dataset \n",
    "        \n",
    "        out_vector = [2, 5, 6, 10, 10, 8, 7, 9, 19, ......., 3, 0, 0, 0, ..., 0]\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        indices = [self.news_vocab.begin_seq_index]\n",
    "        indices.extend(self.news_vocab.lookup_token(token) \n",
    "                       for token in text.split(\" \"))\n",
    "        indices.append(self.news_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.news_vocab.mask_index\n",
    "\n",
    "        return out_vector\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, news_df, cutoff=25):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            news_df (pandas.DataFrame): the target dataset\n",
    "            cutoff (int): frequency threshold for including in Vocabulary \n",
    "        Returns:\n",
    "            an instance of the NewsVectorizer\n",
    "        \"\"\"\n",
    "        category_vocab = Vocabulary()        \n",
    "        for category in sorted(set(news_df.category)):\n",
    "            category_vocab.add_token(category)\n",
    "\n",
    "        word_counts = Counter()\n",
    "        for text in news_df.text:\n",
    "            for token in text.split(\" \"):\n",
    "                if token not in string.punctuation:\n",
    "                    word_counts[token] += 1\n",
    "        \n",
    "        news_vocab = SequenceVocabulary()\n",
    "        for word, word_count in word_counts.items():\n",
    "            if word_count >= cutoff:\n",
    "                news_vocab.add_token(word)\n",
    "        \n",
    "        return cls(news_vocab, category_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glaxo settle settle paxil paxil suicide suicide pill pill suit suit new new york york reuters reuters glaxosmithkline glaxosmithkline plc plc href href target target stock stock quickinfo quickinfo fullquote fullquote l l agreed agreed release release clinical clinical study study drug drug settle settle lawsuit lawsuit accused accused withholding withholding negative negative information information antidepressant antidepressant paxil paxil new new york york attorney attorney general general office office said said thursday'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_preprocessing(text):\n",
    "    text = text.lower() # case folding\n",
    "    text = re.sub('&\\w*\\;\\w*', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub(r\"[^a-z]+\", r\" \", text) # Regulation, remove special charecters\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    # remove stopwords and lemmatization\n",
    "    result = [lemmatizer.lemmatize(i) for i in tokens if not i in stop_words]\n",
    "    result = result[:500]\n",
    "    # bigram\n",
    "    bigram_result = []\n",
    "    bigram_list = ngrams(result,2)\n",
    "    for word_set in bigram_list:\n",
    "        for word in word_set:\n",
    "            bigram_result.append(word)\n",
    "    return bigram_result\n",
    "\n",
    "test_str_1 = \"This is sentence to test the effect of preprocessing... Yeah~\\nCool!fac  feae ge fe ga 🪣🛀🎀 ☏☢︎⏥␘⍎ (>╹ω╹<)喵\"\n",
    "test_str_2 = \"Glaxo Settles Paxil 'Suicide Pill' Suit.  NEW YORK (Reuters) - GlaxoSmithKline Plc &lt;A HREF=http://www.investor.reuters.com/FullQuote.aspx?ticker=GSK.L target=/stocks/quickinfo/fullquote\"\"&gt;GSK.L&lt;/A&gt; has agreed  to release all clinical studies of its drugs to settle a  lawsuit that accused it of withholding negative information  about the antidepressant Paxil, the New York Attorney General's  office said on Thursday.\"\n",
    "list = text_preprocessing(test_str_2)\n",
    "' '.join(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, news_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            news_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (NewsVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.news_df = news_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        # +1 if only using begin_seq, +2 if using both begin and end seq tokens\n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, news_df.text)) + 2\n",
    "        \n",
    "\n",
    "        self.train_df = self.news_df[self.news_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.news_df[self.news_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.news_df[self.news_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "        # Class weights\n",
    "        class_counts = news_df.category.value_counts().to_dict()\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.category_vocab.lookup_token(item[0])\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, news_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            surname_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of SurnameDataset\n",
    "        \"\"\"\n",
    "        news_df = pd.read_csv(news_csv)\n",
    "        \n",
    "        for index, text in enumerate(news_df.text):\n",
    "            processed_list = text_preprocessing(text)\n",
    "            news_df.text[index] = ' '.join(processed_list)\n",
    "\n",
    "        train_news_df = news_df[news_df.split=='train']\n",
    "        return cls(news_df, NewsVectorizer.from_dataframe(train_news_df))\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        news_vector = \\\n",
    "            self._vectorizer.vectorize(row.text, self._max_seq_length)\n",
    "\n",
    "        category_index = \\\n",
    "            self._vectorizer.category_vocab.lookup_token(row.category)\n",
    "\n",
    "        return {'x_data': news_vector,     # e.g., \"Wall St. Bears Claw Back Into the Black (Reuters)\" \n",
    "                                            # -> [2, 5, 6, 10, 10, 8, 7, 9, 19, ......., 3, 0, 0, 0, ..., 0]\n",
    "                'y_target': category_index} # e.g., 2\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model: NewsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "    def __init__(self, embedding_size, num_embeddings, num_channels, \n",
    "                 hidden_dim, num_classes, dropout_p, \n",
    "                 pretrained_embeddings=None, padding_idx=0, emb_freeze=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_size (int): size of the embedding vectors\n",
    "            num_embeddings (int): number of embedding vectors\n",
    "            filter_width (int): width of the convolutional kernels\n",
    "            num_channels (int): number of convolutional kernels per layer\n",
    "            hidden_dim (int): the size of the hidden dimension\n",
    "            num_classes (int): the number of classes in classification\n",
    "            dropout_p (float): a dropout parameter \n",
    "            pretrained_embeddings (numpy.array): previously trained word embeddings\n",
    "                default is None. If provided, \n",
    "            padding_idx (int): an index representing a null position\n",
    "        \"\"\"\n",
    "        super(NewsClassifier, self).__init__()\n",
    "        \n",
    "        if pretrained_embeddings is None:\n",
    "            self.emb = nn.Embedding(embedding_dim=embedding_size,   # 100\n",
    "                                    num_embeddings=num_embeddings,  # 3409\n",
    "                                    padding_idx=padding_idx)        \n",
    "            self.emb.weight.requires_grad = True\n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.emb = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=emb_freeze) # when freeze=True (default), \n",
    "                                                                           # the tensor does not get updated in the learning process\n",
    "                             \n",
    "        # in_channels: embedding_size; out_channels: # of filters; kernel_size = n-gram size\n",
    "        # number of parameters: (# of filters, embedding_size, n-gram size), (100, 100, 2) for 2-gram\n",
    "        self.conv1d_4gram = nn.Conv1d(in_channels=embedding_size, out_channels=num_channels, kernel_size=4)       \n",
    "        self.conv1d_3gram = nn.Conv1d(in_channels=embedding_size, out_channels=num_channels, kernel_size=3)                          \n",
    "        self.conv1d_2gram = nn.Conv1d(in_channels=embedding_size, out_channels=num_channels, kernel_size=2)                   \n",
    "\n",
    "        self._dropout_p = dropout_p\n",
    "        self.fc1 = nn.Linear(num_channels*3, hidden_dim) # input:concatination of conv1d_4gram, conv1d_3gram, conv1d_2gram outputs \n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, dataset._max_seq_length)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, num_classes)\n",
    "        \"\"\"\n",
    "        \n",
    "        # embed and permute so features are channels\n",
    "        x_embedded = self.emb(x_in).permute(0, 2, 1)    # (batch, seq_len) -> (batch, seq_len, features)\n",
    "                                                        # rearange (batch, seq_len, features) to (batch, features, seq_len) \n",
    "                                                        # E.g.,    (128,   29,      100)      to (128,   100,      29)\n",
    "\n",
    "        features = F.elu(self.conv1d_4gram(x_embedded)) # features: (batch, num_channels, ?); e.g., (128, 100, ?)\n",
    "                                                        # activation function similar to leaky RELU(); can use F.relu() instead\n",
    "        # max/average and remove the extra dimension\n",
    "        remaining_size = features.size(dim=2)          # remaining_size: ? in (batch, num_channels, ?)\n",
    "        features_4gram = F.max_pool1d(features, remaining_size).squeeze(dim=2) # features_4gram: (batch, num_channels);kernel_size=remaining_size   \n",
    "        #features_4gram = F.avg_pool1d(features, remaining_size).squeeze(dim=2)   \n",
    "        \n",
    "        features = F.elu(self.conv1d_3gram(x_embedded)) # features: (batch, num_channels, ?); e.g., (128, 100, ?)\n",
    "        remaining_size = features.size(dim=2)          # remaining_size: ? in (batch, num_channels, ?)\n",
    "        features_3gram = F.max_pool1d(features, remaining_size).squeeze(dim=2)    # features_3gram: (batch, num_channels)\n",
    "\n",
    "        features = F.elu(self.conv1d_2gram(x_embedded)) # features: (batch, num_channels, ?); e.g., (128, 100, ?)\n",
    "        remaining_size = features.size(dim=2)          # remaining_size: ? in (batch, num_channels, ?)\n",
    "        features_2gram = F.max_pool1d(features, remaining_size).squeeze(dim=2)    # features_2gram: (batch, num_channels) \n",
    " \n",
    "        features = torch.cat([features_4gram, features_3gram, features_2gram], dim=1)\n",
    "            \n",
    "        features = F.dropout(features, p=self._dropout_p, training=self.training)\n",
    "        \n",
    "        # mlp classifier\n",
    "        intermediate_vector = F.dropout(F.relu(self.fc1(features)), p=self._dropout_p, training=self.training)\n",
    "        prediction_vector = self.fc2(intermediate_vector)  # (batch, num_classes)\n",
    "\n",
    "        if apply_softmax:\n",
    "            prediction_vector = F.softmax(prediction_vector, dim=1)\n",
    "\n",
    "        return prediction_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t  # update 'early_stopping_best_val'\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### general utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda, mps):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    try:\n",
    "        if mps:\n",
    "            torch.mps.manual_seed(seed)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "        \n",
    "def load_glove_from_file(glove_filepath):\n",
    "    \"\"\"\n",
    "    Load the GloVe embeddings \n",
    "    \n",
    "    Args:\n",
    "        glove_filepath (str): path to the glove embeddings file \n",
    "    Returns:\n",
    "        word_to_index (dict), embeddings (numpy.ndarary)\n",
    "    \"\"\"\n",
    "\n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(glove_filepath, \"r\", encoding='utf8') as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \") # each line: word num1 num2 ...\n",
    "            word_to_index[line[0]] = index # word = line[0] \n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    return word_to_index, np.stack(embeddings)\n",
    "\n",
    "def make_embedding_matrix(glove_filepath, words):\n",
    "    \"\"\"\n",
    "    Create embedding matrix for a specific set of words.\n",
    "    \n",
    "    Args:\n",
    "        glove_filepath (str): file path to the glove embeddigns\n",
    "        words (list): list of words in the dataset\n",
    "    \"\"\"\n",
    "    word_to_idx, glove_embeddings = load_glove_from_file(glove_filepath)\n",
    "    embedding_size = glove_embeddings.shape[1]\n",
    "    \n",
    "    final_embeddings = np.zeros((len(words), embedding_size))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word in word_to_idx:\n",
    "            final_embeddings[i, :] = glove_embeddings[word_to_idx[word]]\n",
    "        else:\n",
    "            embedding_i = torch.ones(1, embedding_size)\n",
    "            torch.nn.init.xavier_uniform_(embedding_i)\n",
    "            final_embeddings[i, :] = embedding_i\n",
    "\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings and some prep work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\t../model_storage/News_Category\\model_cnn_News_Category.pth\n",
      "Using CUDA: True\n",
      "Using MPS: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and Path hyper parameters\n",
    "    news_csv=\"../data/processed/News_Category_Dataset_with_splits.csv\",\n",
    "    model_state_file=\"model_cnn_News_Category.pth\",\n",
    "    save_dir=\"../model_storage/News_Category\",\n",
    "    # Model hyper parameters\n",
    "    glove_filepath='../data/glove/glove.6B.100d.txt', \n",
    "    use_glove=True,\n",
    "    embedding_size=100, \n",
    "    hidden_dim=512, \n",
    "    num_channels=320, \n",
    "    # Training hyper parameter\n",
    "    seed=1337, \n",
    "    learning_rate=0.001, \n",
    "    dropout_p=0.2, \n",
    "    batch_size=160, \n",
    "    num_epochs=100, \n",
    "    emb_freeze=False,\n",
    "    early_stopping_criteria=5, \n",
    "    # Runtime option\n",
    "    cuda=True,\n",
    "    mps=True, \n",
    "    catch_keyboard_interrupt=True, \n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True\n",
    ") \n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA for Nvidia\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "# Check MPS for Mac\n",
    "if not torch.backends.mps.is_available():\n",
    "    args.mps = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"mps\" if args.mps else \"cpu\")\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "print(\"Using MPS: {}\".format(args.mps))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda, args.mps)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-trained embeddings\n"
     ]
    }
   ],
   "source": [
    "# create dataset and vectorizer\n",
    "dataset = NewsDataset.load_dataset_and_make_vectorizer(args.news_csv)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# Use GloVe or randomly initialized embeddings\n",
    "if args.use_glove:\n",
    "    words = vectorizer.news_vocab._token_to_idx.keys()  # 3409 unique words\n",
    "    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath,     # embeddings: (3409, 100)\n",
    "                                       words=words)\n",
    "    print(\"Using pre-trained embeddings\")\n",
    "else:\n",
    "    print(\"Not using pre-trained embeddings\")\n",
    "    embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'profit': 4, 'price': 5, 'cut': 6, 'new': 7, 'york': 8, 'reuters': 9, 'co': 10, 'top': 11, 'u': 12, 'tuesday': 13, 'posted': 14, 'percent': 15, 'rise': 16, 'quarterly': 17, 'due': 18, 'cost': 19, 'control': 20, 'shopper': 21, 'caused': 22, 'earnings': 23, 'miss': 24, 'wall': 25, 'street': 26, 'estimate': 27, 'share': 28, 'fell': 29, 'group': 30, 'inc': 31, 'may': 32, 'talk': 33, 'family': 34, 'japanese': 35, 'consumer': 36, 'finance': 37, 'firm': 38, 'corp': 39, 'stake': 40, 'losing': 41, 'right': 42, 'sue': 43, 'washington': 44, 'business': 45, 'contract': 46, 'give': 47, 'want': 48, 'conduct': 49, 'made': 50, 'priority': 51, 'battle': 52, 'eu': 53, 'ap': 54, 'united': 55, 'state': 56, 'australia': 57, 'interim': 58, 'ruling': 59, 'world': 60, 'trade': 61, 'organisation': 62, 'wto': 63, 'dispute': 64, 'protection': 65, 'given': 66, 'european': 67, 'union': 68, 'regional': 69, 'good': 70, 'wine': 71, 'official': 72, 'said': 73, 'foreign': 74, 'minister': 75, 'hope': 76, 'break': 77, 'summit': 78, 'friday': 79, 'quot': 80, 'reach': 81, 'meeting': 82, 'military': 83, 'ruled': 84, 'myanmar': 85, 'upcoming': 86, 'asian': 87, 'nation': 88, 'watchdog': 89, 'today': 90, 'ordered': 91, 'open': 92, 'modern': 93, 'service': 94, 'broadband': 95, 'competitor': 96, 'charge': 97, 'retail': 98, 'within': 99, 'matter': 100, 'month': 101, 'venezuela': 102, 'increase': 103, 'opec': 104, 'production': 105, 'third': 106, 'largest': 107, 'oil': 108, 'producer': 109, 'raise': 110, 'output': 111, 'target': 112, 'week': 113, 'vienna': 114, 'auto': 115, 'sale': 116, 'job': 117, 'number': 118, 'time': 119, 'chicago': 120, 'cbs': 121, 'mw': 122, 'could': 123, 'people': 124, 'buying': 125, 'thing': 126, 'wal': 127, 'mart': 128, 'free': 129, 'sign': 130, 'roundup': 131, 'e': 132, 'blue': 133, 'chip': 134, 'end': 135, 'lower': 136, 'hit': 137, 'stock': 138, 'declined': 139, 'level': 140, 'thursday': 141, 'crude': 142, 'barrel': 143, 'renewed': 144, 'concern': 145, 'high': 146, 'fuel': 147, 'corporate': 148, 'guide': 149, 'sharply': 150, 'nyse': 151, 'news': 152, 'research': 153, 'fiscal': 154, 'fourth': 155, 'quarter': 156, 'came': 157, 'light': 158, 'company': 159, 'first': 160, 'weak': 161, 'calif': 162, 'stewart': 163, 'case': 164, 'expert': 165, 'found': 166, 'guilty': 167, 'government': 168, 'trial': 169, 'yesterday': 170, 'witness': 171, 'stand': 172, 'delay': 173, 'action': 174, 'airbus': 175, 'subsidy': 176, 'offer': 177, 'branch': 178, 'peter': 179, 'commissioner': 180, 'next': 181, 'boeing': 182, 'agrees': 183, 'account': 184, 'b': 185, 'writes': 186, 'confirmed': 187, 'authority': 188, 'agreed': 189, 'appeal': 190, 'heard': 191, 'court': 192, 'make': 193, 'decision': 194, 'bank': 195, 'hostile': 196, 'bid': 197, 'takeover': 198, 'biggest': 199, 'ever': 200, 'japan': 201, 'got': 202, 'even': 203, 'bigger': 204, 'sought': 205, 'rival': 206, 'expansion': 207, 'plan': 208, 'billion': 209, 'bush': 210, 'tax': 211, 'bill': 212, 'president': 213, 'signed': 214, 'law': 215, 'sweeping': 216, 'nearly': 217, 'two': 218, 'decade': 219, 'flight': 220, 'air': 221, 'force': 222, 'one': 223, 'campaign': 224, 'stop': 225, 'pension': 226, 'year': 227, 'airline': 228, 'announced': 229, 'citing': 230, 'reason': 231, 'ongoing': 232, 'industry': 233, 'economic': 234, 'environment': 235, 'record': 236, 'jet': 237, 'update': 238, 'james': 239, 'h': 240, 'net': 241, 'forecast': 242, 'sydney': 243, 'dow': 244, 'jones': 245, 'australian': 246, 'building': 247, 'product': 248, 'manufacturer': 249, 'investor': 250, 'monday': 251, 'reporting': 252, 'drop': 253, 'treasury': 254, 'held': 255, 'near': 256, 'six': 257, 'low': 258, 'though': 259, 'market': 260, 'struggling': 261, 'extend': 262, 'recent': 263, 'gain': 264, 'face': 265, 'taking': 266, 'bankrupt': 267, 'clear': 268, 'cutting': 269, 'major': 270, 'bankruptcy': 271, 'tough': 272, 'choice': 273, 'wage': 274, 'ticket': 275, 'offered': 276, 'holiday': 277, 'result': 278, 'lift': 279, 'kmart': 280, 'store': 281, 'surge': 282, 'christmas': 283, 'shopping': 284, 'december': 285, 'holding': 286, 'rose': 287, 'season': 288, 'limited': 289, 'deep': 290, 'discount': 291, 'sell': 292, 'maker': 293, 'drink': 294, 'giant': 295, 'raised': 296, 'dollar': 297, 'bn': 298, 'selling': 299, 'general': 300, 'army': 301, 'payment': 302, 'per': 303, 'cent': 304, 'future': 305, 'support': 306, 'housing': 307, 'troop': 308, 'iraq': 309, 'kuwait': 310, 'see': 311, 'retailer': 312, 'owner': 313, 'least': 314, 'september': 315, 'slightly': 316, 'higher': 317, 'preliminary': 318, 'report': 319, 'still': 320, 'towards': 321, 'range': 322, 'sony': 323, 'lead': 324, 'acquisition': 325, 'entertainment': 326, 'get': 327, 'hand': 328, 'title': 329, 'warner': 330, 'seen': 331, 'front': 332, 'race': 333, 'drug': 334, 'worried': 335, 'rising': 336, 'would': 337, 'possible': 338, 'regulator': 339, 'data': 340, 'view': 341, 'singapore': 342, 'aug': 343, 'expectation': 344, 'industrial': 345, 'smaller': 346, 'expected': 347, 'august': 348, 'pharmaceutical': 349, 'base': 350, 'ago': 351, 'st': 352, 'louis': 353, 'spike': 354, 'publisher': 355, 'post': 356, 'arizona': 357, 'newspaper': 358, 'considering': 359, 'sec': 360, 'probe': 361, 'rental': 362, 'security': 363, 'investigating': 364, 'href': 365, 'quickinfo': 366, 'fullquote': 367, 'n': 368, 'accounting': 369, 'sending': 370, 'com': 371, 'cool': 372, 'something': 373, 'else': 374, 'mind': 375, 'need': 376, 'computer': 377, 'note': 378, 'searching': 379, 'internet': 380, 'heating': 381, 'worry': 382, 'ahead': 383, 'inventory': 384, 'show': 385, 'tight': 386, 'winter': 387, 'golden': 388, 'ring': 389, 'cheaper': 390, 'list': 391, 'save': 392, 'consider': 393, 'five': 394, 'fifth': 395, 'classic': 396, 'song': 397, 'day': 398, 'mortgage': 399, 'rate': 400, 'around': 401, 'country': 402, 'continue': 403, 'provide': 404, 'analyst': 405, 'say': 406, 'little': 407, 'ban': 408, 'bell': 409, 'nationwide': 410, 'qualcomm': 411, 'strong': 412, 'demand': 413, 'mobile': 414, 'phone': 415, 'technology': 416, 'san': 417, 'diego': 418, 'expects': 419, 'oracle': 420, 'peoplesoft': 421, 'purchase': 422, 'bought': 423, 'international': 424, 'uk': 425, 'optimistic': 426, 'economy': 427, 'prospect': 428, 'hunt': 429, 'page': 430, 'v': 431, 'main': 432, 'look': 433, 'image': 434, 'buyer': 435, 'labour': 436, 'reform': 437, 'pay': 438, 'population': 439, 'afp': 440, 'organization': 441, 'operation': 442, 'development': 443, 'called': 444, 'labor': 445, 'boost': 446, 'marine': 447, 'city': 448, 'leaf': 449, 'following': 450, 'helping': 451, 'church': 452, 'work': 453, 'donald': 454, 'help': 455, 'death': 456, 'push': 457, 'trader': 458, 'described': 459, 'wave': 460, 'gasoline': 461, 'cardinal': 462, 'pick': 463, 'health': 464, 'deal': 465, 'suggests': 466, 'fee': 467, 'model': 468, 'helped': 469, 'brewer': 470, 'income': 471, 'plc': 472, 'l': 473, 'offset': 474, 'weakness': 475, 'domestic': 476, 'tobacco': 477, 'food': 478, 'justice': 479, 'close': 480, 'inquiry': 481, 'wednesday': 482, 'department': 483, 'closed': 484, 'potential': 485, 'antitrust': 486, 'issue': 487, 'key': 488, 'used': 489, 'million': 490, 'florida': 491, 'jeanne': 492, 'customer': 493, 'remained': 494, 'without': 495, 'power': 496, 'early': 497, 'hurricane': 498, 'weekend': 499, 'according': 500, 'utility': 501, 'lawsuit': 502, 'try': 503, 'damage': 504, 'falling': 505, 'broker': 506, 'threatened': 507, 'financial': 508, 'huge': 509, 'executive': 510, 'dismissed': 511, 'insurance': 512, 'ace': 513, 'became': 514, 'latest': 515, 'announce': 516, 'change': 517, 'practice': 518, 'response': 519, 'investigation': 520, 'launched': 521, 'attorney': 522, 'aol': 523, 'file': 524, 'im': 525, 'america': 526, 'online': 527, 'filed': 528, 'federal': 529, 'accusing': 530, 'message': 531, 'known': 532, 'instant': 533, 'chat': 534, 'room': 535, 'build': 536, 'version': 537, 'twin': 538, 'engine': 539, 'commercial': 540, 'enter': 541, 'late': 542, 'kerry': 543, 'ready': 544, 'final': 545, 'democratic': 546, 'challenger': 547, 'john': 548, 'set': 549, 'debate': 550, 'candidate': 551, 'turn': 552, 'policy': 553, 'office': 554, 'depot': 555, 'chairman': 556, 'ceo': 557, 'resigns': 558, 'quote': 559, 'profile': 560, 'supply': 561, 'chain': 562, 'chief': 563, 'officer': 564, 'resigned': 565, 'search': 566, 'energy': 567, 'panel': 568, 'criticized': 569, 'crisis': 570, 'duty': 571, 'order': 572, 'tech': 573, 'advance': 574, 'exporter': 575, 'electronics': 576, 'ltd': 577, 'outlook': 578, 'slide': 579, 'nextel': 580, 'sprint': 581, 'communication': 582, 'jumped': 583, 'telephone': 584, 'merger': 585, 'farmer': 586, 'fed': 587, 'pct': 588, 'growth': 589, 'slow': 590, 'interest': 591, 'reserve': 592, 'conference': 593, 'released': 594, 'fire': 595, 'back': 596, 'parmalat': 597, 'london': 598, 'grant': 599, 'motion': 600, 'remove': 601, 'italian': 602, 'sued': 603, 'airway': 604, 'accord': 605, 'journal': 606, 'carrier': 607, 'aircraft': 608, 'gap': 609, 'sap': 610, 'software': 611, 'jeff': 612, 'interview': 613, 'published': 614, 'focus': 615, 'politician': 616, 'lewis': 617, 'running': 618, 'massachusetts': 619, 'sun': 620, 'settle': 621, 'patent': 622, 'suit': 623, 'microsystems': 624, 'java': 625, 'ocean': 626, 'peace': 627, 'ended': 628, 'legal': 629, 'join': 630, 'take': 631, 'olympics': 632, 'advertising': 633, 'reported': 634, 'half': 635, 'russia': 636, 'yukos': 637, 'auction': 638, 'moscow': 639, 'core': 640, 'asset': 641, 'despite': 642, 'disputed': 643, 'controlled': 644, 'gas': 645, 'bidding': 646, 'delta': 647, 'pilot': 648, 'ok': 649, 'concession': 650, 'francisco': 651, 'line': 652, 'approved': 653, 'management': 654, 'backed': 655, 'china': 656, 'pledge': 657, 'move': 658, 'toward': 659, 'exchange': 660, 'currency': 661, 'word': 662, 'long': 663, 'gold': 664, 'sink': 665, 'merck': 666, 'toronto': 667, 'small': 668, 'pushed': 669, 'sector': 670, 'amp': 671, 'took': 672, 'average': 673, 'red': 674, 'arthritis': 675, 'vioxx': 676, 'withdrawal': 677, 'revenue': 678, 'setback': 679, 'patient': 680, 'doctor': 681, 'dozen': 682, 'relief': 683, 'unemployment': 684, 'claim': 685, 'slip': 686, 'picture': 687, 'american': 688, 'jobless': 689, 'benefit': 690, 'last': 691, 'decline': 692, 'current': 693, 'announces': 694, 'closing': 695, 'weaker': 696, 'allow': 697, 'brand': 698, 'session': 699, 'rally': 700, 'ran': 701, 'saw': 702, 'large': 703, 'short': 704, 'index': 705, 'best': 706, 'term': 707, 'germany': 708, 'worst': 709, 'field': 710, 'win': 711, 'fight': 712, 'harmony': 713, 'mining': 714, 'create': 715, 'c': 716, 'indian': 717, 'unveils': 718, 'since': 719, 'launch': 720, 'imf': 721, 'keep': 722, 'global': 723, 'recovery': 724, 'facing': 725, 'factor': 726, 'opened': 727, 'saturday': 728, 'discus': 729, 'way': 730, 'track': 731, 'marsh': 732, 'spitzer': 733, 'center': 734, 'eliot': 735, 'electric': 736, 'dividend': 737, 'well': 738, 'television': 739, 'network': 740, 'board': 741, 'charles': 742, 'certain': 743, 'arm': 744, 'equity': 745, 'commission': 746, 'reduce': 747, 'position': 748, 'leading': 749, 'preparing': 750, 'lay': 751, 'many': 752, 'employee': 753, 'ireland': 754, 'poised': 755, 'grow': 756, 'faster': 757, 'deficit': 758, 'thanks': 759, 'administration': 760, 'emergency': 761, 'petroleum': 762, 'ivan': 763, 'source': 764, 'told': 765, 'budget': 766, 'virgin': 767, 'add': 768, 'soaring': 769, 'doubt': 770, 'russian': 771, 'warned': 772, 'night': 773, 'driven': 774, 'briefly': 775, 'unit': 776, 'producing': 777, 'chinese': 778, 'saying': 779, 'agency': 780, 'gate': 781, 'founder': 782, 'microsoft': 783, 'remains': 784, 'person': 785, 'usa': 786, 'magazine': 787, 'keeping': 788, 'place': 789, 'already': 790, 'among': 791, 'worker': 792, 'victim': 793, 'rallied': 794, 'outside': 795, 'embattled': 796, 'central': 797, 'edge': 798, 'flu': 799, 'shot': 800, 'shortage': 801, 'highlight': 802, 'began': 803, 'went': 804, 'wrong': 805, 'british': 806, 'vaccine': 807, 'plant': 808, 'confidence': 809, 'second': 810, 'consecutive': 811, 'based': 812, 'private': 813, 'sears': 814, 'form': 815, 'annual': 816, 'school': 817, 'hoping': 818, 'fashion': 819, 'style': 820, 'teen': 821, 'young': 822, 'adult': 823, 'fall': 824, 'student': 825, 'parent': 826, 'hold': 827, 'ibm': 828, 'strike': 829, 'expanded': 830, 'relationship': 831, 'infrastructure': 832, 'application': 833, 'fear': 834, 'representing': 835, 'gm': 836, 'go': 837, 'green': 838, 'team': 839, 'compete': 840, 'situation': 841, 'moment': 842, 'white': 843, 'house': 844, 'spin': 845, 'man': 846, 'much': 847, 'like': 848, 'four': 849, 'ad': 850, 'men': 851, 'accused': 852, 'using': 853, 'europe': 854, 'direct': 855, 'sound': 856, 'mayor': 857, 'wake': 858, 'another': 859, 'credit': 860, 'rating': 861, 'public': 862, 'amid': 863, 'offering': 864, 'flying': 865, 'scheduled': 866, 'play': 867, 'debt': 868, 'slipped': 869, 'previous': 870, 'played': 871, 'technical': 872, 'trading': 873, 'hurt': 874, 'q': 875, 'personal': 876, 'home': 877, 'loss': 878, 'presidential': 879, 'election': 880, 'seek': 881, 'cp': 882, 'telecommunication': 883, 'war': 884, 'buy': 885, 'component': 886, 'provider': 887, 'circuit': 888, 'solution': 889, 'black': 890, 'samsung': 891, 'seoul': 892, 'south': 893, 'korea': 894, 'bottom': 895, 'google': 896, 'almost': 897, 'sharp': 898, 'reached': 899, 'agreement': 900, 'negotiator': 901, 'accept': 902, 'leader': 903, 'prevent': 904, 'collapse': 905, 'flag': 906, 'detail': 907, 'rescue': 908, 'tokyo': 909, 'lifted': 910, 'survey': 911, 'mid': 912, 'morning': 913, 'broad': 914, 'getting': 915, 'boosted': 916, 'optimism': 917, 'figure': 918, 'schedule': 919, 'charlotte': 920, 'philadelphia': 921, 'fla': 922, 'swing': 923, 'warns': 924, 'manufacturing': 925, 'atlantic': 926, 'factory': 927, 'dec': 928, 'increased': 929, 'withdrawn': 930, 'asia': 931, 'pacific': 932, 'independent': 933, 'director': 934, 'fannie': 935, 'mae': 936, 'criminal': 937, 'begun': 938, 'prosecutor': 939, 'ata': 940, 'indianapolis': 941, 'full': 942, 'filing': 943, 'big': 944, 'political': 945, 'engineering': 946, 'scandal': 947, 'boston': 948, 'hundred': 949, 'safe': 950, 'hole': 951, 'beginning': 952, 'question': 953, 'super': 954, 'status': 955, 'fraud': 956, 'allegation': 957, 'call': 958, 'program': 959, 'poor': 960, 'gordon': 961, 'brown': 962, 'retire': 963, 'start': 964, 'date': 965, 'package': 966, 'steady': 967, 'looked': 968, 'changed': 969, 'heavy': 970, 'remain': 971, 'dip': 972, 'often': 973, 'drive': 974, 'away': 975, 'summer': 976, 'self': 977, 'serve': 978, 'regular': 979, 'saudi': 980, 'system': 981, 'announcing': 982, 'progress': 983, 'admitted': 984, 'trouble': 985, 'controversial': 986, 'al': 987, 'verizon': 988, 'canada': 989, 'canadian': 990, 'capital': 991, 'block': 992, 'lawyer': 993, 'likely': 994, 'temporary': 995, 'mark': 996, 'era': 997, 'edward': 998, 'old': 999, 'asked': 1000, 'decided': 1001, 'traded': 1002, 'increasingly': 1003, 'civil': 1004, 'evidence': 1005, 'three': 1006, 'j': 1007, 'reportedly': 1008, 'johnson': 1009, 'advanced': 1010, 'negotiation': 1011, 'acquire': 1012, 'medical': 1013, 'device': 1014, 'coca': 1015, 'cola': 1016, 'shop': 1017, 'competition': 1018, 'enron': 1019, 'houston': 1020, 'pipeline': 1021, 'fund': 1022, 'thousand': 1023, 'former': 1024, 'vote': 1025, 'shift': 1026, 'shareholder': 1027, 'approval': 1028, 'headquarters': 1029, 'medium': 1030, 'finally': 1031, 'planned': 1032, 'check': 1033, 'staff': 1034, 'walt': 1035, 'disney': 1036, 'might': 1037, 'done': 1038, 'double': 1039, 'michael': 1040, 'brief': 1041, 'friend': 1042, 'must': 1043, 'expand': 1044, 'strategic': 1045, 'standard': 1046, 'ensure': 1047, 'beijing': 1048, 'surged': 1049, 'nine': 1050, 'sunday': 1051, 'claiming': 1052, 'county': 1053, 'employer': 1054, 'nikkei': 1055, 'richard': 1056, 'branson': 1057, 'disappointing': 1058, 'exec': 1059, 'urged': 1060, 'assist': 1061, 'developing': 1062, 'monetary': 1063, 'develop': 1064, 'facility': 1065, 'wish': 1066, 'nasdaq': 1067, 'hour': 1068, 'aid': 1069, 'express': 1070, 'sept': 1071, 'corporation': 1072, 'performance': 1073, 'believed': 1074, 'history': 1075, 'turned': 1076, 'negative': 1077, 'bond': 1078, 'showed': 1079, 'inflation': 1080, 'flat': 1081, 'spending': 1082, 'french': 1083, 'france': 1084, 'replace': 1085, 'resignation': 1086, 'governing': 1087, 'party': 1088, 'intel': 1089, 'making': 1090, 'better': 1091, 'viacom': 1092, 'howard': 1093, 'stern': 1094, 'switch': 1095, 'satellite': 1096, 'radio': 1097, 'deutsche': 1098, 'ag': 1099, 'cincinnati': 1100, 'investment': 1101, 'plus': 1102, 'le': 1103, 'export': 1104, 'find': 1105, 'jim': 1106, 'remember': 1107, 'failing': 1108, 'insurer': 1109, 'real': 1110, 'estate': 1111, 'broke': 1112, 'territory': 1113, 'prove': 1114, 'northern': 1115, 'awaits': 1116, 'greenspan': 1117, 'moved': 1118, 'address': 1119, 'point': 1120, 'cash': 1121, 'coming': 1122, 'soon': 1123, 'able': 1124, 'screen': 1125, 'initiative': 1126, 'link': 1127, 'machine': 1128, 'nortel': 1129, 'exit': 1130, 'ottawa': 1131, 'eliminate': 1132, 'previously': 1133, 'estimated': 1134, 'amazon': 1135, 'los': 1136, 'mail': 1137, 'dvd': 1138, 'dot': 1139, 'movie': 1140, 'fda': 1141, 'import': 1142, 'whether': 1143, 'use': 1144, 'secretary': 1145, 'indonesian': 1146, 'diplomat': 1147, 'improve': 1148, 'bad': 1149, 'jakarta': 1150, 'indonesia': 1151, 'majority': 1152, 'supplier': 1153, 'pm': 1154, 'heart': 1155, 'la': 1156, 'user': 1157, 'attempt': 1158, 'p': 1159, 'g': 1160, 'continued': 1161, 'ranked': 1162, 'behind': 1163, 'greater': 1164, 'manage': 1165, 'effect': 1166, 'college': 1167, 'lowered': 1168, 'expense': 1169, 'saving': 1170, 'problem': 1171, 'additional': 1172, 'seven': 1173, 'senior': 1174, 'au': 1175, 'property': 1176, 'trust': 1177, 'pc': 1178, 'enterprise': 1179, 'notebook': 1180, 'shipment': 1181, 'grew': 1182, 'announcement': 1183, 'strength': 1184, 'african': 1185, 'mine': 1186, 'judge': 1187, 'warning': 1188, 'enough': 1189, 'january': 1190, 'airport': 1191, 'f': 1192, 'kennedy': 1193, 'passenger': 1194, 'signal': 1195, 'studio': 1196, 'banned': 1197, 'speculation': 1198, 'struck': 1199, 'pound': 1200, 'euro': 1201, 'fined': 1202, 'sa': 1203, 'bos': 1204, 'jean': 1205, 'issued': 1206, 'period': 1207, 'hard': 1208, 'disc': 1209, 'stronger': 1210, 'weather': 1211, 'park': 1212, 'improvement': 1213, 'overtime': 1214, 'rule': 1215, 'mean': 1216, 'seems': 1217, 'working': 1218, 'ask': 1219, 'probably': 1220, 'know': 1221, 'showing': 1222, 'march': 1223, 'jump': 1224, 'expect': 1225, 'quickly': 1226, 'web': 1227, 'oct': 1228, 'october': 1229, 'battery': 1230, 'great': 1231, 'become': 1232, 'past': 1233, 'name': 1234, 'rich': 1235, 'local': 1236, 'discovered': 1237, 'mother': 1238, 'present': 1239, 'delayed': 1240, 'yet': 1241, 'release': 1242, 'statement': 1243, 'challenge': 1244, 'fresh': 1245, 'forced': 1246, 'allowing': 1247, 'equipment': 1248, 'newly': 1249, 'cancer': 1250, 'construction': 1251, 'highest': 1252, 'continuing': 1253, 'rock': 1254, 'proposal': 1255, 'fix': 1256, 'serious': 1257, 'threatens': 1258, 'mci': 1259, 'paid': 1260, 'distance': 1261, 'britain': 1262, 'license': 1263, 'suspended': 1264, 'begin': 1265, 'releasing': 1266, 'steel': 1267, 'received': 1268, 'bay': 1269, 'restructuring': 1270, 'hamilton': 1271, 'violence': 1272, 'india': 1273, 'familiar': 1274, 'individual': 1275, 'firing': 1276, 'buyout': 1277, 'minority': 1278, 'division': 1279, 'follow': 1280, 'ny': 1281, 'trend': 1282, 'across': 1283, 'fail': 1284, 'national': 1285, 'regulatory': 1286, 'virtually': 1287, 'every': 1288, 'region': 1289, 'pressure': 1290, 'extended': 1291, 'steve': 1292, 'ballmer': 1293, 'finish': 1294, 'mixed': 1295, 'finished': 1296, 'forward': 1297, 'senator': 1298, 'senate': 1299, 'armed': 1300, 'committee': 1301, 'defense': 1302, 'effort': 1303, 'tip': 1304, 'ex': 1305, 'cover': 1306, 'distributor': 1307, 'aside': 1308, 'money': 1309, 'penalty': 1310, 'initial': 1311, 'nokia': 1312, 'texas': 1313, 'instrument': 1314, 'sent': 1315, 'zealand': 1316, 'governor': 1317, 'alan': 1318, 'single': 1319, 'conflict': 1320, 'mutual': 1321, 'developed': 1322, 'prime': 1323, 'lender': 1324, 'council': 1325, 'analysis': 1326, 'space': 1327, 'nov': 1328, 'study': 1329, 'rank': 1330, 'dangerous': 1331, 'jersey': 1332, 'detroit': 1333, 'atlanta': 1334, 'ranking': 1335, 'morgan': 1336, 'crime': 1337, 'aim': 1338, 'allowed': 1339, 'twice': 1340, 'mostly': 1341, 'radical': 1342, 'settled': 1343, 'yen': 1344, 'suffering': 1345, 'amsterdam': 1346, 'dutch': 1347, 'w': 1348, 'm': 1349, 'multiple': 1350, 'disease': 1351, 'really': 1352, 'education': 1353, 'care': 1354, 'massive': 1355, 'run': 1356, 'aimed': 1357, 'hike': 1358, 'stay': 1359, 'abu': 1360, 'gulf': 1361, 'bring': 1362, 'limit': 1363, 'venture': 1364, 'troubled': 1365, 'german': 1366, 'joint': 1367, 'life': 1368, 'suicide': 1369, 'appears': 1370, 'linked': 1371, 'child': 1372, 'concluded': 1373, 'shut': 1374, 'hollywood': 1375, 'film': 1376, 'channel': 1377, 'june': 1378, 'fierce': 1379, 'luxury': 1380, 'car': 1381, 'watch': 1382, 'important': 1383, 'avoid': 1384, 'cold': 1385, 'snap': 1386, 'afternoon': 1387, 'pre': 1388, 'southwest': 1389, 'traffic': 1390, 'increasing': 1391, 'november': 1392, 'seat': 1393, 'plane': 1394, 'paris': 1395, 'rather': 1396, 'unlikely': 1397, 'left': 1398, 'mile': 1399, 'malaysia': 1400, 'idea': 1401, 'owned': 1402, 'entire': 1403, 'cingular': 1404, 'wireless': 1405, 'charley': 1406, 'coast': 1407, 'risk': 1408, 'faced': 1409, 'paying': 1410, 'fast': 1411, 'growing': 1412, 'toy': 1413, 'merrill': 1414, 'lynch': 1415, 'newratings': 1416, 'involved': 1417, 'eagle': 1418, 'accepted': 1419, 'includes': 1420, 'flagship': 1421, 'database': 1422, 'worm': 1423, 'carlos': 1424, 'demanded': 1425, 'fired': 1426, 'loan': 1427, 'comment': 1428, 'retreat': 1429, 'opposition': 1430, 'earlier': 1431, 'discussion': 1432, 'hong': 1433, 'kong': 1434, 'driving': 1435, 'injury': 1436, 'road': 1437, 'possibly': 1438, 'ease': 1439, 'eased': 1440, 'cabinet': 1441, 'including': 1442, 'deadly': 1443, 'attack': 1444, 'chase': 1445, 'impact': 1446, 'led': 1447, 'vehicle': 1448, 'seem': 1449, 'joining': 1450, 'motor': 1451, 'test': 1452, 'access': 1453, 'telecom': 1454, 'amount': 1455, 'agree': 1456, 'operating': 1457, 'related': 1458, 'climb': 1459, 'reaching': 1460, 'workforce': 1461, 'worldwide': 1462, 'part': 1463, 'hp': 1464, 'sight': 1465, 'hardware': 1466, 'tv': 1467, 'music': 1468, 'player': 1469, 'content': 1470, 'beating': 1471, 'success': 1472, 'lose': 1473, 'threat': 1474, 'upgrade': 1475, 'expressed': 1476, 'hero': 1477, 'easy': 1478, 'carried': 1479, 'thin': 1480, 'republican': 1481, 'convention': 1482, 'storm': 1483, 'anti': 1484, 'terror': 1485, 'scottish': 1486, 'legislation': 1487, 'jail': 1488, 'human': 1489, 'think': 1490, 'disaster': 1491, 'resolve': 1492, 'cautious': 1493, 'dream': 1494, 'perfect': 1495, 'fine': 1496, 'come': 1497, 'true': 1498, 'natural': 1499, 'review': 1500, 'perhaps': 1501, 'ipo': 1502, 'trail': 1503, 'tried': 1504, 'managed': 1505, 'approach': 1506, 'abbey': 1507, 'longer': 1508, 'spanish': 1509, 'brings': 1510, 'side': 1511, 'truck': 1512, 'along': 1513, 'developer': 1514, 'calling': 1515, 'professional': 1516, 'cap': 1517, 'virus': 1518, 'dead': 1519, 'simple': 1520, 'kept': 1521, 'southern': 1522, 'california': 1523, 'shed': 1524, 'eight': 1525, 'th': 1526, 'summary': 1527, 'seeking': 1528, 'manager': 1529, 'leaving': 1530, 'friendly': 1531, 'daily': 1532, 'starting': 1533, 'july': 1534, 'apparently': 1535, 'book': 1536, 'halo': 1537, 'score': 1538, 'game': 1539, 'video': 1540, 'sold': 1541, 'finding': 1542, 'card': 1543, 'larger': 1544, 'partner': 1545, 'george': 1546, 'hire': 1547, 'window': 1548, 'neck': 1549, 'scientific': 1550, 'separate': 1551, 'stroke': 1552, 'step': 1553, 'alert': 1554, 'soft': 1555, 'patch': 1556, 'design': 1557, 'astronaut': 1558, 'moon': 1559, 'beyond': 1560, 'sustained': 1561, 'automaker': 1562, 'woman': 1563, 'died': 1564, 'surgery': 1565, 'saint': 1566, 'hospital': 1567, 'river': 1568, 'stopped': 1569, 'internal': 1570, 'lawmaker': 1571, 'lack': 1572, 'spent': 1573, 'approve': 1574, 'sanction': 1575, 'declared': 1576, 'illegal': 1577, 'confirms': 1578, 'monthly': 1579, 'commerce': 1580, 'wide': 1581, 'trump': 1582, 'casino': 1583, 'proposed': 1584, 'divided': 1585, 'hedge': 1586, 'available': 1587, 'larry': 1588, 'intelligence': 1589, 'community': 1590, 'terrorist': 1591, 'never': 1592, 'critic': 1593, 'forest': 1594, 'comcast': 1595, 'bln': 1596, 'spirit': 1597, 'climbed': 1598, 'setting': 1599, 'jack': 1600, 'box': 1601, 'soared': 1602, 'lehman': 1603, 'brother': 1604, 'treo': 1605, 'palmone': 1606, 'licensing': 1607, 'generation': 1608, 'smart': 1609, 'directly': 1610, 'tap': 1611, 'lost': 1612, 'stephen': 1613, 'deputy': 1614, 'named': 1615, 'symantec': 1616, 'veritas': 1617, 'common': 1618, 'citigroup': 1619, 'banking': 1620, 'qantas': 1621, 'route': 1622, 'alliance': 1623, 'pair': 1624, 'trying': 1625, 'meet': 1626, 'berlusconi': 1627, 'putin': 1628, 'prize': 1629, 'referendum': 1630, 'turkey': 1631, 'membership': 1632, 'several': 1633, 'let': 1634, 'decide': 1635, 'voted': 1636, 'return': 1637, 'immediately': 1638, 'extension': 1639, 'water': 1640, 'reality': 1641, 'passed': 1642, 'sea': 1643, 'milestone': 1644, 'stayed': 1645, 'blood': 1646, 'acquired': 1647, 'station': 1648, 'shell': 1649, 'invest': 1650, 'shake': 1651, 'browser': 1652, 'information': 1653, 'widely': 1654, 'digital': 1655, 'camera': 1656, 'partnership': 1657, 'improving': 1658, 'press': 1659, 'significant': 1660, 'peak': 1661, 'milwaukee': 1662, 'paul': 1663, 'story': 1664, 'baseball': 1665, 'straight': 1666, 'predicted': 1667, 'seattle': 1668, 'miner': 1669, 'un': 1670, 'reveals': 1671, 'especially': 1672, 'r': 1673, 'fan': 1674, 'secure': 1675, 'site': 1676, 'northeast': 1677, 'also': 1678, 'fully': 1679, 'association': 1680, 'blamed': 1681, 'beat': 1682, 'worth': 1683, 'shook': 1684, 'secret': 1685, 'winning': 1686, 'streak': 1687, 'cellphone': 1688, 'flaw': 1689, 'handset': 1690, 'travel': 1691, 'pfizer': 1692, 'popular': 1693, 'royal': 1694, 'police': 1695, 'gear': 1696, 'although': 1697, 'cowboy': 1698, 'marketing': 1699, 'inside': 1700, 'pentagon': 1701, 'course': 1702, 'mad': 1703, 'cow': 1704, 'animal': 1705, 'clean': 1706, 'david': 1707, 'moving': 1708, 'bar': 1709, 'glazer': 1710, 'malcolm': 1711, 'swiss': 1712, 'resource': 1713, 'edged': 1714, 'bolster': 1715, 'confident': 1716, 'row': 1717, 'brussels': 1718, 'brought': 1719, 'guy': 1720, 'pulled': 1721, 'contest': 1722, 'asks': 1723, 'value': 1724, 'capacity': 1725, 'politics': 1726, 'coach': 1727, 'civilian': 1728, 'mount': 1729, 'added': 1730, 'struggle': 1731, 'class': 1732, 'nd': 1733, 'material': 1734, 'cellular': 1735, 'giving': 1736, 'spend': 1737, 'philippine': 1738, 'rd': 1739, 'recall': 1740, 'blockbuster': 1741, 'pain': 1742, 'hotel': 1743, 'usatoday': 1744, 'activity': 1745, 'delivery': 1746, 'athletic': 1747, 'shoe': 1748, 'improved': 1749, 'adding': 1750, 'pace': 1751, 'semiconductor': 1752, 'micro': 1753, 'flash': 1754, 'memory': 1755, 'cross': 1756, 'border': 1757, 'bargain': 1758, 'breaking': 1759, 'waiting': 1760, 'northwest': 1761, 'distribution': 1762, 'nigeria': 1763, 'nigerian': 1764, 'copy': 1765, 'extra': 1766, 'path': 1767, 'voice': 1768, 'motorola': 1769, 'area': 1770, 'cnn': 1771, 'champion': 1772, 'member': 1773, 'ca': 1774, 'associate': 1775, 'promised': 1776, 'santander': 1777, 'eas': 1778, 'expands': 1779, 'size': 1780, 'realnetworks': 1781, 'download': 1782, 'ending': 1783, 'cable': 1784, 'via': 1785, 'subscriber': 1786, 'heavyweight': 1787, 'academic': 1788, 'warming': 1789, 'nuclear': 1790, 'continues': 1791, 'produce': 1792, 'different': 1793, 'holy': 1794, 'operator': 1795, 'georgia': 1796, 'headed': 1797, 'plea': 1798, 'letter': 1799, 'ray': 1800, 'retirement': 1801, 'sometimes': 1802, 'offense': 1803, 'demanding': 1804, 'failed': 1805, 'adviser': 1806, 'farm': 1807, 'awaited': 1808, 'craig': 1809, 'conway': 1810, 'ford': 1811, 'argentina': 1812, 'cooperation': 1813, 'document': 1814, 'putting': 1815, 'returned': 1816, 'wait': 1817, 'robert': 1818, 'pact': 1819, 'settlement': 1820, 'carrying': 1821, 'ministry': 1822, 'pro': 1823, 'built': 1824, 'writer': 1825, 'extending': 1826, 'officially': 1827, 'associated': 1828, 'ability': 1829, 'dropped': 1830, 'event': 1831, 'broadcast': 1832, 'leave': 1833, 'wi': 1834, 'fi': 1835, 'speed': 1836, 'emerging': 1837, 'eye': 1838, 'advantage': 1839, 'mouse': 1840, 'fit': 1841, 'launching': 1842, 'woe': 1843, 'feel': 1844, 'soldier': 1845, 'agent': 1846, 'put': 1847, 'deadline': 1848, 'resolution': 1849, 'ill': 1850, 'resident': 1851, 'reject': 1852, 'spain': 1853, 'complete': 1854, 'goal': 1855, 'assembly': 1856, 'designed': 1857, 'body': 1858, 'touch': 1859, 'mac': 1860, 'difference': 1861, 'jungle': 1862, 'website': 1863, 'quest': 1864, 'ipod': 1865, 'promise': 1866, 'live': 1867, 'science': 1868, 'deliver': 1869, 'publishing': 1870, 'gun': 1871, 'montreal': 1872, 'brazil': 1873, 'congress': 1874, 'send': 1875, 'cell': 1876, 'apple': 1877, 'others': 1878, 'lcd': 1879, 'infringement': 1880, 'display': 1881, 'chance': 1882, 'curb': 1883, 'vice': 1884, 'north': 1885, 'carolina': 1886, 'blow': 1887, 'researcher': 1888, 'project': 1889, 'chile': 1890, 'western': 1891, 'id': 1892, 'identity': 1893, 'sweet': 1894, 'bitter': 1895, 'far': 1896, 'fly': 1897, 'theft': 1898, 'sentenced': 1899, 'prison': 1900, 'april': 1901, 'cloud': 1902, 'creating': 1903, 'reduction': 1904, 'smith': 1905, 'west': 1906, 'pull': 1907, 'middle': 1908, 'admits': 1909, 'southeast': 1910, 'audit': 1911, 'hugo': 1912, 'chavez': 1913, 'charged': 1914, 'electoral': 1915, 'solid': 1916, 'reporter': 1917, 'wisconsin': 1918, 'closer': 1919, 'gathered': 1920, 'victory': 1921, 'debut': 1922, 'anticipated': 1923, 'raising': 1924, 'explosive': 1925, 'homeland': 1926, 'door': 1927, 'handed': 1928, 'spokesman': 1929, 'brazilian': 1930, 'server': 1931, 'shock': 1932, 'poll': 1933, 'soar': 1934, 'hat': 1935, 'jr': 1936, 'kevin': 1937, 'needed': 1938, 'recover': 1939, 'rest': 1940, 'virginia': 1941, 'powerful': 1942, 'supercomputer': 1943, 'failure': 1944, 'austrian': 1945, 'va': 1946, 'recently': 1947, 'cisco': 1948, 'walk': 1949, 'henry': 1950, 'abuse': 1951, 'journalist': 1952, 'standing': 1953, 'rejected': 1954, 'mexico': 1955, 'transfer': 1956, 'reward': 1957, 'atop': 1958, 'non': 1959, 'guard': 1960, 'expanding': 1961, 'treatment': 1962, 'acquires': 1963, 'continent': 1964, 'stem': 1965, 'hearing': 1966, 'novell': 1967, 'option': 1968, 'ed': 1969, 'electronic': 1970, 'navy': 1971, 'sky': 1972, 'vladimir': 1973, 'economist': 1974, 'safety': 1975, 'injured': 1976, 'chart': 1977, 'representative': 1978, 'together': 1979, 'opportunity': 1980, 'pass': 1981, 'answer': 1982, 'ship': 1983, 'govt': 1984, 'defence': 1985, 'contractor': 1986, 'spacecraft': 1987, 'sport': 1988, 'nepal': 1989, 'tour': 1990, 'tourist': 1991, 'rebel': 1992, 'joe': 1993, 'bringing': 1994, 'tie': 1995, 'wounded': 1996, 'southeastern': 1997, 'looking': 1998, 'whose': 1999, 'delivered': 2000, 'fought': 2001, 'speech': 2002, 'signing': 2003, 'everyone': 2004, 'winner': 2005, 'opinion': 2006, 'column': 2007, 'fastest': 2008, 'training': 2009, 'commander': 2010, 'award': 2011, 'missile': 2012, 'fails': 2013, 'prepared': 2014, 'similar': 2015, 'read': 2016, 'gave': 2017, 'century': 2018, 'barcelona': 2019, 'ebay': 2020, 'irish': 2021, 'italy': 2022, 'head': 2023, 'tool': 2024, 'repair': 2025, 'fossil': 2026, 'positive': 2027, 'believe': 2028, 'dc': 2029, 'netherlands': 2030, 'suffered': 2031, 'ice': 2032, 'crash': 2033, 'surprise': 2034, 'baltimore': 2035, 'stalled': 2036, 'threw': 2037, 'bridge': 2038, 'titan': 2039, 'pack': 2040, 'watched': 2041, 'transaction': 2042, 'critical': 2043, 'foot': 2044, 'voting': 2045, 'always': 2046, 'society': 2047, 'rebound': 2048, 'created': 2049, 'pt': 2050, 'hear': 2051, 'asking': 2052, 'imposed': 2053, 'ground': 2054, 'heat': 2055, 'feeling': 2056, 'loses': 2057, 'halt': 2058, 'zone': 2059, 'worse': 2060, 'overnight': 2061, 'condition': 2062, 'however': 2063, 'going': 2064, 'preview': 2065, 'introduced': 2066, 'carry': 2067, 'processor': 2068, 'multimedia': 2069, 'feature': 2070, 'include': 2071, 'mp': 2072, 'capability': 2073, 'thought': 2074, 'spring': 2075, 'evening': 2076, 'planning': 2077, 'peer': 2078, 'danger': 2079, 'series': 2080, 'funding': 2081, 'burst': 2082, 'copyright': 2083, 'act': 2084, 'england': 2085, 'hiring': 2086, 'buffalo': 2087, 'turning': 2088, 'locked': 2089, 'easily': 2090, 'escape': 2091, 'de': 2092, 'specie': 2093, 'bob': 2094, 'wife': 2095, 'grand': 2096, 'university': 2097, 'threatening': 2098, 'ivory': 2099, 'protest': 2100, 'attacked': 2101, 'cause': 2102, 'actually': 2103, 'iraqi': 2104, 'hurdle': 2105, 'welcomed': 2106, 'seventh': 2107, 'match': 2108, 'colorado': 2109, 'placed': 2110, 'wanted': 2111, 'total': 2112, 'bet': 2113, 'overall': 2114, 'kind': 2115, 'el': 2116, 'plot': 2117, 'israel': 2118, 'die': 2119, 'age': 2120, 'opening': 2121, 'milan': 2122, 'flow': 2123, 'instead': 2124, 'resort': 2125, 'delhi': 2126, 'laboratory': 2127, 'grab': 2128, 'fighting': 2129, 'completed': 2130, 'special': 2131, 'crucial': 2132, 'star': 2133, 'pas': 2134, 'sixth': 2135, 'hall': 2136, 'bloc': 2137, 'supreme': 2138, 'tomorrow': 2139, 'urge': 2140, 'spread': 2141, 'ten': 2142, 'difficult': 2143, 'process': 2144, 'count': 2145, 'ousted': 2146, 'alive': 2147, 'wider': 2148, 'wrap': 2149, 'seemed': 2150, 'suspect': 2151, 'scientist': 2152, 'angeles': 2153, 'lion': 2154, 'crm': 2155, 'sen': 2156, 'shown': 2157, 'photo': 2158, 'democrat': 2159, 'integration': 2160, 'belief': 2161, 'social': 2162, 'laden': 2163, 'tree': 2164, 'east': 2165, 'happy': 2166, 'earned': 2167, 'creation': 2168, 'ken': 2169, 'andre': 2170, 'land': 2171, 'chosen': 2172, 'chemical': 2173, 'pose': 2174, 'earn': 2175, 'greatest': 2176, 'striking': 2177, 'administrator': 2178, 'sbc': 2179, 'doubled': 2180, 'measure': 2181, 'vow': 2182, 'vowed': 2183, 'quit': 2184, 'connection': 2185, 'storage': 2186, 'backup': 2187, 'town': 2188, 'string': 2189, 'toshiba': 2190, 'revealed': 2191, 'console': 2192, 'sean': 2193, 'famous': 2194, 'poland': 2195, 'adam': 2196, 'bit': 2197, 'ac': 2198, 'earth': 2199, 'nec': 2200, 'gene': 2201, 'handheld': 2202, 'watching': 2203, 'taken': 2204, 'messaging': 2205, 'vendor': 2206, 'role': 2207, 'monitoring': 2208, 'investigator': 2209, 'determine': 2210, 'rivalry': 2211, 'original': 2212, 'sir': 2213, 'bombing': 2214, 'egypt': 2215, 'beef': 2216, 'resume': 2217, 'arrested': 2218, 'art': 2219, 'nfl': 2220, 'offensive': 2221, 'unveiled': 2222, 'berlin': 2223, 'dramatic': 2224, 'fellow': 2225, 'toll': 2226, 'connecticut': 2227, 'gateway': 2228, 'freed': 2229, 'stage': 2230, 'defended': 2231, 'wild': 2232, 'forget': 2233, 'missed': 2234, 'sentence': 2235, 'later': 2236, 'button': 2237, 'bear': 2238, 'suspected': 2239, 'fox': 2240, 'denied': 2241, 'fate': 2242, 'yahoo': 2243, 'xp': 2244, 'living': 2245, 'spur': 2246, 'rbi': 2247, 'cd': 2248, 'coalition': 2249, 'vietnam': 2250, 'arrived': 2251, 'gone': 2252, 'ohio': 2253, 'spyware': 2254, 'dell': 2255, 'prince': 2256, 'availability': 2257, 'kick': 2258, 'defends': 2259, 'monitor': 2260, 'round': 2261, 'protect': 2262, 'tell': 2263, 'computing': 2264, 'silver': 2265, 'recording': 2266, 'traditional': 2267, 'included': 2268, 'affair': 2269, 'silicon': 2270, 'defeat': 2271, 'terrorism': 2272, 'host': 2273, 'boom': 2274, 'committed': 2275, 'easing': 2276, 'indiana': 2277, 'ryder': 2278, 'transport': 2279, 'andrew': 2280, 'ball': 2281, 'agenda': 2282, 'spammer': 2283, 'king': 2284, 'allegedly': 2285, 'premier': 2286, 'piece': 2287, 'birth': 2288, 'task': 2289, 'desktop': 2290, 'platform': 2291, 'clash': 2292, 'feared': 2293, 'passing': 2294, 'mission': 2295, 'pool': 2296, 'gaming': 2297, 'draw': 2298, 'thomson': 2299, 'wind': 2300, 'mississippi': 2301, 'oklahoma': 2302, 'dominated': 2303, 'dna': 2304, 'struggled': 2305, 'targeted': 2306, 'jury': 2307, 'introduce': 2308, 'request': 2309, 'welcome': 2310, 'camp': 2311, 'alternative': 2312, 'historic': 2313, 'prior': 2314, 'martin': 2315, 'mass': 2316, 'tackle': 2317, 'hot': 2318, 'marked': 2319, 'caribbean': 2320, 'networking': 2321, 'port': 2322, 'eighth': 2323, 'career': 2324, 'spot': 2325, 'lot': 2326, 'weapon': 2327, 'replacement': 2328, 'jose': 2329, 'crew': 2330, 'desert': 2331, 'austria': 2332, 'quick': 2333, 'andy': 2334, 'olympic': 2335, 'greece': 2336, 'athens': 2337, 'greek': 2338, 'criticism': 2339, 'deciding': 2340, 'seal': 2341, 'drove': 2342, 'nothing': 2343, 'arrest': 2344, 'nobel': 2345, 'edition': 2346, 'eastern': 2347, 'info': 2348, 'feed': 2349, 'attention': 2350, 'dog': 2351, 'alleged': 2352, 'strategy': 2353, 'justin': 2354, 'jaguar': 2355, 'miami': 2356, 'michigan': 2357, 'celebrate': 2358, 'accident': 2359, 'kansa': 2360, 'militia': 2361, 'targeting': 2362, 'currently': 2363, 'tennessee': 2364, 'prepare': 2365, 'franchise': 2366, 'harry': 2367, 'allows': 2368, 'stood': 2369, 'pakistan': 2370, 'appeared': 2371, 'ninth': 2372, 'clock': 2373, 'cup': 2374, 'linux': 2375, 'munich': 2376, 'denies': 2377, 'lee': 2378, 'erp': 2379, 'relation': 2380, 'responsible': 2381, 'kill': 2382, 'veteran': 2383, 'institute': 2384, 'paper': 2385, 'picked': 2386, 'son': 2387, 'x': 2388, 'district': 2389, 'minnesota': 2390, 'counting': 2391, 'client': 2392, 'train': 2393, 'kid': 2394, 'van': 2395, 'gaza': 2396, 'strip': 2397, 'swedish': 2398, 'palmsource': 2399, 'turkish': 2400, 'ride': 2401, 'usc': 2402, 'aboard': 2403, 'entered': 2404, 'hunting': 2405, 'trip': 2406, 'error': 2407, 'complaint': 2408, 'contact': 2409, 'libya': 2410, 'coup': 2411, 'joined': 2412, 'earthquake': 2413, 'successful': 2414, 'dual': 2415, 'golf': 2416, 'redskin': 2417, 'influence': 2418, 'format': 2419, 'slam': 2420, 'israeli': 2421, 'engineer': 2422, 'rover': 2423, 'shanghai': 2424, 'korean': 2425, 'dallas': 2426, 'fair': 2427, 'map': 2428, 'met': 2429, 'multi': 2430, 'province': 2431, 'prepares': 2432, 'najaf': 2433, 'sparked': 2434, 'opponent': 2435, 'scene': 2436, 'arena': 2437, 'killed': 2438, 'centre': 2439, 'suspension': 2440, 'master': 2441, 'boy': 2442, 'born': 2443, 'testing': 2444, 'refugee': 2445, 'embargo': 2446, 'stepped': 2447, 'scott': 2448, 'devil': 2449, 'tank': 2450, 'talking': 2451, 'suite': 2452, 'league': 2453, 'jeeves': 2454, 'catch': 2455, 'orleans': 2456, 'newsfactor': 2457, 'island': 2458, 'started': 2459, 'overhaul': 2460, 'k': 2461, 'sox': 2462, 'playing': 2463, 'proved': 2464, 'celtic': 2465, 'potentially': 2466, 'lineup': 2467, 'blast': 2468, 'liverpool': 2469, 'voter': 2470, 'nvidia': 2471, 'graphic': 2472, 'hewlett': 2473, 'packard': 2474, 'lab': 2475, 'pitch': 2476, 'clue': 2477, 'club': 2478, 'sharing': 2479, 'ally': 2480, 'observer': 2481, 'appointed': 2482, 'crack': 2483, 'philip': 2484, 'fact': 2485, 'tony': 2486, 'tied': 2487, 'caught': 2488, 'uranium': 2489, 'crowd': 2490, 'unveil': 2491, 'illegally': 2492, 'laptop': 2493, 'appear': 2494, 'example': 2495, 'truce': 2496, 'cleveland': 2497, 'ballot': 2498, 'older': 2499, 'favorite': 2500, 'racing': 2501, 'throw': 2502, 'ii': 2503, 'driver': 2504, 'hd': 2505, 'orlando': 2506, 'label': 2507, 'oakland': 2508, 'sexual': 2509, 'nl': 2510, 'heading': 2511, 'missing': 2512, 'pursue': 2513, 'triumph': 2514, 'rumor': 2515, 'mar': 2516, 'tear': 2517, 'siege': 2518, 'taiwan': 2519, 'semi': 2520, 'everything': 2521, 'magic': 2522, 'aide': 2523, 'nintendo': 2524, 'portable': 2525, 'communist': 2526, 'marathon': 2527, 'tom': 2528, 'robot': 2529, 'helicopter': 2530, 'crashed': 2531, 'capsule': 2532, 'nasa': 2533, 'bird': 2534, 'amd': 2535, 'assault': 2536, 'blog': 2537, 'captain': 2538, 'verdana': 2539, 'sans': 2540, 'serif': 2541, 'arial': 2542, 'helvetica': 2543, 'color': 2544, 'washingtonpost': 2545, 'font': 2546, 'sp': 2547, 'quite': 2548, 'spam': 2549, 'planet': 2550, 'love': 2551, 'virtual': 2552, 'itunes': 2553, 'voip': 2554, 'shuttle': 2555, 'rocket': 2556, 'iran': 2557, 'us': 2558, 'tiny': 2559, 'fault': 2560, 'protocol': 2561, 'climate': 2562, 'entry': 2563, 'firefox': 2564, 'roll': 2565, 'code': 2566, 'trojan': 2567, 'horse': 2568, 'text': 2569, 'imac': 2570, 'expo': 2571, 'hacker': 2572, 'artist': 2573, 'cultural': 2574, 'playstation': 2575, 'explorer': 2576, 'o': 2577, 'bowl': 2578, 'medal': 2579, 'athlete': 2580, 'xbox': 2581, 'andreas': 2582, 'cassini': 2583, 'saturn': 2584, 'fbi': 2585, 'cyber': 2586, 'audio': 2587, 'orbit': 2588, 'maccentral': 2589, 'sex': 2590, 'infoworld': 2591, 'teenager': 2592, 'rolled': 2593, 'msn': 2594, 'cancel': 2595, 'shoot': 2596, 'murder': 2597, 'orange': 2598, 'becoming': 2599, 'solar': 2600, 'soviet': 2601, 'longhorn': 2602, 'grid': 2603, 'arctic': 2604, 'palm': 2605, 'vulnerability': 2606, 'cloning': 2607, 'ancient': 2608, 'explosion': 2609, 'gary': 2610, 'religious': 2611, 'trick': 2612, 'psp': 2613, 'beta': 2614, 'experiment': 2615, 'knee': 2616, 'piracy': 2617, 'leg': 2618, 'violent': 2619, 'lake': 2620, 'jacques': 2621, 'pda': 2622, 'submarine': 2623, 'memphis': 2624, 'ziff': 2625, 'davis': 2626, 'adapter': 2627, 'claimed': 2628, 'killing': 2629, 'itanium': 2630, 'tiger': 2631, 'domain': 2632, 'relay': 2633, 'powell': 2634, 'floor': 2635, 'captured': 2636, 'curt': 2637, 'columbia': 2638, 'beach': 2639, 'helen': 2640, 'movement': 2641, 'briton': 2642, 'surface': 2643, 'elephant': 2644, 'broken': 2645, 'pentium': 2646, 'czech': 2647, 'ie': 2648, 'draft': 2649, 'landmark': 2650, 'ghz': 2651, 'beckham': 2652, 'football': 2653, 'hill': 2654, 'mike': 2655, 'remote': 2656, 'chris': 2657, 'bomb': 2658, 'williams': 2659, 'sure': 2660, 'unix': 2661, 'km': 2662, 'astronomer': 2663, 'gov': 2664, 'formally': 2665, 'wing': 2666, 'africa': 2667, 'tennis': 2668, 'championship': 2669, 'tournament': 2670, 'organic': 2671, 'explain': 2672, 'identified': 2673, 'girl': 2674, 'female': 2675, 'incident': 2676, 'bryant': 2677, 'nba': 2678, 'kobe': 2679, 'starter': 2680, 'kim': 2681, 'sized': 2682, 'doping': 2683, 'couple': 2684, 'dolphin': 2685, 'evacuation': 2686, 'village': 2687, 'bull': 2688, 'chad': 2689, 'fish': 2690, 'allen': 2691, 'peru': 2692, 'blame': 2693, 'netscape': 2694, 'atomic': 2695, 'hawk': 2696, 'thailand': 2697, 'madrid': 2698, 'strained': 2699, 'tropical': 2700, 'scored': 2701, 'interior': 2702, 'squad': 2703, 'wayne': 2704, 'yard': 2705, 'strain': 2706, 'symbian': 2707, 'brave': 2708, 'tsunami': 2709, 'router': 2710, 'band': 2711, 'techweb': 2712, 'yankee': 2713, 'minute': 2714, 'tonight': 2715, 'ryan': 2716, 'iowa': 2717, 'unknown': 2718, 'crown': 2719, 'bus': 2720, 'viking': 2721, 'republic': 2722, 'anniversary': 2723, 'assassination': 2724, 'legend': 2725, 'drew': 2726, 'dy': 2727, 'utah': 2728, 'rain': 2729, 'hopeful': 2730, 'christian': 2731, 'protester': 2732, 'quake': 2733, 'freedom': 2734, 'louisville': 2735, 'swimming': 2736, 'lunar': 2737, 'seed': 2738, 'exploded': 2739, 'seized': 2740, 'sweep': 2741, 'arrives': 2742, 'rare': 2743, 'tim': 2744, 'nascar': 2745, 'flood': 2746, 'raid': 2747, 'humanitarian': 2748, 'activist': 2749, 'convicted': 2750, 'islamabad': 2751, 'pakistani': 2752, 'showdown': 2753, 'jackson': 2754, 'hostage': 2755, 'bigley': 2756, 'cub': 2757, 'meter': 2758, 'supporter': 2759, 'alex': 2760, 'busy': 2761, 'father': 2762, 'wood': 2763, 'steroid': 2764, 'patrick': 2765, 'syria': 2766, 'stadium': 2767, 'islamic': 2768, 'visit': 2769, 'par': 2770, 'arsenal': 2771, 'insurgent': 2772, 'baghdad': 2773, 'gunman': 2774, 'receiver': 2775, 'angel': 2776, 'inning': 2777, 'scoring': 2778, 'anaheim': 2779, 'athletics': 2780, 'unbeaten': 2781, 'manchester': 2782, 'phelps': 2783, 'teammate': 2784, 'colt': 2785, 'sri': 2786, 'lanka': 2787, 'defeated': 2788, 'prix': 2789, 'bernie': 2790, 'mauresmo': 2791, 'amelie': 2792, 'uefa': 2793, 'soccer': 2794, 'visiting': 2795, 'barry': 2796, 'quarterback': 2797, 'cuba': 2798, 'ichiro': 2799, 'mariner': 2800, 'jay': 2801, 'tampa': 2802, 'pitcher': 2803, 'rookie': 2804, 'basketball': 2805, 'pittsburgh': 2806, 'upset': 2807, 'lakers': 2808, 'ranger': 2809, 'homer': 2810, 'striker': 2811, 'manning': 2812, 'newcastle': 2813, 'opener': 2814, 'singh': 2815, 'touchdown': 2816, 'qualifier': 2817, 'premiership': 2818, 'mets': 2819, 'schilling': 2820, 'chelsea': 2821, 'juventus': 2822, 'owen': 2823, 'english': 2824, 'midfielder': 2825, 'wenger': 2826, 'wicket': 2827, 'dodger': 2828, 'ticker': 2829, 'brawl': 2830, 'nhl': 2831, 'sharapova': 2832, 'maria': 2833, 'federer': 2834, 'busch': 2835, 'defensive': 2836, 'steelers': 2837, 'playoff': 2838, 'rafael': 2839, 'pitched': 2840, 'jordan': 2841, 'wizard': 2842, 'packer': 2843, 'hamm': 2844, 'comeback': 2845, 'pga': 2846, 'semifinal': 2847, 'cricket': 2848, 'safin': 2849, 'ncaa': 2850, 'defending': 2851, 'brian': 2852, 'icc': 2853, 'trophy': 2854, 'denver': 2855, 'formula': 2856, 'ferguson': 2857, 'agassi': 2858, 'raven': 2859, 'hockey': 2860, 'notre': 2861, 'dame': 2862, 'coaching': 2863, 'qualifying': 2864, 'battled': 2865, 'oriole': 2866, 'astros': 2867, 'roger': 2868, 'clemens': 2869, 'er': 2870, 'robinson': 2871, 'garcia': 2872, 'pedro': 2873, 'martinez': 2874, 'henman': 2875, 'davenport': 2876, 'defender': 2877, 'inter': 2878, 'trainer': 2879, 'embassy': 2880, 'postseason': 2881, 'seeded': 2882, 'quarterfinal': 2883, 'patriot': 2884, 'bronco': 2885, 'pole': 2886, 'colin': 2887, 'pacer': 2888, 'pennington': 2889, 'charger': 2890, 'zimbabwe': 2891, 'racism': 2892, 'bangladesh': 2893, 'ankle': 2894, 'auburn': 2895, 'vijay': 2896, 'jason': 2897, 'torn': 2898, 'rugby': 2899, 'hewitt': 2900, 'lleyton': 2901, 'withdraw': 2902, 'roddick': 2903, 'injuring': 2904, 'trafford': 2905, 'phillies': 2906, 'marriage': 2907, 'arab': 2908, 'tape': 2909, 'rape': 2910, 'ukraine': 2911, 'catholic': 2912, 'fighter': 2913, 'tension': 2914, 'corruption': 2915, 'kidnapper': 2916, 'kidnapped': 2917, 'abducted': 2918, 'khan': 2919, 'muslim': 2920, 'calm': 2921, 'shooting': 2922, 'chen': 2923, 'afghan': 2924, 'bomber': 2925, 'sadr': 2926, 'shrine': 2927, 'mosque': 2928, 'cleric': 2929, 'sudan': 2930, 'detained': 2931, 'hassan': 2932, 'palestinian': 2933, 'militant': 2934, 'checkpoint': 2935, 'afghanistan': 2936, 'arafat': 2937, 'yasser': 2938, 'kabul': 2939, 'allawi': 2940, 'saddam': 2941, 'hussein': 2942, 'sudanese': 2943, 'darfur': 2944, 'blair': 2945, 'jazeera': 2946, 'wounding': 2947, 'karzai': 2948, 'hamid': 2949, 'jewish': 2950, 'haiti': 2951, 'sharon': 2952, 'typhoon': 2953, 'parliament': 2954, 'pyongyang': 2955, 'detainee': 2956, 'ariel': 2957, 'fallujah': 2958, 'egyptian': 2959, 'democracy': 2960, 'congo': 2961, 'prisoner': 2962, 'thai': 2963, 'beslan': 2964, 'kashmir': 2965, 'jerusalem': 2966, 'mosul': 2967, 'hamas': 2968, 'dialogue': 2969, 'shiite': 2970, 'muqtada': 2971, 'pervez': 2972, 'musharraf': 2973, 'iranian': 2974, 'tehran': 2975, 'manmohan': 2976, 'bin': 2977, 'guinea': 2978, 'margaret': 2979, 'milosevic': 2980, 'hague': 2981, 'guantanamo': 2982, 'settler': 2983, 'separatist': 2984, 'envoy': 2985, 'qaeda': 2986, 'sunni': 2987, 'peacekeeper': 2988, 'kofi': 2989, 'annan': 2990, 'stronghold': 2991, 'cambodia': 2992, 'lebanese': 2993, 'lebanon': 2994, 'nato': 2995, 'taliban': 2996, 'enrichment': 2997}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.news_vocab._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.category_vocab._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._max_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_for_fine_tune(embedding_size, num_channels, hidden_dim, dropout_p, pretrained_embeddings, emb_freeze, batch_size):\n",
    "    set_seed_everywhere(args.seed, args.cuda, args.mps)\n",
    "    \n",
    "    args.batch_size = batch_size\n",
    "    classifier = NewsClassifier(embedding_size=embedding_size,          # e.g, 100\n",
    "                                num_embeddings=len(vectorizer.news_vocab),  # e.g., 3409\n",
    "                                num_channels=num_channels,              # e.g., 100\n",
    "                                hidden_dim=args.hidden_dim,                  # e.g., 100\n",
    "                                num_classes=len(vectorizer.category_vocab),  # e.g., 4\n",
    "                                dropout_p=dropout_p,                    # e.g., 0.1\n",
    "                                pretrained_embeddings=pretrained_embeddings,\n",
    "                                padding_idx=0,\n",
    "                                emb_freeze=emb_freeze)\n",
    "    \n",
    "    if pretrained_embeddings is None:\n",
    "        is_pretrained_embeddings = False\n",
    "    else:\n",
    "        is_pretrained_embeddings = True\n",
    "        \n",
    "    classifier = classifier.to(args.device)\n",
    "    dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "        \n",
    "    loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "    train_state = make_train_state(args)\n",
    "\n",
    "    epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "    dataset.set_split('train')\n",
    "    train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "    dataset.set_split('val')\n",
    "    val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "    try:\n",
    "        for epoch_index in range(args.num_epochs):\n",
    "            train_state['epoch_index'] = epoch_index\n",
    "\n",
    "            # Iterate over training dataset\n",
    "\n",
    "            # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "\n",
    "            dataset.set_split('train')\n",
    "            batch_generator = generate_batches(dataset, \n",
    "                                            batch_size=args.batch_size, \n",
    "                                            device=args.device)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            classifier.train()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "                # the training routine is these 5 steps:\n",
    "\n",
    "                # --------------------------------------\n",
    "                # step 1. zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # step 2. compute the output\n",
    "                y_pred = classifier(batch_dict['x_data']) # (batch, seq_len) -> (batch, num_classes)\n",
    "\n",
    "                # step 3. compute the loss\n",
    "                loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "                loss_t = loss.item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # step 4. use loss to produce gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # step 5. use optimizer to take gradient step\n",
    "                optimizer.step()\n",
    "                # -----------------------------------------\n",
    "                # compute the accuracy\n",
    "                acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "                # update bar\n",
    "                train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                   epoch=epoch_index)\n",
    "                train_bar.update()\n",
    "\n",
    "            train_state['train_loss'].append(running_loss)\n",
    "            train_state['train_acc'].append(running_acc)\n",
    "\n",
    "            # Iterate over val dataset\n",
    "\n",
    "            # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "            dataset.set_split('val')\n",
    "            batch_generator = generate_batches(dataset, \n",
    "                                            batch_size=args.batch_size, \n",
    "                                            device=args.device)\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "            classifier.eval()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "                # compute the output\n",
    "                y_pred =  classifier(batch_dict['x_data'])\n",
    "\n",
    "                # step 3. compute the loss\n",
    "                loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "                loss_t = loss.item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # compute the accuracy\n",
    "                acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "                val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                epoch=epoch_index)\n",
    "                val_bar.update()\n",
    "\n",
    "            train_state['val_loss'].append(running_loss)\n",
    "            train_state['val_acc'].append(running_acc)\n",
    "\n",
    "            train_state = update_train_state(args=args, model=classifier,\n",
    "                                            train_state=train_state)\n",
    "\n",
    "            scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "            if train_state['stop_early']:\n",
    "                break\n",
    "\n",
    "            train_bar.n = 0\n",
    "            val_bar.n = 0\n",
    "            epoch_bar.update()\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Exiting loop\")\n",
    "\n",
    "    acc = train_state['train_acc']\n",
    "    val_acc = train_state['val_acc']\n",
    "    loss = train_state['train_loss']\n",
    "    val_loss = train_state['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    # compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "    classifier.load_state_dict(torch.load(train_state['model_filename'])) # load the best model\n",
    "\n",
    "    classifier = classifier.to(args.device)\n",
    "    dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "    dataset.set_split('test')\n",
    "    batch_generator = generate_batches(dataset, \n",
    "                                    batch_size=args.batch_size, \n",
    "                                    device=args.device)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    classifier.eval()\n",
    "\n",
    "    y_pred_list = []         # store predicted values for confusion matrix\n",
    "    y_category_list = []  # ground truth value\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # compute the output\n",
    "        y_pred =  classifier(batch_dict['x_data'])\n",
    "        \n",
    "        # store predicted values and ground truth values for calculating confusion matrix\n",
    "        y_pred_list.extend(y_pred.max(dim=1)[1].cpu().numpy())\n",
    "        y_category_list.extend(batch_dict['y_target'].cpu().numpy())\n",
    "        \n",
    "        # compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        # compute the accuracy\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "    train_state['test_loss'] = running_loss\n",
    "    train_state['test_acc'] = running_acc\n",
    "    \n",
    "    return [embedding_size, num_channels, hidden_dim, dropout_p, is_pretrained_embeddings, emb_freeze, batch_size, train_state['val_loss'][-1], train_state['val_acc'][-1], train_state['test_loss'], train_state['test_acc']]\n",
    "\n",
    "def simple_grid_search(embedding_size_values, num_channels_values, hidden_dim_values, dropout_p_values, batch_size_values, pretrained_embeddings_values, emb_freeze_values):    \n",
    "    print(\"embedding_size_values:\", embedding_size_values)\n",
    "    print(\"num_channels_values:\", num_channels_values)\n",
    "    print(\"hidden_dim_values:\", hidden_dim_values)\n",
    "    print(\"dropout_p_values:\", dropout_p_values)\n",
    "    print(\"batch_size_values: \", batch_size_values)\n",
    "    \n",
    "    best_by_val_loss = []\n",
    "    best_by_val_acc = []\n",
    "    best_by_test_loss = []\n",
    "    best_by_test_acc = []\n",
    "    \n",
    "    log_path = 'Log_CNN_News_Category.txt'\n",
    "    if os.path.exists(log_path):\n",
    "        os.remove(log_path)\n",
    "        \n",
    "    with open(log_path, 'a') as log:\n",
    "        for pretrained_embeddings_value in pretrained_embeddings_values:\n",
    "            if pretrained_embeddings_value is not None:\n",
    "                print(\"------------Use Pretrain------------\")\n",
    "                log.write(\"------------Use Pretrain------------\\n\")\n",
    "                for emb_freeze_value in emb_freeze_values:\n",
    "                    for num_channels_value in num_channels_values:  \n",
    "                        for hidden_dim_value in hidden_dim_values:\n",
    "                            for dropout_p_value in dropout_p_values:\n",
    "                                for batch_size_value in batch_size_values:\n",
    "                                    print(f\"------args-----\\nnum_channels: {num_channels_value} | hidden_dim: {hidden_dim_value} | dropout_p: {dropout_p_value} | batch_size: {batch_size_value} | emb_freeze: {emb_freeze_value}\")\n",
    "                                    log.write(f\"------args-----\\nnum_channels: {num_channels_value} | hidden_dim: {hidden_dim_value} | dropout_p: {dropout_p_value} | batch_size: {batch_size_value} | emb_freeze: {emb_freeze_value}\\n\")\n",
    "                                    start_time = time.time()\n",
    "                                    result = train_for_fine_tune(100, num_channels_value, hidden_dim_value, dropout_p_value, pretrained_embeddings_value, emb_freeze_value, batch_size_value)\n",
    "                                    end_time = time.time()\n",
    "                                    torch.cuda.empty_cache()\n",
    "                                    if best_by_val_loss == [] or best_by_val_loss[7] > result[7]:\n",
    "                                        best_by_val_loss = result\n",
    "                                    if best_by_val_acc == [] or best_by_val_acc[8] < result[8]:\n",
    "                                        best_by_val_acc = result\n",
    "                                    if best_by_test_loss == [] or best_by_test_loss[9] > result[9]:\n",
    "                                        best_by_test_loss = result\n",
    "                                    if best_by_test_acc == [] or best_by_test_acc[10] < result[10]:\n",
    "                                        best_by_test_acc = result\n",
    "                                    elapsed_time = end_time - start_time\n",
    "                                    print(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\")\n",
    "                                    print(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\")\n",
    "                                    log.write(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\\n\")\n",
    "                                    log.write(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\\n\")\n",
    "            else:\n",
    "                print(\"------Not Use Pretrain------\")\n",
    "                log.write(\"------------Not Use Pretrain------------\\n\")\n",
    "                for embedding_size_value in embedding_size_values:\n",
    "                    for hidden_dim_value in hidden_dim_values:\n",
    "                        for num_channels_value in num_channels_values:  \n",
    "                            for hidden_dim_value in hidden_dim_values:\n",
    "                                for dropout_p_value in dropout_p_values:\n",
    "                                    for batch_size_value in batch_size_values:\n",
    "                                        print(f\"------args-----\\nembedding_size: {embedding_size_value} | num_channels: {num_channels_value} | hidden_dim: {hidden_dim_value} | dropout_p: {dropout_p_value} | batch_size: {batch_size_value}\")\n",
    "                                        log.write(f\"------args-----\\nembedding_size: {embedding_size_value} | num_channels: {num_channels_value} | hidden_dim: {hidden_dim_value} | dropout_p: {dropout_p_value} | batch_size: {batch_size_value}\")\n",
    "                                        start_time = time.time()\n",
    "                                        result = train_for_fine_tune(embedding_size_value, num_channels_value, hidden_dim_value, dropout_p_value, pretrained_embeddings_value, True, batch_size_value)\n",
    "                                        end_time = time.time()\n",
    "                                        torch.cuda.empty_cache()\n",
    "                                        if best_by_val_loss == [] or best_by_val_loss[7] > result[7]:\n",
    "                                            best_by_val_loss = result\n",
    "                                        if best_by_val_acc == [] or best_by_val_acc[8] < result[8]:\n",
    "                                            best_by_val_acc = result\n",
    "                                        if best_by_test_loss == [] or best_by_test_loss[9] > result[9]:\n",
    "                                            best_by_test_loss = result\n",
    "                                        if best_by_test_acc == [] or best_by_test_acc[10] < result[10]:\n",
    "                                            best_by_test_acc = result\n",
    "                                        elapsed_time = end_time - start_time\n",
    "                                        print(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\")\n",
    "                                        print(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\")\n",
    "                                        log.write(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\\n\")\n",
    "                                        log.write(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\\n\")\n",
    "                                                                  \n",
    "        print(\"--------------Best Val Loss--------------\")\n",
    "        print(f\"embedding_size: {best_by_val_loss[0]}\\nnum_channels: {best_by_val_loss[1]}\\nhidden_dim: {best_by_val_loss[2]}\\ndropout_p: {best_by_val_loss[3]}\\nis_pretrained_embeddings: {best_by_val_loss[4]}\\nemb_freeze: {best_by_val_loss[5]}\\nbatch_size: {best_by_val_loss[6]}\\n\")\n",
    "        \n",
    "        print(\"--------------Best Val Acc--------------\")\n",
    "        print(f\"embedding_size: {best_by_val_acc[0]}\\nnum_channels: {best_by_val_acc[1]}\\nhidden_dim: {best_by_val_acc[2]}\\ndropout_p: {best_by_val_acc[3]}\\nis_pretrained_embeddings: {best_by_val_acc[4]}\\nemb_freeze: {best_by_val_acc[5]}\\nbatch_size: {best_by_val_acc[6]}\\n\")\n",
    "        \n",
    "        print(\"--------------Best Test Loss--------------\")\n",
    "        print(f\"embedding_size: {best_by_test_loss[0]}\\nnum_channels: {best_by_test_loss[1]}\\nhidden_dim: {best_by_test_loss[2]}\\ndropout_p: {best_by_test_loss[3]}\\nis_pretrained_embeddings: {best_by_test_loss[4]}\\nemb_freeze: {best_by_test_loss[5]}\\nbatch_size: {best_by_test_loss[6]}\\n\")\n",
    "        \n",
    "        print(\"--------------Best Test Acc--------------\")\n",
    "        print(f\"embedding_size: {best_by_test_acc[0]}\\nnum_channels: {best_by_test_acc[1]}\\nhidden_dim: {best_by_test_acc[2]}\\ndropout_p: {best_by_test_acc[3]}\\nis_pretrained_embeddings: {best_by_test_acc[4]}\\nemb_freeze: {best_by_test_acc[5]}\\nbatch_size: {best_by_test_acc[6]}\\n\")\n",
    "\n",
    "        log.write(\"--------------Best Val Loss--------------\\n\")\n",
    "        log.write(f\"embedding_size: {best_by_val_loss[0]}\\nnum_channels: {best_by_val_loss[1]}\\nhidden_dim: {best_by_val_loss[2]}\\ndropout_p: {best_by_val_loss[3]}\\nis_pretrained_embeddings: {best_by_val_loss[4]}\\nemb_freeze: {best_by_val_loss[5]}\\nbatch_size: {best_by_val_loss[6]}\\n\\n\")\n",
    "        \n",
    "        log.write(\"--------------Best Val Acc--------------\\n\")\n",
    "        log.write(f\"embedding_size: {best_by_val_acc[0]}\\nnum_channels: {best_by_val_acc[1]}\\nhidden_dim: {best_by_val_acc[2]}\\ndropout_p: {best_by_val_acc[3]}\\nis_pretrained_embeddings: {best_by_val_acc[4]}\\nemb_freeze: {best_by_val_acc[5]}\\nbatch_size: {best_by_val_acc[6]}\\n\\n\")\n",
    "        \n",
    "        log.write(\"--------------Best Test Loss--------------\\n\")\n",
    "        log.write(f\"embedding_size: {best_by_test_loss[0]}\\nnum_channels: {best_by_test_loss[1]}\\nhidden_dim: {best_by_test_loss[2]}\\ndropout_p: {best_by_test_loss[3]}\\nis_pretrained_embeddings: {best_by_test_loss[4]}\\nemb_freeze: {best_by_test_loss[5]}\\nbatch_size: {best_by_test_loss[6]}\\n\\n\")\n",
    "        \n",
    "        log.write(\"--------------Best Test Acc--------------\\n\")\n",
    "        log.write(f\"embedding_size: {best_by_test_acc[0]}\\nnum_channels: {best_by_test_acc[1]}\\nhidden_dim: {best_by_test_acc[2]}\\ndropout_p: {best_by_test_acc[3]}\\nis_pretrained_embeddings: {best_by_test_acc[4]}\\nemb_freeze: {best_by_test_acc[5]}\\nbatch_size: {best_by_test_acc[6]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size_values = [i for i in range(64, 161, 32)]\n",
    "num_channels_values = [i for i in range(50, 201, 50)]\n",
    "dropout_p_values = [0.2, 0.5]\n",
    "hidden_dim_values = [i for i in range(64, 513, 64)]\n",
    "batch_size_values = [i for i in range(64, 193, 32)]\n",
    "pretrained_embeddings_values = [embeddings]\n",
    "emb_freeze_values = [False]\n",
    "\n",
    "run = False\n",
    "if run:\n",
    "    simple_grid_search(embedding_size_values, num_channels_values, hidden_dim_values, dropout_p_values, batch_size_values, pretrained_embeddings_values, emb_freeze_values)\n",
    "    args.embedding_size=100\n",
    "    args.num_channels=100\n",
    "    args.hidden_dim=320\n",
    "    args.dropout_p=0.2\n",
    "    args.use_glove=True\n",
    "    args.emb_freeze=False\n",
    "    args.batch_size=160\n",
    "    \n",
    "    if args.use_glove:\n",
    "        words = vectorizer.news_vocab._token_to_idx.keys()  # 3409 unique words\n",
    "        embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath,     # embeddings: (3409, 100)\n",
    "                                        words=words)\n",
    "        print(\"Using pre-trained embeddings\")\n",
    "    else:\n",
    "        print(\"Not using pre-trained embeddings\")\n",
    "        embeddings = None\n",
    "        \n",
    "    classifier = NewsClassifier(embedding_size=args.embedding_size,          # e.g, 100\n",
    "                            num_embeddings=len(vectorizer.news_vocab),  # e.g., 3409\n",
    "                            num_channels=args.num_channels,              # e.g., 100\n",
    "                            hidden_dim=args.hidden_dim,                  # e.g., 100\n",
    "                            num_classes=len(vectorizer.category_vocab),  # e.g., 4\n",
    "                            dropout_p=args.dropout_p,                    # e.g., 0.1\n",
    "                            pretrained_embeddings=embeddings,\n",
    "                            padding_idx=0,\n",
    "                            emb_freeze=args.emb_freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NewsClassifier(embedding_size=args.embedding_size,          # e.g, 100\n",
    "                        num_embeddings=len(vectorizer.news_vocab),  # e.g., 3409\n",
    "                        num_channels=args.num_channels,              # e.g., 100\n",
    "                        hidden_dim=args.hidden_dim,                  # e.g., 100\n",
    "                        num_classes=len(vectorizer.category_vocab),  # e.g., 4\n",
    "                        dropout_p=args.dropout_p,                    # e.g., 0.1\n",
    "                        pretrained_embeddings=embeddings,\n",
    "                        padding_idx=0,\n",
    "                        emb_freeze=args.emb_freeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006b1b294bd94100bb915401be31cfd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481ba3bb14744bb58960b7b732704821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49aae94dcbcb4f6ab8eb5a1f723b7199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------\n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(batch_dict['x_data']) # (batch, seq_len) -> (batch, num_classes)\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                  epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred =  classifier(batch_dict['x_data'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename'])) # load the best model\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                batch_size=args.batch_size, \n",
    "                                device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_category_list = []  # ground truth value\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_data'])\n",
    "    \n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_list.extend(y_pred.max(dim=1)[1].cpu().numpy())\n",
    "    y_category_list.extend(batch_dict['y_target'].cpu().numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.35099067200313916;\n",
      "Test Accuracy: 89.31818181818181\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business', 'Sci/Tech', 'Sports', 'World']\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "for i in range(len(dataset._vectorizer.category_vocab)):\n",
    "    classes.append(dataset._vectorizer.category_vocab.lookup_index(i))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True       Business  Sci/Tech  Sports  World\n",
      "Predicted                                   \n",
      "Business        364        35       4     21\n",
      "Sci/Tech         39       398       7     13\n",
      "Sports            3         4     416     12\n",
      "World            31         9      10    394\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_category_list, y_pred_list)\n",
    "cm_df = pd.DataFrame(cm.T, index=classes, columns=classes)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       437\n",
      "           1       0.87      0.89      0.88       446\n",
      "           2       0.96      0.95      0.95       437\n",
      "           3       0.89      0.90      0.89       440\n",
      "\n",
      "    accuracy                           0.89      1760\n",
      "   macro avg       0.89      0.89      0.89      1760\n",
      "weighted avg       0.89      0.89      0.89      1760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_category_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the reviews\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(title, classifier, vectorizer, max_length):\n",
    "    \"\"\"Predict a News category for a new title\n",
    "    \n",
    "    Args:\n",
    "        title (str): a raw title string\n",
    "        classifier (NewsClassifier): an instance of the trained classifier\n",
    "        vectorizer (NewsVectorizer): the corresponding vectorizer\n",
    "        max_length (int): the max sequence length\n",
    "            Note: CNNs are sensitive to the input data tensor size. \n",
    "                  This ensures to keep it the same size as the training data\n",
    "    \"\"\"\n",
    "    title = preprocess_text(title)\n",
    "    vectorized_title = \\\n",
    "        torch.tensor(vectorizer.vectorize(title, vector_length=max_length))\n",
    "    result = classifier(vectorized_title.unsqueeze(0), apply_softmax=True)\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    predicted_category = vectorizer.category_vocab.lookup_index(indices.item())\n",
    "\n",
    "    return {'category': predicted_category, \n",
    "            'probability': probability_values.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples():\n",
    "    samples = {}\n",
    "    for cat in dataset.val_df.category.unique():\n",
    "        samples[cat] = dataset.val_df.text[dataset.val_df.category==cat].tolist()[:5]\n",
    "    return samples\n",
    "\n",
    "val_samples = get_samples() # first 5 titles of each category from validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Category: Business\n",
      "==============================\n",
      "Prediction: Business (p=0.88)\n",
      "\t + Sample: sony group group buy buy mgm mgm consortium consortium led led sony sony corp corp agreed agreed principle principle acquire acquire famed famed hollywood hollywood studio studio metro metro goldwyn goldwyn mayer mayer inc inc nearly nearly billion billion mgm mgm said said late late yesterday\n",
      "Prediction: Business (p=0.99)\n",
      "\t + Sample: pilgrim baxter baxter founder founder pay pay washington washington two two founder founder pilgrim pilgrim baxter baxter mutual mutual fund fund family family agreed agreed pay pay million million settle settle regulator regulator charge charge improper improper trading trading benefit benefit friend friend expense expense longer longer term term shareholder shareholder authority authority said said yesterday\n",
      "Prediction: Business (p=0.67)\n",
      "\t + Sample: loss making making smart smart doomed doomed head head smart smart car car denies denies rumour rumour loss loss making making firm firm may may sold sold even even closed closed parent parent group group daimlerchrysler\n",
      "Prediction: Business (p=0.98)\n",
      "\t + Sample: united seek seek cut cut labor labor elsewhere elsewhere united united airline airline say say need need even even labor labor cut cut anticipated anticipated get get bankruptcy bankruptcy united united told told bankruptcy bankruptcy court court judge judge chicago chicago today today intends intends start start talk talk union union next next month month new new round round cost cost saving\n",
      "Prediction: Business (p=0.99)\n",
      "\t + Sample: oil price price jump jump u u report report lower lower supply supply oil oil future future price price bolted bolted percent percent higher higher yesterday yesterday climbing climbing barrel barrel u u government government data data showed showed slight slight decline decline crude crude heating heating oil oil supply\n",
      "------------------------------\n",
      "\n",
      "True Category: Sci/Tech\n",
      "==============================\n",
      "Prediction: Sci/Tech (p=0.81)\n",
      "\t + Sample: china blasted blasted piracy piracy lax lax enforcement enforcement intellectual intellectual property property law law hurt hurt business business investment investment group group charge\n",
      "Prediction: Sci/Tech (p=0.94)\n",
      "\t + Sample: company put put loyalty loyalty test test cisco cisco ibm ibm microsoft microsoft sap sap loyal loyal customer customer according according report report released released today today fact fact biggest biggest successful successful vendor\n",
      "Prediction: Business (p=0.67)\n",
      "\t + Sample: mobile margin margin fall fall telstra telstra telstra telstra chief chief financial financial officer officer john john stanhope stanhope admitted admitted telstra telstra margin margin billion billion year year mobile mobile phone phone business business shrink shrink year year face face increased increased price price competition competition growing growing cost cost acquiring acquiring new new customer\n",
      "Prediction: Business (p=0.63)\n",
      "\t + Sample: peoplesoft ibm ibm strike strike middleware middleware alliance alliance peoplesoft peoplesoft inc inc deepening deepening tie tie ibm ibm corp corp announcing announcing tuesday tuesday sale sale development development partnership partnership called called significant significant enterprise enterprise application application alliance alliance company company history\n",
      "Prediction: Sci/Tech (p=0.99)\n",
      "\t + Sample: apple sue sue web web leak leak advance advance product product reuters reuters reuters reuters apple apple computer computer inc inc suing suing anonymous anonymous people people leaked leaked detail detail new new product product posting posting information information internet internet court court document document showed showed friday\n",
      "------------------------------\n",
      "\n",
      "True Category: Sports\n",
      "==============================\n",
      "Prediction: Sports (p=0.99)\n",
      "\t + Sample: mcnair injures injures sternum sternum jaguar jaguar ap ap ap ap steve steve mcnair mcnair nfl nfl co co mvp mvp bruised bruised sternum sternum sunday sunday admitted admitted hospital hospital night\n",
      "Prediction: Sports (p=0.99)\n",
      "\t + Sample: urso suspended suspended fa fa football football association association handed handed referee referee andy andy urso urso day day suspension suspension following following failure failure give give barry barry ferguson ferguson marching marching order order southampton southampton august\n",
      "Prediction: Sports (p=0.78)\n",
      "\t + Sample: greek prosecutor prosecutor expected expected rule rule olympic olympic pair pair greek greek prosecutor prosecutor expected expected wednesday wednesday announce announce result result investigation investigation whether whether country country top top sprinter sprinter faked faked road road accident accident doping doping scandal scandal rocked rocked greece greece plagued plagued athens athens olympics\n",
      "Prediction: Sports (p=0.98)\n",
      "\t + Sample: familiar brave brave tune tune postseason postseason dirge dirge end end long long season season grueling grueling playoff playoff series series manager manager often often point point weary weary optimist optimist toward toward hill hill place place bullpen bullpen high high alert\n",
      "Prediction: Sports (p=0.97)\n",
      "\t + Sample: australia give give neighbour neighbour mercy mercy australia australia wrapped wrapped win win series series beating beating new new zealand zealand run run fifth fifth day day second second final final cricket cricket test test tuesday\n",
      "------------------------------\n",
      "\n",
      "True Category: World\n",
      "==============================\n",
      "Prediction: World (p=1.00)\n",
      "\t + Sample: austria extradite extradite turkish turkish underworld underworld figure figure vienna vienna reuters reuters convicted convicted turkish turkish underworld underworld bos bos alaattin alaattin cakici cakici sought sought charge charge corruption corruption extortion extortion extradited extradited austria austria turkey turkey district district court court ruled ruled monday\n",
      "Prediction: World (p=0.82)\n",
      "\t + Sample: french court court rule rule sikh sikh boy boy french french court court rule rule whether whether new new law law ban ban three three sikh sikh boy boy wearing wearing turban turban school\n",
      "Prediction: World (p=0.63)\n",
      "\t + Sample: holiday stamp stamp issued issued oct oct ap ap ap ap holiday holiday postage postage stamp stamp celebrating celebrating christmas christmas hanukkah hanukkah kwanzaa kwanzaa issued issued next next month month u u postal postal service service announced announced monday\n",
      "Prediction: World (p=1.00)\n",
      "\t + Sample: protester harry harry israel israel parliament parliament gaza gaza vote vote jerusalem jerusalem reuters reuters thousand thousand rightist rightist israeli israeli accused accused prime prime minister minister ariel ariel sharon sharon treason treason tuesday tuesday parliament parliament looked looked set set approve approve first first pullout pullout settler settler occupied occupied land land palestinian palestinian want want part part future future state\n",
      "Prediction: World (p=0.99)\n",
      "\t + Sample: plane crash crash venezuelan venezuelan mountain mountain killing killing military military plane plane crashed crashed mountain mountain central central venezuela venezuela killing killing people people including including five five child child air air force force rescue rescue team team said said statement\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#title = input(\"Enter a news title to classify: \")\n",
    "classifier = classifier.to(\"cpu\")\n",
    "\n",
    "for truth, sample_group in val_samples.items():\n",
    "    print(f\"True Category: {truth}\")\n",
    "    print(\"=\"*30)\n",
    "    for sample in sample_group:\n",
    "        prediction = predict_category(sample, classifier, \n",
    "                                      vectorizer, dataset._max_seq_length)\n",
    "        print(\"Prediction: {} (p={:0.2f})\".format(prediction['category'],\n",
    "                                                  prediction['probability']))\n",
    "        print(\"\\t + Sample: {}\".format(sample))\n",
    "    print(\"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": "5",
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
