{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM News Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\miuGrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords # remove stopword\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Vectorization classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "        \"\"\"\n",
    "\n",
    "        # news_vocab._token_to_idx: {'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'jobs': 4, 'tax': 5, 'cuts': 6,  \n",
    "        #                             ......, 'shiite': 3407, 'ghraib': 3408}\n",
    "        # category_vocab._token_to_idx: {'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}\n",
    "        \n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token             # for paddding, e.g., Wall St. Bears Claw Back Into the Black (Reuters)\n",
    "                                                  #               -> [2, 5, 6, 10, 10, 8, 7, 9, 19, ......., 3, 0, 0, 0, ..., 0]\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)            # mask_index is 0\n",
    "        self.unk_index = self.add_token(self._unk_token)              # unk_index is 1\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)  # begin_seq_index is 2\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)      # end_seq_index is 3\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
    "    def __init__(self, news_vocab, category_vocab):\n",
    "        self.news_vocab = news_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "\n",
    "    def vectorize(self, text, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text (str): the string of words separated by a space\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        Returns:\n",
    "            the vetorized text (numpy.array)\n",
    "        \"\"\"\n",
    "        \"\"\"    \n",
    "        mask_index is 0\n",
    "        unk_index is 1\n",
    "        begin_seq_index is 2\n",
    "        end_seq_index is 3\n",
    "        \n",
    "        When text is \"Wall St. Bears Claw Back Into the Black (Reuters)\"; max vector length is 29 in current dataset \n",
    "        \n",
    "        out_vector = [2, 5, 6, 10, 10, 8, 7, 9, 19, ......., 3, 0, 0, 0, ..., 0]\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        indices = [self.news_vocab.begin_seq_index]\n",
    "        indices.extend(self.news_vocab.lookup_token(token) \n",
    "                       for token in text.split(\" \"))\n",
    "        indices.append(self.news_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.news_vocab.mask_index\n",
    "\n",
    "        return out_vector\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, news_df, cutoff=25):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            news_df (pandas.DataFrame): the target dataset\n",
    "            cutoff (int): frequency threshold for including in Vocabulary \n",
    "        Returns:\n",
    "            an instance of the NewsVectorizer\n",
    "        \"\"\"\n",
    "        category_vocab = Vocabulary()        \n",
    "        for category in sorted(set(news_df.category)):\n",
    "            category_vocab.add_token(category)\n",
    "\n",
    "        word_counts = Counter()\n",
    "        for text in news_df.text:\n",
    "            for token in text.split(\" \"):\n",
    "                if token not in string.punctuation:\n",
    "                    word_counts[token] += 1\n",
    "        \n",
    "        news_vocab = SequenceVocabulary()\n",
    "        for word, word_count in word_counts.items():\n",
    "            if word_count >= cutoff:\n",
    "                news_vocab.add_token(word)\n",
    "        \n",
    "        return cls(news_vocab, category_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glaxo settle paxil settle paxil suicide paxil suicide pill suicide pill suit pill suit new suit new york new york reuters york reuters glaxosmithkline reuters glaxosmithkline plc glaxosmithkline plc href plc href target href target stock target stock quickinfo stock quickinfo fullquote quickinfo fullquote l fullquote l agreed l agreed release agreed release clinical release clinical study clinical study drug study drug settle drug settle lawsuit settle lawsuit accused lawsuit accused withholding accused withholding negative withholding negative information negative information antidepressant information antidepressant paxil antidepressant paxil new paxil new york new york attorney york attorney general attorney general office general office said office said thursday'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_preprocessing(text):\n",
    "    text = text.lower() # case folding\n",
    "    text = re.sub('&\\w*\\;\\w*', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub(r\"[^a-z]+\", r\" \", text) # Regulation, remove special charecters\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    # remove stopwords and lemmatization\n",
    "    result = [lemmatizer.lemmatize(i) for i in tokens if not i in stop_words]\n",
    "    # result = result[:1000]\n",
    "    # bigram\n",
    "    bigram_result = []\n",
    "    bigram_list = ngrams(result, 3)\n",
    "    for word_set in bigram_list:\n",
    "        for word in word_set:\n",
    "            bigram_result.append(word)\n",
    "    return bigram_result\n",
    "\n",
    "test_str_1 = \"This is sentence to test the effect of preprocessing... Yeah~\\nCool!fac  feae ge fe ga ðŸª£ðŸ›€ðŸŽ€ â˜â˜¢ï¸Žâ¥â˜âŽ (>â•¹Ï‰â•¹<)å–µ\"\n",
    "test_str_2 = \"Glaxo Settles Paxil 'Suicide Pill' Suit.  NEW YORK (Reuters) - GlaxoSmithKline Plc &lt;A HREF=http://www.investor.reuters.com/FullQuote.aspx?ticker=GSK.L target=/stocks/quickinfo/fullquote\"\"&gt;GSK.L&lt;/A&gt; has agreed  to release all clinical studies of its drugs to settle a  lawsuit that accused it of withholding negative information  about the antidepressant Paxil, the New York Attorney General's  office said on Thursday.\"\n",
    "list = text_preprocessing(test_str_2)\n",
    "' '.join(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, news_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            news_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (NewsVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.news_df = news_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        # +1 if only using begin_seq, +2 if using both begin and end seq tokens\n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, news_df.text)) + 2\n",
    "        \n",
    "\n",
    "        self.train_df = self.news_df[self.news_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.news_df[self.news_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.news_df[self.news_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "        # Class weights\n",
    "        class_counts = news_df.category.value_counts().to_dict()\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.category_vocab.lookup_token(item[0])\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, news_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            surname_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of SurnameDataset\n",
    "        \"\"\"\n",
    "        news_df = pd.read_csv(news_csv)\n",
    "        \n",
    "        for index, text in enumerate(news_df.text):\n",
    "            processed_list = text_preprocessing(text)\n",
    "            news_df.text[index] = ' '.join(processed_list)\n",
    "\n",
    "        train_news_df = news_df[news_df.split=='train']\n",
    "        return cls(news_df, NewsVectorizer.from_dataframe(train_news_df))\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        news_vector = \\\n",
    "            self._vectorizer.vectorize(row.text, self._max_seq_length)\n",
    "\n",
    "        category_index = \\\n",
    "            self._vectorizer.category_vocab.lookup_token(row.category)\n",
    "\n",
    "        return {'x_data': news_vector,     # e.g., \"Wall St. Bears Claw Back Into the Black (Reuters)\" \n",
    "                                            # -> [2, 5, 6, 10, 10, 8, 7, 9, 19, ......., 3, 0, 0, 0, ..., 0]\n",
    "                'y_target': category_index} # e.g., 2\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model: NewsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, output_dim, hidden_dim, num_layers, bidirectional, pretrained_embeddings=None, emb_freeze=True):\n",
    "        super(NewsClassifier, self).__init__()\n",
    "\n",
    "        if pretrained_embeddings is None:\n",
    "            self.embedding = nn.Embedding(num_embeddings, embedding_dim) \n",
    "            self.embedding.weight.requires_grad = True\n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=emb_freeze) \n",
    "                                                                          \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1, :, :]\n",
    "        out = self.fc(hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t  # update 'early_stopping_best_val'\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### general utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda, mps):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    try:\n",
    "        if mps:\n",
    "            torch.mps.manual_seed(seed)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "        \n",
    "def load_glove_from_file(glove_filepath):\n",
    "    \"\"\"\n",
    "    Load the GloVe embeddings \n",
    "    \n",
    "    Args:\n",
    "        glove_filepath (str): path to the glove embeddings file \n",
    "    Returns:\n",
    "        word_to_index (dict), embeddings (numpy.ndarary)\n",
    "    \"\"\"\n",
    "\n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(glove_filepath, \"r\", encoding='utf8') as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \") # each line: word num1 num2 ...\n",
    "            word_to_index[line[0]] = index # word = line[0] \n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    return word_to_index, np.stack(embeddings)\n",
    "\n",
    "def make_embedding_matrix(glove_filepath, words):\n",
    "    \"\"\"\n",
    "    Create embedding matrix for a specific set of words.\n",
    "    \n",
    "    Args:\n",
    "        glove_filepath (str): file path to the glove embeddigns\n",
    "        words (list): list of words in the dataset\n",
    "    \"\"\"\n",
    "    word_to_idx, glove_embeddings = load_glove_from_file(glove_filepath)\n",
    "    embedding_size = glove_embeddings.shape[1]\n",
    "    \n",
    "    final_embeddings = np.zeros((len(words), embedding_size))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word in word_to_idx:\n",
    "            final_embeddings[i, :] = glove_embeddings[word_to_idx[word]]\n",
    "        else:\n",
    "            embedding_i = torch.ones(1, embedding_size)\n",
    "            torch.nn.init.xavier_uniform_(embedding_i)\n",
    "            final_embeddings[i, :] = embedding_i\n",
    "\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings and some prep work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\t../model_storage/News_Category\\model_LSTM_News_Category.pth\n",
      "Using CUDA: True\n",
      "Using MPS: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and Path hyper parameters\n",
    "    news_csv=\"../data/processed/News_Category_Dataset_with_splits.csv\",\n",
    "    model_state_file=\"model_LSTM_News_Category.pth\",\n",
    "    save_dir=\"../model_storage/News_Category\",\n",
    "    # Model hyper parameters\n",
    "    glove_filepath='../data/glove/glove.6B.100d.txt', \n",
    "    use_glove=True,\n",
    "    embedding_dim=100, \n",
    "    hidden_dim=256,\n",
    "    output_dim=4,\n",
    "    num_layers=1,\n",
    "    bidirectional=True,\n",
    "    # Training hyper parameter\n",
    "    seed=1337, \n",
    "    learning_rate=0.001, \n",
    "    batch_size=96, \n",
    "    num_epochs=100, \n",
    "    early_stopping_criteria=5, \n",
    "    emb_freeze=False,\n",
    "    # Runtime option\n",
    "    cuda=True,\n",
    "    mps=True, \n",
    "    catch_keyboard_interrupt=True, \n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True\n",
    ") \n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA for Nvidia\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "# Check MPS for Mac\n",
    "if not torch.backends.mps.is_available():\n",
    "    args.mps = False\n",
    "    \n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"mps\" if args.mps else \"cpu\")\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "print(\"Using MPS: {}\".format(args.mps))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda, args.mps)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-trained embeddings\n"
     ]
    }
   ],
   "source": [
    "# create dataset and vectorizer\n",
    "dataset = NewsDataset.load_dataset_and_make_vectorizer(args.news_csv)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# Use GloVe or randomly initialized embeddings\n",
    "if args.use_glove:\n",
    "    words = vectorizer.news_vocab._token_to_idx.keys()  # 3409 unique words\n",
    "    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath,     # embeddings: (3409, 100)\n",
    "                                       words=words)\n",
    "    print(\"Using pre-trained embeddings\")\n",
    "else:\n",
    "    print(\"Not using pre-trained embeddings\")\n",
    "    embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'profit': 4, 'price': 5, 'cut': 6, 'weigh': 7, 'new': 8, 'york': 9, 'reuters': 10, 'co': 11, 'top': 12, 'u': 13, 'tuesday': 14, 'posted': 15, 'percent': 16, 'rise': 17, 'quarterly': 18, 'due': 19, 'cost': 20, 'control': 21, 'shopper': 22, 'caused': 23, 'earnings': 24, 'miss': 25, 'wall': 26, 'street': 27, 'estimate': 28, 'share': 29, 'fell': 30, 'goldman': 31, 'group': 32, 'inc': 33, 'may': 34, 'talk': 35, 'family': 36, 'japanese': 37, 'consumer': 38, 'finance': 39, 'firm': 40, 'corp': 41, 'stake': 42, 'losing': 43, 'right': 44, 'sue': 45, 'washington': 46, 'business': 47, 'contract': 48, 'forcing': 49, 'give': 50, 'want': 51, 'conduct': 52, 'made': 53, 'priority': 54, 'aussie': 55, 'battle': 56, 'eu': 57, 'ap': 58, 'united': 59, 'state': 60, 'australia': 61, 'interim': 62, 'ruling': 63, 'world': 64, 'trade': 65, 'organisation': 66, 'wto': 67, 'dispute': 68, 'protection': 69, 'given': 70, 'european': 71, 'union': 72, 'regional': 73, 'good': 74, 'wine': 75, 'official': 76, 'said': 77, 'foreign': 78, 'minister': 79, 'hope': 80, 'break': 81, 'summit': 82, 'friday': 83, 'quot': 84, 'hoped': 85, 'reach': 86, 'meeting': 87, 'military': 88, 'ruled': 89, 'myanmar': 90, 'upcoming': 91, 'asian': 92, 'nation': 93, 'watchdog': 94, 'today': 95, 'ordered': 96, 'open': 97, 'modern': 98, 'service': 99, 'broadband': 100, 'competitor': 101, 'charge': 102, 'retail': 103, 'within': 104, 'matter': 105, 'month': 106, 'venezuela': 107, 'increase': 108, 'opec': 109, 'production': 110, 'quota': 111, 'third': 112, 'largest': 113, 'oil': 114, 'producer': 115, 'raise': 116, 'output': 117, 'target': 118, 'week': 119, 'vienna': 120, 'auto': 121, 'sale': 122, 'job': 123, 'number': 124, 'time': 125, 'chicago': 126, 'cbs': 127, 'mw': 128, 'could': 129, 'people': 130, 'buying': 131, 'thing': 132, 'wal': 133, 'mart': 134, 'free': 135, 'sign': 136, 'roundup': 137, 'e': 138, 'blue': 139, 'chip': 140, 'end': 141, 'lower': 142, 'hit': 143, 'stock': 144, 'declined': 145, 'lowest': 146, 'level': 147, 'thursday': 148, 'crude': 149, 'barrel': 150, 'renewed': 151, 'concern': 152, 'high': 153, 'fuel': 154, 'corporate': 155, 'guide': 156, 'sharply': 157, 'nyse': 158, 'news': 159, 'research': 160, 'fiscal': 161, 'fourth': 162, 'quarter': 163, 'came': 164, 'light': 165, 'company': 166, 'first': 167, 'weak': 168, 'calif': 169, 'stewart': 170, 'case': 171, 'ink': 172, 'expert': 173, 'found': 174, 'guilty': 175, 'lying': 176, 'government': 177, 'martha': 178, 'trial': 179, 'yesterday': 180, 'witness': 181, 'stand': 182, 'delay': 183, 'action': 184, 'airbus': 185, 'subsidy': 186, 'offer': 187, 'branch': 188, 'peter': 189, 'commissioner': 190, 'next': 191, 'boeing': 192, 'agrees': 193, 'account': 194, 'b': 195, 'writes': 196, 'confirmed': 197, 'written': 198, 'authority': 199, 'agreed': 200, 'appeal': 201, 'heard': 202, 'court': 203, 'make': 204, 'decision': 205, 'bank': 206, 'hostile': 207, 'bid': 208, 'takeover': 209, 'biggest': 210, 'ever': 211, 'japan': 212, 'got': 213, 'even': 214, 'bigger': 215, 'sought': 216, 'rival': 217, 'expansion': 218, 'plan': 219, 'billion': 220, 'bush': 221, 'tax': 222, 'bill': 223, 'president': 224, 'signed': 225, 'law': 226, 'sweeping': 227, 'nearly': 228, 'two': 229, 'decade': 230, 'flight': 231, 'air': 232, 'force': 233, 'one': 234, 'campaign': 235, 'stop': 236, 'pennsylvania': 237, 'pension': 238, 'year': 239, 'airline': 240, 'announced': 241, 'citing': 242, 'reason': 243, 'ongoing': 244, 'uncertainty': 245, 'industry': 246, 'economic': 247, 'environment': 248, 'record': 249, 'jet': 250, 'update': 251, 'james': 252, 'h': 253, 'net': 254, 'forecast': 255, 'sydney': 256, 'dow': 257, 'jones': 258, 'australian': 259, 'building': 260, 'product': 261, 'manufacturer': 262, 'nv': 263, 'investor': 264, 'monday': 265, 'reporting': 266, 'drop': 267, 'treasury': 268, 'yield': 269, 'held': 270, 'near': 271, 'six': 272, 'low': 273, 'though': 274, 'market': 275, 'struggling': 276, 'extend': 277, 'recent': 278, 'gain': 279, 'face': 280, 'taking': 281, 'bankrupt': 282, 'clear': 283, 'cutting': 284, 'major': 285, 'bankruptcy': 286, 'tough': 287, 'choice': 288, 'wage': 289, 'largely': 290, 'ticket': 291, 'offered': 292, 'holiday': 293, 'result': 294, 'lift': 295, 'kmart': 296, 'store': 297, 'surge': 298, 'christmas': 299, 'shopping': 300, 'december': 301, 'holding': 302, 'rose': 303, 'season': 304, 'limited': 305, 'deep': 306, 'discount': 307, 'sell': 308, 'cereal': 309, 'maker': 310, 'drink': 311, 'giant': 312, 'raised': 313, 'dollar': 314, 'bn': 315, 'selling': 316, 'general': 317, 'halliburton': 318, 'army': 319, 'payment': 320, 'per': 321, 'cent': 322, 'future': 323, 'support': 324, 'housing': 325, 'troop': 326, 'iraq': 327, 'kuwait': 328, 'see': 329, 'retailer': 330, 'owner': 331, 'supermarket': 332, 'least': 333, 'september': 334, 'slightly': 335, 'higher': 336, 'preliminary': 337, 'report': 338, 'still': 339, 'towards': 340, 'range': 341, 'sony': 342, 'lead': 343, 'acquisition': 344, 'entertainment': 345, 'get': 346, 'hand': 347, 'library': 348, 'title': 349, 'warner': 350, 'seen': 351, 'front': 352, 'runner': 353, 'race': 354, 'drug': 355, 'knocked': 356, 'worried': 357, 'rising': 358, 'would': 359, 'possible': 360, 'regulator': 361, 'data': 362, 'view': 363, 'singapore': 364, 'aug': 365, 'expectation': 366, 'industrial': 367, 'smaller': 368, 'expected': 369, 'august': 370, 'pharmaceutical': 371, 'base': 372, 'ago': 373, 'st': 374, 'louis': 375, 'spike': 376, 'publisher': 377, 'post': 378, 'arizona': 379, 'newspaper': 380, 'considering': 381, 'sec': 382, 'probe': 383, 'rental': 384, 'security': 385, 'investigating': 386, 'href': 387, 'quickinfo': 388, 'fullquote': 389, 'n': 390, 'accounting': 391, 'sending': 392, 'com': 393, 'cool': 394, 'something': 395, 'else': 396, 'mind': 397, 'need': 398, 'computer': 399, 'note': 400, 'searching': 401, 'internet': 402, 'heating': 403, 'worry': 404, 'ahead': 405, 'inventory': 406, 'show': 407, 'tight': 408, 'winter': 409, 'golden': 410, 'ring': 411, 'cheaper': 412, 'list': 413, 'gift': 414, 'please': 415, 'save': 416, 'buck': 417, 'consider': 418, 'five': 419, 'fifth': 420, 'classic': 421, 'song': 422, 'day': 423, 'mortgage': 424, 'rate': 425, 'around': 426, 'country': 427, 'continue': 428, 'provide': 429, 'analyst': 430, 'say': 431, 'little': 432, 'ban': 433, 'bell': 434, 'nationwide': 435, 'qualcomm': 436, 'strong': 437, 'demand': 438, 'mobile': 439, 'phone': 440, 'technology': 441, 'san': 442, 'diego': 443, 'expects': 444, 'oracle': 445, 'peoplesoft': 446, 'purchase': 447, 'gained': 448, 'bought': 449, 'international': 450, 'uk': 451, 'optimistic': 452, 'economy': 453, 'prospect': 454, 'hunt': 455, 'page': 456, 'article': 457, 'toyota': 458, 'v': 459, 'main': 460, 'look': 461, 'image': 462, 'buyer': 463, 'labour': 464, 'reform': 465, 'pay': 466, 'population': 467, 'afp': 468, 'organization': 469, 'operation': 470, 'development': 471, 'called': 472, 'labor': 473, 'boost': 474, 'employment': 475, 'marine': 476, 'city': 477, 'priest': 478, 'leaf': 479, 'foundation': 480, 'following': 481, 'helping': 482, 'church': 483, 'work': 484, 'donald': 485, 'help': 486, 'death': 487, 'push': 488, 'trader': 489, 'described': 490, 'wave': 491, 'gasoline': 492, 'cardinal': 493, 'pick': 494, 'health': 495, 'deal': 496, 'suggests': 497, 'fee': 498, 'model': 499, 'gaining': 500, 'helped': 501, 'brewer': 502, 'income': 503, 'plc': 504, 'l': 505, 'offset': 506, 'weakness': 507, 'domestic': 508, 'tobacco': 509, 'kraft': 510, 'food': 511, 'justice': 512, 'close': 513, 'inquiry': 514, 'wednesday': 515, 'department': 516, 'closed': 517, 'potential': 518, 'antitrust': 519, 'issue': 520, 'key': 521, 'used': 522, 'million': 523, 'florida': 524, 'jeanne': 525, 'customer': 526, 'remained': 527, 'without': 528, 'power': 529, 'early': 530, 'hurricane': 531, 'tore': 532, 'weekend': 533, 'according': 534, 'utility': 535, 'lawsuit': 536, 'try': 537, 'damage': 538, 'falling': 539, 'broker': 540, 'threatened': 541, 'financial': 542, 'huge': 543, 'executive': 544, 'dismissed': 545, 'insurance': 546, 'ace': 547, 'became': 548, 'latest': 549, 'announce': 550, 'change': 551, 'practice': 552, 'response': 553, 'investigation': 554, 'launched': 555, 'attorney': 556, 'aol': 557, 'file': 558, 'im': 559, 'america': 560, 'online': 561, 'filed': 562, 'federal': 563, 'accusing': 564, 'numerous': 565, 'violating': 566, 'message': 567, 'known': 568, 'instant': 569, 'chat': 570, 'room': 571, 'build': 572, 'cargo': 573, 'version': 574, 'twin': 575, 'engine': 576, 'commercial': 577, 'enter': 578, 'late': 579, 'kerry': 580, 'ready': 581, 'final': 582, 'democratic': 583, 'challenger': 584, 'john': 585, 'set': 586, 'debate': 587, 'candidate': 588, 'turn': 589, 'policy': 590, 'office': 591, 'depot': 592, 'chairman': 593, 'ceo': 594, 'resigns': 595, 'quote': 596, 'profile': 597, 'supply': 598, 'chain': 599, 'chief': 600, 'officer': 601, 'resigned': 602, 'search': 603, 'successor': 604, 'energy': 605, 'panel': 606, 'criticized': 607, 'crisis': 608, 'duty': 609, 'order': 610, 'tech': 611, 'advance': 612, 'exporter': 613, 'electronics': 614, 'ltd': 615, 'outlook': 616, 'slide': 617, 'nextel': 618, 'sprint': 619, 'communication': 620, 'jumped': 621, 'telephone': 622, 'merger': 623, 'farmer': 624, 'fed': 625, 'gdp': 626, 'pct': 627, 'growth': 628, 'slow': 629, 'interest': 630, 'reserve': 631, 'conference': 632, 'released': 633, 'fire': 634, 'back': 635, 'parmalat': 636, 'london': 637, 'grant': 638, 'motion': 639, 'remove': 640, 'counter': 641, 'suing': 642, 'italian': 643, 'dairy': 644, 'sued': 645, 'airway': 646, 'accord': 647, 'airplane': 648, 'financing': 649, 'journal': 650, 'carrier': 651, 'creditor': 652, 'aircraft': 653, 'gap': 654, 'sap': 655, 'software': 656, 'jeff': 657, 'interview': 658, 'published': 659, 'focus': 660, 'politician': 661, 'kenneth': 662, 'lewis': 663, 'running': 664, 'massachusetts': 665, 'sun': 666, 'settle': 667, 'patent': 668, 'suit': 669, 'microsystems': 670, 'involving': 671, 'java': 672, 'ocean': 673, 'peace': 674, 'ended': 675, 'legal': 676, 'join': 677, 'take': 678, 'olympics': 679, 'advertising': 680, 'reported': 681, 'half': 682, 'russia': 683, 'freeze': 684, 'yukos': 685, 'auction': 686, 'moscow': 687, 'core': 688, 'asset': 689, 'despite': 690, 'disputed': 691, 'controlled': 692, 'gas': 693, 'gazprom': 694, 'bidding': 695, 'delta': 696, 'pilot': 697, 'ok': 698, 'concession': 699, 'francisco': 700, 'line': 701, 'approved': 702, 'management': 703, 'backed': 704, 'china': 705, 'pledge': 706, 'move': 707, 'toward': 708, 'exchange': 709, 'currency': 710, 'word': 711, 'long': 712, 'gold': 713, 'sink': 714, 'merck': 715, 'toronto': 716, 'small': 717, 'pushed': 718, 'sector': 719, 'amp': 720, 'took': 721, 'average': 722, 'red': 723, 'arthritis': 724, 'vioxx': 725, 'md': 726, 'withdrawal': 727, 'revenue': 728, 'setback': 729, 'patient': 730, 'doctor': 731, 'dozen': 732, 'relief': 733, 'unemployment': 734, 'claim': 735, 'slip': 736, 'picture': 737, 'american': 738, 'jobless': 739, 'benefit': 740, 'last': 741, 'decline': 742, 'current': 743, 'announces': 744, 'closing': 745, 'weaker': 746, 'allow': 747, 'strengthen': 748, 'brand': 749, 'cleared': 750, 'session': 751, 'rally': 752, 'ran': 753, 'steam': 754, 'saw': 755, 'large': 756, 'short': 757, 'index': 758, 'best': 759, 'term': 760, 'germany': 761, 'worst': 762, 'field': 763, 'win': 764, 'fight': 765, 'harmony': 766, 'mining': 767, 'create': 768, 'c': 769, 'indian': 770, 'unveils': 771, 'since': 772, 'launch': 773, 'imf': 774, 'keep': 775, 'global': 776, 'recovery': 777, 'facing': 778, 'surging': 779, 'factor': 780, 'opened': 781, 'saturday': 782, 'discus': 783, 'way': 784, 'track': 785, 'marsh': 786, 'spitzer': 787, 'mclennan': 788, 'accepting': 789, 'center': 790, 'eliot': 791, 'rigging': 792, 'electric': 793, 'dividend': 794, 'plastic': 795, 'appliance': 796, 'well': 797, 'television': 798, 'network': 799, 'board': 800, 'charles': 801, 'certain': 802, 'brokerage': 803, 'arm': 804, 'equity': 805, 'commission': 806, 'reduce': 807, 'competitive': 808, 'position': 809, 'leading': 810, 'preparing': 811, 'lay': 812, 'many': 813, 'employee': 814, 'ireland': 815, 'poised': 816, 'grow': 817, 'faster': 818, 'deficit': 819, 'thanks': 820, 'administration': 821, 'emergency': 822, 'petroleum': 823, 'ivan': 824, 'congressional': 825, 'source': 826, 'pending': 827, 'told': 828, 'budget': 829, 'virgin': 830, 'add': 831, 'soaring': 832, 'doubt': 833, 'russian': 834, 'warned': 835, 'night': 836, 'driven': 837, 'briefly': 838, 'unit': 839, 'producing': 840, 'chinese': 841, 'quoted': 842, 'saying': 843, 'agency': 844, 'gate': 845, 'founder': 846, 'microsoft': 847, 'remains': 848, 'person': 849, 'usa': 850, 'forbes': 851, 'magazine': 852, 'keeping': 853, 'place': 854, 'already': 855, 'raw': 856, 'among': 857, 'worker': 858, 'victim': 859, 'rallied': 860, 'outside': 861, 'embattled': 862, 'central': 863, 'edge': 864, 'flu': 865, 'shot': 866, 'shortage': 867, 'highlight': 868, 'began': 869, 'went': 870, 'wrong': 871, 'british': 872, 'vaccine': 873, 'plant': 874, 'confidence': 875, 'second': 876, 'consecutive': 877, 'based': 878, 'private': 879, 'sears': 880, 'form': 881, 'annual': 882, 'school': 883, 'hoping': 884, 'fashion': 885, 'grade': 886, 'style': 887, 'teen': 888, 'young': 889, 'adult': 890, 'fall': 891, 'student': 892, 'parent': 893, 'hold': 894, 'ibm': 895, 'strike': 896, 'expanded': 897, 'relationship': 898, 'effectively': 899, 'infrastructure': 900, 'application': 901, 'fear': 902, 'representing': 903, 'gm': 904, 'go': 905, 'green': 906, 'team': 907, 'compete': 908, 'fill': 909, 'situation': 910, 'moment': 911, 'white': 912, 'house': 913, 'spin': 914, 'man': 915, 'much': 916, 'like': 917, 'four': 918, 'ad': 919, 'men': 920, 'accused': 921, 'using': 922, 'latin': 923, 'europe': 924, 'direct': 925, 'sound': 926, 'mayor': 927, 'wake': 928, 'another': 929, 'credit': 930, 'rating': 931, 'dick': 932, 'public': 933, 'amid': 934, 'offering': 935, 'flying': 936, 'scheduled': 937, 'play': 938, 'debt': 939, 'slipped': 940, 'previous': 941, 'played': 942, 'technical': 943, 'trading': 944, 'hurt': 945, 'q': 946, 'personal': 947, 'home': 948, 'loss': 949, 'presidential': 950, 'election': 951, 'seek': 952, 'cp': 953, 'telecommunication': 954, 'war': 955, 'buy': 956, 'component': 957, 'provider': 958, 'circuit': 959, 'solution': 960, 'black': 961, 'earns': 962, 'leap': 963, 'samsung': 964, 'seoul': 965, 'south': 966, 'korea': 967, 'promotion': 968, 'bottom': 969, 'google': 970, 'almost': 971, 'sharp': 972, 'grows': 973, 'slowly': 974, 'reached': 975, 'agreement': 976, 'negotiator': 977, 'accept': 978, 'leader': 979, 'prevent': 980, 'collapse': 981, 'flag': 982, 'detail': 983, 'rescue': 984, 'tokyo': 985, 'lifted': 986, 'survey': 987, 'mid': 988, 'morning': 989, 'broad': 990, 'getting': 991, 'boosted': 992, 'optimism': 993, 'figure': 994, 'schedule': 995, 'february': 996, 'charlotte': 997, 'philadelphia': 998, 'hub': 999, 'mini': 1000, 'fla': 1001, 'swing': 1002, 'warns': 1003, 'manufacturing': 1004, 'swung': 1005, 'atlantic': 1006, 'factory': 1007, 'dec': 1008, 'kicked': 1009, 'increased': 1010, 'withdrawn': 1011, 'asia': 1012, 'pacific': 1013, 'independent': 1014, 'director': 1015, 'fannie': 1016, 'mae': 1017, 'criminal': 1018, 'begun': 1019, 'prosecutor': 1020, 'ata': 1021, 'indianapolis': 1022, 'full': 1023, 'filing': 1024, 'chapter': 1025, 'big': 1026, 'political': 1027, 'engineering': 1028, 'scandal': 1029, 'boston': 1030, 'underground': 1031, 'interstate': 1032, 'highway': 1033, 'hundred': 1034, 'safe': 1035, 'hole': 1036, 'beginning': 1037, 'question': 1038, 'super': 1039, 'status': 1040, 'fraud': 1041, 'allegation': 1042, 'call': 1043, 'program': 1044, 'writing': 1045, 'poor': 1046, 'gordon': 1047, 'brown': 1048, 'write': 1049, 'retire': 1050, 'start': 1051, 'effective': 1052, 'date': 1053, 'package': 1054, 'steady': 1055, 'looked': 1056, 'changed': 1057, 'heavy': 1058, 'remain': 1059, 'dip': 1060, 'often': 1061, 'drive': 1062, 'away': 1063, 'summer': 1064, 'self': 1065, 'serve': 1066, 'regular': 1067, 'saudi': 1068, 'system': 1069, 'announcing': 1070, 'progress': 1071, 'admitted': 1072, 'trouble': 1073, 'controversial': 1074, 'al': 1075, 'verizon': 1076, 'canada': 1077, 'directory': 1078, 'canadian': 1079, 'capital': 1080, 'block': 1081, 'lawyer': 1082, 'likely': 1083, 'temporary': 1084, 'mark': 1085, 'era': 1086, 'edward': 1087, 'meyer': 1088, 'old': 1089, 'asked': 1090, 'decided': 1091, 'publicly': 1092, 'traded': 1093, 'increasingly': 1094, 'dominate': 1095, 'civil': 1096, 'evidence': 1097, 'improper': 1098, 'three': 1099, 'plunge': 1100, 'crunch': 1101, 'j': 1102, 'reportedly': 1103, 'johnson': 1104, 'advanced': 1105, 'negotiation': 1106, 'acquire': 1107, 'medical': 1108, 'device': 1109, 'coca': 1110, 'cola': 1111, 'shop': 1112, 'competition': 1113, 'enron': 1114, 'houston': 1115, 'pipeline': 1116, 'fund': 1117, 'thousand': 1118, 'former': 1119, 'murdoch': 1120, 'vote': 1121, 'shift': 1122, 'shareholder': 1123, 'approval': 1124, 'headquarters': 1125, 'medium': 1126, 'finally': 1127, 'root': 1128, 'planned': 1129, 'check': 1130, 'staff': 1131, 'walt': 1132, 'disney': 1133, 'might': 1134, 'done': 1135, 'double': 1136, 'michael': 1137, 'eisner': 1138, 'brief': 1139, 'friend': 1140, 'ovitz': 1141, 'must': 1142, 'expand': 1143, 'strategic': 1144, 'standard': 1145, 'ensure': 1146, 'beijing': 1147, 'surged': 1148, 'impressive': 1149, 'nine': 1150, 'slower': 1151, 'recorded': 1152, 'sunday': 1153, 'claiming': 1154, 'predict': 1155, 'county': 1156, 'employer': 1157, 'nikkei': 1158, 'widespread': 1159, 'prompted': 1160, 'richard': 1161, 'branson': 1162, 'margin': 1163, 'disappointing': 1164, 'prediction': 1165, 'exec': 1166, 'urged': 1167, 'assist': 1168, 'developing': 1169, 'monetary': 1170, 'develop': 1171, 'lending': 1172, 'facility': 1173, 'wish': 1174, 'upon': 1175, 'nasdaq': 1176, 'hour': 1177, 'coffee': 1178, 'champ': 1179, 'lackluster': 1180, 'aid': 1181, 'express': 1182, 'shipping': 1183, 'granted': 1184, 'sept': 1185, 'corporation': 1186, 'performance': 1187, 'believed': 1188, 'history': 1189, 'turned': 1190, 'negative': 1191, 'bond': 1192, 'direction': 1193, 'showed': 1194, 'inflation': 1195, 'flat': 1196, 'spending': 1197, 'french': 1198, 'france': 1199, 'replace': 1200, 'resignation': 1201, 'governing': 1202, 'party': 1203, 'intel': 1204, 'making': 1205, 'better': 1206, 'viacom': 1207, 'howard': 1208, 'stern': 1209, 'switch': 1210, 'satellite': 1211, 'radio': 1212, 'deutsche': 1213, 'ag': 1214, 'cincinnati': 1215, 'investment': 1216, 'plus': 1217, 'le': 1218, 'export': 1219, 'find': 1220, 'jim': 1221, 'remember': 1222, 'failing': 1223, 'insurer': 1224, 'real': 1225, 'estate': 1226, 'broke': 1227, 'territory': 1228, 'prove': 1229, 'northern': 1230, 'awaits': 1231, 'greenspan': 1232, 'barely': 1233, 'moved': 1234, 'address': 1235, 'point': 1236, 'cash': 1237, 'coming': 1238, 'soon': 1239, 'able': 1240, 'balance': 1241, 'screen': 1242, 'initiative': 1243, 'link': 1244, 'machine': 1245, 'nortel': 1246, 'fewer': 1247, 'exit': 1248, 'ottawa': 1249, 'eliminate': 1250, 'previously': 1251, 'estimated': 1252, 'buzz': 1253, 'amazon': 1254, 'los': 1255, 'mail': 1256, 'dvd': 1257, 'plunged': 1258, 'dot': 1259, 'movie': 1260, 'fda': 1261, 'import': 1262, 'whether': 1263, 'use': 1264, 'secretary': 1265, 'indonesian': 1266, 'diplomat': 1267, 'improve': 1268, 'bad': 1269, 'jakarta': 1270, 'indonesia': 1271, 'majority': 1272, 'supplier': 1273, 'pm': 1274, 'treat': 1275, 'heart': 1276, 'la': 1277, 'vega': 1278, 'user': 1279, 'attempt': 1280, 'p': 1281, 'g': 1282, 'continued': 1283, 'ups': 1284, 'ranked': 1285, 'behind': 1286, 'greater': 1287, 'manage': 1288, 'effect': 1289, 'college': 1290, 'lowered': 1291, 'expense': 1292, 'saving': 1293, 'sponsored': 1294, 'problem': 1295, 'additional': 1296, 'seven': 1297, 'senior': 1298, 'au': 1299, 'property': 1300, 'trust': 1301, 'pc': 1302, 'enterprise': 1303, 'notebook': 1304, 'shipment': 1305, 'grew': 1306, 'announcement': 1307, 'strength': 1308, 'contained': 1309, 'african': 1310, 'mine': 1311, 'judge': 1312, 'impose': 1313, 'warning': 1314, 'enough': 1315, 'january': 1316, 'airport': 1317, 'f': 1318, 'kennedy': 1319, 'passenger': 1320, 'signal': 1321, 'studio': 1322, 'banned': 1323, 'speculation': 1324, 'struck': 1325, 'pound': 1326, 'euro': 1327, 'fined': 1328, 'universal': 1329, 'sa': 1330, 'bos': 1331, 'jean': 1332, 'issued': 1333, 'period': 1334, 'hard': 1335, 'disc': 1336, 'stronger': 1337, 'restaurant': 1338, 'weather': 1339, 'park': 1340, 'campbell': 1341, 'soup': 1342, 'improvement': 1343, 'overtime': 1344, 'rule': 1345, 'outsourcing': 1346, 'overseas': 1347, 'mean': 1348, 'seems': 1349, 'working': 1350, 'ask': 1351, 'probably': 1352, 'supposed': 1353, 'know': 1354, 'showing': 1355, 'march': 1356, 'jump': 1357, 'provides': 1358, 'restriction': 1359, 'expect': 1360, 'quickly': 1361, 'web': 1362, 'oct': 1363, 'rite': 1364, 'october': 1365, 'battery': 1366, 'mix': 1367, 'dropping': 1368, 'great': 1369, 'become': 1370, 'past': 1371, 'name': 1372, 'rich': 1373, 'local': 1374, 'discovered': 1375, 'mother': 1376, 'present': 1377, 'delayed': 1378, 'postponed': 1379, 'yet': 1380, 'release': 1381, 'statement': 1382, 'challenge': 1383, 'fresh': 1384, 'forced': 1385, 'allowing': 1386, 'equipment': 1387, 'newly': 1388, 'cancer': 1389, 'construction': 1390, 'highest': 1391, 'boosting': 1392, 'continuing': 1393, 'rock': 1394, 'proposal': 1395, 'anything': 1396, 'fix': 1397, 'serious': 1398, 'threatens': 1399, 'mci': 1400, 'paid': 1401, 'distance': 1402, 'britain': 1403, 'license': 1404, 'suspended': 1405, 'begin': 1406, 'releasing': 1407, 'stelco': 1408, 'steel': 1409, 'received': 1410, 'bay': 1411, 'restructuring': 1412, 'hamilton': 1413, 'violence': 1414, 'india': 1415, 'slowed': 1416, 'familiar': 1417, 'individual': 1418, 'firing': 1419, 'buyout': 1420, 'minority': 1421, 'division': 1422, 'follow': 1423, 'ny': 1424, 'trend': 1425, 'across': 1426, 'fail': 1427, 'national': 1428, 'regulatory': 1429, 'virtually': 1430, 'every': 1431, 'region': 1432, 'pressure': 1433, 'extended': 1434, 'steve': 1435, 'ballmer': 1436, 'finish': 1437, 'mixed': 1438, 'finished': 1439, 'forward': 1440, 'senator': 1441, 'senate': 1442, 'armed': 1443, 'committee': 1444, 'defense': 1445, 'investigate': 1446, 'effort': 1447, 'tip': 1448, 'slowdown': 1449, 'ex': 1450, 'cover': 1451, 'deeper': 1452, 'junk': 1453, 'beer': 1454, 'distributor': 1455, 'aside': 1456, 'money': 1457, 'penalty': 1458, 'initial': 1459, 'nokia': 1460, 'texas': 1461, 'instrument': 1462, 'sent': 1463, 'zealand': 1464, 'governor': 1465, 'alan': 1466, 'single': 1467, 'conflict': 1468, 'mutual': 1469, 'developed': 1470, 'whole': 1471, 'regulation': 1472, 'prime': 1473, 'organized': 1474, 'slowing': 1475, 'lender': 1476, 'council': 1477, 'analysis': 1478, 'space': 1479, 'mumbai': 1480, 'nov': 1481, 'study': 1482, 'rank': 1483, 'dangerous': 1484, 'jersey': 1485, 'detroit': 1486, 'atlanta': 1487, 'ranking': 1488, 'morgan': 1489, 'crime': 1490, 'aim': 1491, 'sister': 1492, 'allowed': 1493, 'pocket': 1494, 'twice': 1495, 'hollinger': 1496, 'mostly': 1497, 'fare': 1498, 'lesson': 1499, 'learn': 1500, 'radical': 1501, 'settled': 1502, 'yen': 1503, 'suffering': 1504, 'repeat': 1505, 'amsterdam': 1506, 'dutch': 1507, 'w': 1508, 'surprising': 1509, 'm': 1510, 'multiple': 1511, 'disease': 1512, 'affect': 1513, 'really': 1514, 'education': 1515, 'care': 1516, 'massive': 1517, 'run': 1518, 'aimed': 1519, 'hike': 1520, 'stay': 1521, 'abu': 1522, 'gulf': 1523, 'bring': 1524, 'cartel': 1525, 'formal': 1526, 'limit': 1527, 'venture': 1528, 'troubled': 1529, 'german': 1530, 'joint': 1531, 'life': 1532, 'suicide': 1533, 'antidepressant': 1534, 'appears': 1535, 'linked': 1536, 'child': 1537, 'advisory': 1538, 'concluded': 1539, 'shut': 1540, 'hollywood': 1541, 'film': 1542, 'channel': 1543, 'june': 1544, 'fierce': 1545, 'luxury': 1546, 'car': 1547, 'watch': 1548, 'important': 1549, 'avoid': 1550, 'brent': 1551, 'cold': 1552, 'snap': 1553, 'afternoon': 1554, 'pre': 1555, 'southwest': 1556, 'traffic': 1557, 'increasing': 1558, 'november': 1559, 'seat': 1560, 'plane': 1561, 'paris': 1562, 'rather': 1563, 'liberal': 1564, 'drawn': 1565, 'unlikely': 1566, 'left': 1567, 'mile': 1568, 'malaysia': 1569, 'idea': 1570, 'owned': 1571, 'entire': 1572, 'cingular': 1573, 'wireless': 1574, 'charley': 1575, 'coast': 1576, 'risk': 1577, 'faced': 1578, 'quality': 1579, 'paying': 1580, 'fast': 1581, 'growing': 1582, 'toy': 1583, 'merrill': 1584, 'lynch': 1585, 'newratings': 1586, 'involved': 1587, 'eagle': 1588, 'accepted': 1589, 'includes': 1590, 'flagship': 1591, 'database': 1592, 'worm': 1593, 'carlos': 1594, 'demanded': 1595, 'either': 1596, 'fired': 1597, 'loan': 1598, 'comment': 1599, 'supported': 1600, 'retreat': 1601, 'upbeat': 1602, 'opposition': 1603, 'twist': 1604, 'earlier': 1605, 'discussion': 1606, 'theme': 1607, 'hong': 1608, 'kong': 1609, 'driving': 1610, 'injury': 1611, 'road': 1612, 'possibly': 1613, 'ease': 1614, 'eased': 1615, 'cabinet': 1616, 'steep': 1617, 'including': 1618, 'deadly': 1619, 'attack': 1620, 'arabia': 1621, 'chase': 1622, 'impact': 1623, 'led': 1624, 'hang': 1625, 'vehicle': 1626, 'seem': 1627, 'unite': 1628, 'joining': 1629, 'motor': 1630, 'mainstream': 1631, 'test': 1632, 'access': 1633, 'telecom': 1634, 'amount': 1635, 'wonder': 1636, 'exactly': 1637, 'agree': 1638, 'operating': 1639, 'related': 1640, 'climb': 1641, 'reaching': 1642, 'workforce': 1643, 'worldwide': 1644, 'part': 1645, 'hp': 1646, 'sight': 1647, 'hardware': 1648, 'printer': 1649, 'laid': 1650, 'tv': 1651, 'music': 1652, 'player': 1653, 'content': 1654, 'sealed': 1655, 'beating': 1656, 'cole': 1657, 'success': 1658, 'lose': 1659, 'threat': 1660, 'upgrade': 1661, 'expressed': 1662, 'hero': 1663, 'knight': 1664, 'easy': 1665, 'watcher': 1666, 'carried': 1667, 'riding': 1668, 'beleaguered': 1669, 'thin': 1670, 'republican': 1671, 'convention': 1672, 'storm': 1673, 'anti': 1674, 'terror': 1675, 'scottish': 1676, 'banker': 1677, 'legislation': 1678, 'jail': 1679, 'human': 1680, 'think': 1681, 'disaster': 1682, 'resolve': 1683, 'cautious': 1684, 'matched': 1685, 'drawing': 1686, 'dream': 1687, 'perfect': 1688, 'fine': 1689, 'come': 1690, 'true': 1691, 'natural': 1692, 'review': 1693, 'perhaps': 1694, 'ipo': 1695, 'trail': 1696, 'tried': 1697, 'managed': 1698, 'approach': 1699, 'abbey': 1700, 'longer': 1701, 'complex': 1702, 'spanish': 1703, 'brings': 1704, 'side': 1705, 'truck': 1706, 'along': 1707, 'apartment': 1708, 'developer': 1709, 'calling': 1710, 'urban': 1711, 'violated': 1712, 'manhattan': 1713, 'professional': 1714, 'proceeding': 1715, 'cap': 1716, 'virus': 1717, 'catching': 1718, 'dead': 1719, 'simple': 1720, 'complicated': 1721, 'premium': 1722, 'kept': 1723, 'lingering': 1724, 'southern': 1725, 'california': 1726, 'shed': 1727, 'eight': 1728, 'th': 1729, 'summary': 1730, 'eventually': 1731, 'threaten': 1732, 'seeking': 1733, 'manager': 1734, 'leaving': 1735, 'painkiller': 1736, 'adopted': 1737, 'friendly': 1738, 'daily': 1739, 'starting': 1740, 'july': 1741, 'apparently': 1742, 'book': 1743, 'halo': 1744, 'score': 1745, 'game': 1746, 'video': 1747, 'sold': 1748, 'finding': 1749, 'card': 1750, 'larger': 1751, 'partner': 1752, 'widened': 1753, 'george': 1754, 'hire': 1755, 'window': 1756, 'language': 1757, 'neck': 1758, 'scientific': 1759, 'separate': 1760, 'stroke': 1761, 'genetically': 1762, 'engineered': 1763, 'step': 1764, 'alert': 1765, 'soft': 1766, 'patch': 1767, 'design': 1768, 'astronaut': 1769, 'moon': 1770, 'beyond': 1771, 'sustained': 1772, 'automaker': 1773, 'emission': 1774, 'woman': 1775, 'died': 1776, 'surgery': 1777, 'saint': 1778, 'hospital': 1779, 'river': 1780, 'stopped': 1781, 'internal': 1782, 'lawmaker': 1783, 'lack': 1784, 'spent': 1785, 'approve': 1786, 'sanction': 1787, 'declared': 1788, 'illegal': 1789, 'confirms': 1790, 'warn': 1791, 'cast': 1792, 'monthly': 1793, 'commerce': 1794, 'wide': 1795, 'trump': 1796, 'casino': 1797, 'proposed': 1798, 'divided': 1799, 'hedge': 1800, 'register': 1801, 'available': 1802, 'larry': 1803, 'intelligence': 1804, 'community': 1805, 'terrorist': 1806, 'never': 1807, 'happened': 1808, 'switzerland': 1809, 'critic': 1810, 'structure': 1811, 'closely': 1812, 'foe': 1813, 'roy': 1814, 'forest': 1815, 'comcast': 1816, 'addition': 1817, 'quiet': 1818, 'bln': 1819, 'spirit': 1820, 'climbed': 1821, 'setting': 1822, 'jack': 1823, 'box': 1824, 'soared': 1825, 'robust': 1826, 'lehman': 1827, 'brother': 1828, 'treo': 1829, 'palmone': 1830, 'licensing': 1831, 'generation': 1832, 'smart': 1833, 'directly': 1834, 'email': 1835, 'tap': 1836, 'lost': 1837, 'editor': 1838, 'stephen': 1839, 'deputy': 1840, 'managing': 1841, 'named': 1842, 'symantec': 1843, 'veritas': 1844, 'common': 1845, 'citigroup': 1846, 'banking': 1847, 'qantas': 1848, 'route': 1849, 'alliance': 1850, 'pair': 1851, 'blocked': 1852, 'tribute': 1853, 'lord': 1854, 'trying': 1855, 'meet': 1856, 'silvio': 1857, 'berlusconi': 1858, 'putin': 1859, 'prize': 1860, 'anger': 1861, 'referendum': 1862, 'turkey': 1863, 'membership': 1864, 'several': 1865, 'let': 1866, 'decide': 1867, 'abandon': 1868, 'wildcat': 1869, 'voted': 1870, 'return': 1871, 'immediately': 1872, 'extension': 1873, 'water': 1874, 'reality': 1875, 'passed': 1876, 'sea': 1877, 'milestone': 1878, 'stayed': 1879, 'blood': 1880, 'acquired': 1881, 'station': 1882, 'shell': 1883, 'invest': 1884, 'shake': 1885, 'pledged': 1886, 'browser': 1887, 'lenovo': 1888, 'information': 1889, 'widely': 1890, 'digital': 1891, 'camera': 1892, 'partnership': 1893, 'improving': 1894, 'press': 1895, 'significant': 1896, 'peak': 1897, 'milwaukee': 1898, 'paul': 1899, 'story': 1900, 'baseball': 1901, 'straight': 1902, 'sigh': 1903, 'predicted': 1904, 'seattle': 1905, 'digit': 1906, 'miner': 1907, 'un': 1908, 'reveals': 1909, 'especially': 1910, 'r': 1911, 'fan': 1912, 'secure': 1913, 'considered': 1914, 'site': 1915, 'northeast': 1916, 'also': 1917, 'fully': 1918, 'visa': 1919, 'association': 1920, 'blamed': 1921, 'beat': 1922, 'worth': 1923, 'shook': 1924, 'revealing': 1925, 'secret': 1926, 'winning': 1927, 'streak': 1928, 'siemens': 1929, 'cellphone': 1930, 'flaw': 1931, 'newest': 1932, 'handset': 1933, 'travel': 1934, 'corner': 1935, 'pfizer': 1936, 'sends': 1937, 'popular': 1938, 'celebrex': 1939, 'royal': 1940, 'police': 1941, 'gear': 1942, 'although': 1943, 'cowboy': 1944, 'marketing': 1945, 'inside': 1946, 'pentagon': 1947, 'course': 1948, 'prompting': 1949, 'mad': 1950, 'cow': 1951, 'possibility': 1952, 'animal': 1953, 'tested': 1954, 'clean': 1955, 'david': 1956, 'moving': 1957, 'bar': 1958, 'serving': 1959, 'glazer': 1960, 'malcolm': 1961, 'swiss': 1962, 'resource': 1963, 'edged': 1964, 'bolster': 1965, 'confident': 1966, 'row': 1967, 'brussels': 1968, 'brought': 1969, 'guy': 1970, 'pulled': 1971, 'contest': 1972, 'arch': 1973, 'asks': 1974, 'value': 1975, 'capacity': 1976, 'politics': 1977, 'coach': 1978, 'civilian': 1979, 'mount': 1980, 'added': 1981, 'struggle': 1982, 'cox': 1983, 'class': 1984, 'nd': 1985, 'material': 1986, 'cellular': 1987, 'agreeing': 1988, 'giving': 1989, 'chipmaker': 1990, 'spend': 1991, 'philippine': 1992, 'rd': 1993, 'transportation': 1994, 'recall': 1995, 'blockbuster': 1996, 'pain': 1997, 'hotel': 1998, 'usatoday': 1999, 'activity': 2000, 'delivery': 2001, 'athletic': 2002, 'shoe': 2003, 'improved': 2004, 'adding': 2005, 'gathering': 2006, 'pace': 2007, 'semiconductor': 2008, 'micro': 2009, 'flash': 2010, 'memory': 2011, 'cross': 2012, 'border': 2013, 'bargain': 2014, 'breaking': 2015, 'waiting': 2016, 'northwest': 2017, 'distribution': 2018, 'nigeria': 2019, 'nigerian': 2020, 'copy': 2021, 'extra': 2022, 'onto': 2023, 'path': 2024, 'voice': 2025, 'motorola': 2026, 'area': 2027, 'cnn': 2028, 'champion': 2029, 'lover': 2030, 'member': 2031, 'ca': 2032, 'associate': 2033, 'promised': 2034, 'santander': 2035, 'scotland': 2036, 'indicated': 2037, 'eas': 2038, 'expands': 2039, 'fallen': 2040, 'marking': 2041, 'emerge': 2042, 'profitable': 2043, 'size': 2044, 'fleet': 2045, 'realnetworks': 2046, 'download': 2047, 'ending': 2048, 'cable': 2049, 'via': 2050, 'subscriber': 2051, 'aggressive': 2052, 'bound': 2053, 'heavyweight': 2054, 'academic': 2055, 'warming': 2056, 'promote': 2057, 'nuclear': 2058, 'exploration': 2059, 'turf': 2060, 'apparent': 2061, 'knock': 2062, 'continues': 2063, 'produce': 2064, 'different': 2065, 'holy': 2066, 'operator': 2067, 'georgia': 2068, 'headed': 2069, 'plea': 2070, 'letter': 2071, 'ray': 2072, 'retirement': 2073, 'sometimes': 2074, 'offense': 2075, 'demanding': 2076, 'failed': 2077, 'adviser': 2078, 'farm': 2079, 'awaited': 2080, 'craig': 2081, 'conway': 2082, 'ford': 2083, 'argentina': 2084, 'cooperation': 2085, 'document': 2086, 'putting': 2087, 'returned': 2088, 'wait': 2089, 'barrier': 2090, 'luck': 2091, 'robert': 2092, 'pact': 2093, 'settlement': 2094, 'carrying': 2095, 'kremlin': 2096, 'ministry': 2097, 'pro': 2098, 'built': 2099, 'writer': 2100, 'iron': 2101, 'extending': 2102, 'officially': 2103, 'abandoned': 2104, 'associated': 2105, 'supporting': 2106, 'ability': 2107, 'respond': 2108, 'dropped': 2109, 'event': 2110, 'broadcast': 2111, 'crater': 2112, 'leave': 2113, 'wi': 2114, 'fi': 2115, 'speed': 2116, 'hype': 2117, 'emerging': 2118, 'eye': 2119, 'remark': 2120, 'advantage': 2121, 'mouse': 2122, 'fit': 2123, 'launching': 2124, 'prominent': 2125, 'woe': 2126, 'feel': 2127, 'soldier': 2128, 'agent': 2129, 'put': 2130, 'deadline': 2131, 'resolution': 2132, 'ill': 2133, 'resident': 2134, 'prescription': 2135, 'reject': 2136, 'spain': 2137, 'complete': 2138, 'safeway': 2139, 'goal': 2140, 'assembly': 2141, 'designed': 2142, 'body': 2143, 'touch': 2144, 'mac': 2145, 'pattern': 2146, 'difference': 2147, 'jungle': 2148, 'website': 2149, 'quest': 2150, 'ipod': 2151, 'promise': 2152, 'live': 2153, 'science': 2154, 'deliver': 2155, 'publishing': 2156, 'heavily': 2157, 'gun': 2158, 'montreal': 2159, 'brazil': 2160, 'congress': 2161, 'send': 2162, 'cell': 2163, 'kingdom': 2164, 'billionaire': 2165, 'table': 2166, 'apple': 2167, 'others': 2168, 'lcd': 2169, 'infringement': 2170, 'liquid': 2171, 'display': 2172, 'description': 2173, 'chance': 2174, 'curb': 2175, 'vice': 2176, 'north': 2177, 'carolina': 2178, 'blow': 2179, 'researcher': 2180, 'project': 2181, 'chile': 2182, 'western': 2183, 'id': 2184, 'identity': 2185, 'sweet': 2186, 'bitter': 2187, 'presence': 2188, 'far': 2189, 'fly': 2190, 'theft': 2191, 'sentenced': 2192, 'prison': 2193, 'april': 2194, 'cloud': 2195, 'automotive': 2196, 'creating': 2197, 'fueled': 2198, 'argument': 2199, 'narrower': 2200, 'reduction': 2201, 'smith': 2202, 'west': 2203, 'pull': 2204, 'middle': 2205, 'admits': 2206, 'fixing': 2207, 'southeast': 2208, 'audit': 2209, 'venezuelan': 2210, 'caracas': 2211, 'hugo': 2212, 'chavez': 2213, 'charged': 2214, 'electoral': 2215, 'solid': 2216, 'franklin': 2217, 'reporter': 2218, 'wisconsin': 2219, 'closer': 2220, 'gathered': 2221, 'victory': 2222, 'hailed': 2223, 'debut': 2224, 'anticipated': 2225, 'priced': 2226, 'raising': 2227, 'explosive': 2228, 'homeland': 2229, 'eli': 2230, 'door': 2231, 'handed': 2232, 'spokesman': 2233, 'belgian': 2234, 'brazilian': 2235, 'server': 2236, 'shock': 2237, 'broadcasting': 2238, 'eurozone': 2239, 'poll': 2240, 'soar': 2241, 'hat': 2242, 'jr': 2243, 'kevin': 2244, 'bc': 2245, 'vancouver': 2246, 'needed': 2247, 'recover': 2248, 'rest': 2249, 'overture': 2250, 'virginia': 2251, 'powerful': 2252, 'supercomputer': 2253, 'failure': 2254, 'cease': 2255, 'austrian': 2256, 'va': 2257, 'tag': 2258, 'recently': 2259, 'cisco': 2260, 'walk': 2261, 'henry': 2262, 'walked': 2263, 'abuse': 2264, 'journalist': 2265, 'reaction': 2266, 'standing': 2267, 'rejected': 2268, 'mexico': 2269, 'transfer': 2270, 'reward': 2271, 'ton': 2272, 'succession': 2273, 'atop': 2274, 'non': 2275, 'guard': 2276, 'expanding': 2277, 'momentum': 2278, 'treatment': 2279, 'acquires': 2280, 'continent': 2281, 'stem': 2282, 'hearing': 2283, 'ranging': 2284, 'novell': 2285, 'option': 2286, 'compared': 2287, 'ed': 2288, 'electronic': 2289, 'navy': 2290, 'sky': 2291, 'vladimir': 2292, 'economist': 2293, 'rapid': 2294, 'safety': 2295, 'injured': 2296, 'chart': 2297, 'representative': 2298, 'together': 2299, 'ip': 2300, 'opportunity': 2301, 'pass': 2302, 'providing': 2303, 'loom': 2304, 'answer': 2305, 'ship': 2306, 'vulnerable': 2307, 'govt': 2308, 'institution': 2309, 'defence': 2310, 'contractor': 2311, 'assessment': 2312, 'causing': 2313, 'disruption': 2314, 'spacecraft': 2315, 'caution': 2316, 'sport': 2317, 'nepal': 2318, 'tour': 2319, 'tourist': 2320, 'rebel': 2321, 'joe': 2322, 'unfair': 2323, 'bringing': 2324, 'tie': 2325, 'wounded': 2326, 'southeastern': 2327, 'looking': 2328, 'whose': 2329, 'delivered': 2330, 'spark': 2331, 'fought': 2332, 'speech': 2333, 'signing': 2334, 'intended': 2335, 'immediate': 2336, 'everyone': 2337, 'winner': 2338, 'opinion': 2339, 'column': 2340, 'mr': 2341, 'punch': 2342, 'fastest': 2343, 'command': 2344, 'training': 2345, 'commander': 2346, 'award': 2347, 'missile': 2348, 'fails': 2349, 'prepared': 2350, 'reader': 2351, 'similar': 2352, 'read': 2353, 'gave': 2354, 'century': 2355, 'primary': 2356, 'barcelona': 2357, 'ebay': 2358, 'irish': 2359, 'italy': 2360, 'head': 2361, 'tool': 2362, 'repair': 2363, 'fossil': 2364, 'positive': 2365, 'type': 2366, 'believe': 2367, 'dc': 2368, 'netherlands': 2369, 'suffered': 2370, 'ben': 2371, 'jerry': 2372, 'ice': 2373, 'crash': 2374, 'male': 2375, 'surprise': 2376, 'canceled': 2377, 'baltimore': 2378, 'stalled': 2379, 'threw': 2380, 'bridge': 2381, 'titan': 2382, 'pack': 2383, 'watched': 2384, 'receiving': 2385, 'transaction': 2386, 'critical': 2387, 'liberty': 2388, 'foot': 2389, 'voting': 2390, 'merge': 2391, 'always': 2392, 'society': 2393, 'rebound': 2394, 'quits': 2395, 'created': 2396, 'pt': 2397, 'telephony': 2398, 'deployment': 2399, 'hear': 2400, 'asking': 2401, 'imposed': 2402, 'speaks': 2403, 'ground': 2404, 'alleging': 2405, 'heat': 2406, 'feeling': 2407, 'del': 2408, 'testimony': 2409, 'loses': 2410, 'halt': 2411, 'zone': 2412, 'worse': 2413, 'overnight': 2414, 'condition': 2415, 'however': 2416, 'going': 2417, 'pulling': 2418, 'eve': 2419, 'preview': 2420, 'smartphone': 2421, 'introduced': 2422, 'carry': 2423, 'processor': 2424, 'multimedia': 2425, 'feature': 2426, 'include': 2427, 'mp': 2428, 'capability': 2429, 'capture': 2430, 'thought': 2431, 'spring': 2432, 'reduced': 2433, 'evening': 2434, 'planning': 2435, 'peer': 2436, 'danger': 2437, 'series': 2438, 'shrugged': 2439, 'funding': 2440, 'bubble': 2441, 'burst': 2442, 'circulation': 2443, 'copyright': 2444, 'act': 2445, 'pointed': 2446, 'england': 2447, 'hiring': 2448, 'buffalo': 2449, 'turning': 2450, 'lockout': 2451, 'locked': 2452, 'rice': 2453, 'easily': 2454, 'easier': 2455, 'unchanged': 2456, 'escape': 2457, 'formed': 2458, 'de': 2459, 'specie': 2460, 'bob': 2461, 'wife': 2462, 'medicine': 2463, 'grand': 2464, 'university': 2465, 'active': 2466, 'cited': 2467, 'destruction': 2468, 'outcome': 2469, 'threatening': 2470, 'ivory': 2471, 'protest': 2472, 'versus': 2473, 'chrysler': 2474, 'attacked': 2475, 'telling': 2476, 'rim': 2477, 'intellectual': 2478, 'cause': 2479, 'insisted': 2480, 'actually': 2481, 'iraqi': 2482, 'hurdle': 2483, 'welcomed': 2484, 'seventh': 2485, 'match': 2486, 'colorado': 2487, 'placed': 2488, 'wanted': 2489, 'total': 2490, 'simply': 2491, 'listing': 2492, 'bet': 2493, 'overall': 2494, 'accusation': 2495, 'kind': 2496, 'el': 2497, 'plot': 2498, 'fixed': 2499, 'israel': 2500, 'die': 2501, 'poverty': 2502, 'age': 2503, 'opening': 2504, 'duke': 2505, 'square': 2506, 'milan': 2507, 'flow': 2508, 'flurry': 2509, 'instead': 2510, 'resort': 2511, 'delhi': 2512, 'sao': 2513, 'laboratory': 2514, 'grab': 2515, 'comply': 2516, 'fighting': 2517, 'completed': 2518, 'shape': 2519, 'outage': 2520, 'special': 2521, 'crucial': 2522, 'star': 2523, 'pas': 2524, 'sixth': 2525, 'overcome': 2526, 'melbourne': 2527, 'hall': 2528, 'sense': 2529, 'bloc': 2530, 'fcc': 2531, 'supreme': 2532, 'tomorrow': 2533, 'bounce': 2534, 'galaxy': 2535, 'dial': 2536, 'urge': 2537, 'spread': 2538, 'ten': 2539, 'colleague': 2540, 'difficult': 2541, 'process': 2542, 'count': 2543, 'jan': 2544, 'ousted': 2545, 'nz': 2546, 'alive': 2547, 'braced': 2548, 'wider': 2549, 'wrap': 2550, 'seemed': 2551, 'suspect': 2552, 'scientist': 2553, 'weighs': 2554, 'rout': 2555, 'angeles': 2556, 'lion': 2557, 'crm': 2558, 'sen': 2559, 'mary': 2560, 'shown': 2561, 'photo': 2562, 'democrat': 2563, 'minor': 2564, 'integration': 2565, 'belief': 2566, 'delegation': 2567, 'social': 2568, 'laden': 2569, 'tree': 2570, 'east': 2571, 'queen': 2572, 'hidden': 2573, 'selection': 2574, 'happy': 2575, 'earned': 2576, 'creation': 2577, 'ken': 2578, 'andre': 2579, 'land': 2580, 'chosen': 2581, 'chemical': 2582, 'phoenix': 2583, 'pose': 2584, 'earn': 2585, 'greatest': 2586, 'striking': 2587, 'administrator': 2588, 'sbc': 2589, 'relatively': 2590, 'doubled': 2591, 'measure': 2592, 'vow': 2593, 'vowed': 2594, 'quit': 2595, 'connection': 2596, 'storage': 2597, 'backup': 2598, 'specialist': 2599, 'town': 2600, 'string': 2601, 'atmosphere': 2602, 'toshiba': 2603, 'revealed': 2604, 'console': 2605, 'sean': 2606, 'famous': 2607, 'poland': 2608, 'adam': 2609, 'throughout': 2610, 'exclusive': 2611, 'bit': 2612, 'ac': 2613, 'ditch': 2614, 'earth': 2615, 'nec': 2616, 'gene': 2617, 'handheld': 2618, 'idc': 2619, 'watching': 2620, 'heel': 2621, 'taken': 2622, 'messaging': 2623, 'vendor': 2624, 'role': 2625, 'monitoring': 2626, 'investigator': 2627, 'determine': 2628, 'suggested': 2629, 'rivalry': 2630, 'msft': 2631, 'original': 2632, 'sir': 2633, 'bombing': 2634, 'egypt': 2635, 'beef': 2636, 'resume': 2637, 'halted': 2638, 'subject': 2639, 'arrested': 2640, 'compensation': 2641, 'consortium': 2642, 'art': 2643, 'nfl': 2644, 'offensive': 2645, 'unveiled': 2646, 'backing': 2647, 'persuade': 2648, 'snow': 2649, 'berlin': 2650, 'dramatic': 2651, 'fellow': 2652, 'willing': 2653, 'toll': 2654, 'santa': 2655, 'connecticut': 2656, 'incentive': 2657, 'dealer': 2658, 'gateway': 2659, 'freed': 2660, 'stage': 2661, 'defended': 2662, 'wild': 2663, 'forget': 2664, 'missed': 2665, 'stuck': 2666, 'ontario': 2667, 'throwing': 2668, 'sentence': 2669, 'later': 2670, 'button': 2671, 'turnaround': 2672, 'bear': 2673, 'suspected': 2674, 'dealing': 2675, 'fox': 2676, 'denied': 2677, 'silence': 2678, 'fate': 2679, 'yahoo': 2680, 'xp': 2681, 'definition': 2682, 'living': 2683, 'spur': 2684, 'rbi': 2685, 'violation': 2686, 'teacher': 2687, 'cd': 2688, 'coalition': 2689, 'wire': 2690, 'vietnam': 2691, 'landed': 2692, 'arrived': 2693, 'indicator': 2694, 'gone': 2695, 'dubbed': 2696, 'forum': 2697, 'ohio': 2698, 'william': 2699, 'spyware': 2700, 'dell': 2701, 'scare': 2702, 'prince': 2703, 'culture': 2704, 'availability': 2705, 'td': 2706, 'kick': 2707, 'defends': 2708, 'monitor': 2709, 'questioned': 2710, 'round': 2711, 'volume': 2712, 'strange': 2713, 'walter': 2714, 'volatile': 2715, 'textile': 2716, 'protect': 2717, 'tell': 2718, 'worked': 2719, 'refused': 2720, 'existing': 2721, 'computing': 2722, 'silver': 2723, 'destroyed': 2724, 'unless': 2725, 'recording': 2726, 'traditional': 2727, 'included': 2728, 'affair': 2729, 'battling': 2730, 'opposed': 2731, 'silicon': 2732, 'sub': 2733, 'defeat': 2734, 'thomas': 2735, 'terrorism': 2736, 'host': 2737, 'various': 2738, 'boom': 2739, 'committed': 2740, 'easing': 2741, 'indiana': 2742, 'ryder': 2743, 'transport': 2744, 'andrew': 2745, 'ball': 2746, 'agenda': 2747, 'ot': 2748, 'plotting': 2749, 'spammer': 2750, 'king': 2751, 'allegedly': 2752, 'thinking': 2753, 'premier': 2754, 'piece': 2755, 'loyal': 2756, 'birth': 2757, 'task': 2758, 'desktop': 2759, 'platform': 2760, 'clash': 2761, 'split': 2762, 'feared': 2763, 'recommendation': 2764, 'dark': 2765, 'passing': 2766, 'crackdown': 2767, 'mission': 2768, 'pool': 2769, 'inch': 2770, 'gaming': 2771, 'draw': 2772, 'thomson': 2773, 'wind': 2774, 'integrate': 2775, 'landing': 2776, 'leadership': 2777, 'commitment': 2778, 'kentucky': 2779, 'mississippi': 2780, 'oklahoma': 2781, 'tracking': 2782, 'dominated': 2783, 'dna': 2784, 'struggled': 2785, 'triggered': 2786, 'targeted': 2787, 'jury': 2788, 'apology': 2789, 'cruise': 2790, 'introduce': 2791, 'request': 2792, 'welcome': 2793, 'camp': 2794, 'alternative': 2795, 'stick': 2796, 'historic': 2797, 'prior': 2798, 'stance': 2799, 'martin': 2800, 'vast': 2801, 'mass': 2802, 'tackle': 2803, 'hot': 2804, 'marked': 2805, 'caribbean': 2806, 'scrambled': 2807, 'networking': 2808, 'expensive': 2809, 'port': 2810, 'eighth': 2811, 'career': 2812, 'disclosed': 2813, 'environmental': 2814, 'spot': 2815, 'lot': 2816, 'hitting': 2817, 'weapon': 2818, 'replacement': 2819, 'idg': 2820, 'jose': 2821, 'crew': 2822, 'desert': 2823, 'austria': 2824, 'quick': 2825, 'andy': 2826, 'olympic': 2827, 'greece': 2828, 'athens': 2829, 'greek': 2830, 'criticism': 2831, 'stretch': 2832, 'deciding': 2833, 'seal': 2834, 'jp': 2835, 'drove': 2836, 'triple': 2837, 'nothing': 2838, 'arrest': 2839, 'nobel': 2840, 'edition': 2841, 'eastern': 2842, 'info': 2843, 'feed': 2844, 'attention': 2845, 'dog': 2846, 'stiff': 2847, 'alleged': 2848, 'strategy': 2849, 'justin': 2850, 'jaguar': 2851, 'scale': 2852, 'miami': 2853, 'install': 2854, 'michigan': 2855, 'celebrate': 2856, 'dominant': 2857, 'wholesale': 2858, 'accident': 2859, 'kansa': 2860, 'mo': 2861, 'militia': 2862, 'turnover': 2863, 'targeting': 2864, 'currently': 2865, 'tennessee': 2866, 'maryland': 2867, 'prepare': 2868, 'franchise': 2869, 'harry': 2870, 'acting': 2871, 'thwart': 2872, 'allows': 2873, 'stood': 2874, 'pakistan': 2875, 'appeared': 2876, 'ninth': 2877, 'clock': 2878, 'cup': 2879, 'linux': 2880, 'munich': 2881, 'denies': 2882, 'lee': 2883, 'obtaining': 2884, 'erp': 2885, 'responsibility': 2886, 'relation': 2887, 'responsible': 2888, 'kill': 2889, 'birthday': 2890, 'veteran': 2891, 'institute': 2892, 'paper': 2893, 'picked': 2894, 'son': 2895, 'grabbed': 2896, 'x': 2897, 'district': 2898, 'minnesota': 2899, 'counting': 2900, 'incumbent': 2901, 'deploy': 2902, 'client': 2903, 'blackberry': 2904, 'train': 2905, 'spreading': 2906, 'kid': 2907, 'van': 2908, 'gaza': 2909, 'strip': 2910, 'clearly': 2911, 'swedish': 2912, 'palmsource': 2913, 'turkish': 2914, 'ride': 2915, 'produced': 2916, 'barred': 2917, 'pnet': 2918, 'dubai': 2919, 'usc': 2920, 'mich': 2921, 'aboard': 2922, 'entered': 2923, 'hunting': 2924, 'particularly': 2925, 'trip': 2926, 'citizen': 2927, 'error': 2928, 'complaint': 2929, 'contact': 2930, 'mob': 2931, 'brink': 2932, 'picking': 2933, 'felt': 2934, 'libya': 2935, 'regime': 2936, 'coup': 2937, 'joined': 2938, 'earthquake': 2939, 'informed': 2940, 'successful': 2941, 'dual': 2942, 'golf': 2943, 'redskin': 2944, 'influence': 2945, 'adobe': 2946, 'format': 2947, 'slam': 2948, 'israeli': 2949, 'wound': 2950, 'engineer': 2951, 'rover': 2952, 'ailing': 2953, 'shanghai': 2954, 'korean': 2955, 'dallas': 2956, 'resumed': 2957, 'fair': 2958, 'rapidly': 2959, 'breakthrough': 2960, 'narrow': 2961, 'map': 2962, 'met': 2963, 'verdict': 2964, 'multi': 2965, 'province': 2966, 'prepares': 2967, 'najaf': 2968, 'nc': 2969, 'sparked': 2970, 'siebel': 2971, 'sweden': 2972, 'opponent': 2973, 'duck': 2974, 'scene': 2975, 'tower': 2976, 'arena': 2977, 'killed': 2978, 'centre': 2979, 'eager': 2980, 'sohu': 2981, 'suspension': 2982, 'wright': 2983, 'master': 2984, 'boy': 2985, 'unprecedented': 2986, 'born': 2987, 'testing': 2988, 'refugee': 2989, 'embargo': 2990, 'stepped': 2991, 'scott': 2992, 'devil': 2993, 'knew': 2994, 'tank': 2995, 'talking': 2996, 'suite': 2997, 'league': 2998, 'achievement': 2999, 'jeeves': 3000, 'catch': 3001, 'sideline': 3002, 'orleans': 3003, 'newsfactor': 3004, 'island': 3005, 'started': 3006, 'overhaul': 3007, 'k': 3008, 'sox': 3009, 'playing': 3010, 'retain': 3011, 'proved': 3012, 'privately': 3013, 'celtic': 3014, 'potentially': 3015, 'lineup': 3016, 'blast': 3017, 'liverpool': 3018, 'mate': 3019, 'voter': 3020, 'ft': 3021, 'juan': 3022, 'nvidia': 3023, 'graphic': 3024, 'hewlett': 3025, 'packard': 3026, 'remaining': 3027, 'lab': 3028, 'establish': 3029, 'pitch': 3030, 'clue': 3031, 'steal': 3032, 'club': 3033, 'sharing': 3034, 'ally': 3035, 'plenty': 3036, 'observer': 3037, 'restore': 3038, 'anthony': 3039, 'appointed': 3040, 'crack': 3041, 'invasion': 3042, 'reveal': 3043, 'philip': 3044, 'fact': 3045, 'tony': 3046, 'tribunal': 3047, 'tied': 3048, 'caught': 3049, 'uranium': 3050, 'crowd': 3051, 'unveil': 3052, 'conservative': 3053, 'illegally': 3054, 'laptop': 3055, 'appear': 3056, 'example': 3057, 'graham': 3058, 'audience': 3059, 'counterpart': 3060, 'truce': 3061, 'cleveland': 3062, 'ballot': 3063, 'suzuki': 3064, 'older': 3065, 'costello': 3066, 'colombia': 3067, 'favorite': 3068, 'collaboration': 3069, 'racing': 3070, 'rail': 3071, 'throw': 3072, 'ii': 3073, 'retired': 3074, 'driver': 3075, 'hd': 3076, 'controversy': 3077, 'orlando': 3078, 'label': 3079, 'oakland': 3080, 'down': 3081, 'sexual': 3082, 'pa': 3083, 'clinched': 3084, 'nl': 3085, 'heading': 3086, 'manny': 3087, 'missing': 3088, 'pursue': 3089, 'lock': 3090, 'triumph': 3091, 'rumor': 3092, 'mar': 3093, 'tear': 3094, 'siege': 3095, 'taiwan': 3096, 'semi': 3097, 'espn': 3098, 'everything': 3099, 'unique': 3100, 'seriously': 3101, 'ceremony': 3102, 'magic': 3103, 'powered': 3104, 'aide': 3105, 'nintendo': 3106, 'arrival': 3107, 'portable': 3108, 'communist': 3109, 'marathon': 3110, 'swim': 3111, 'crop': 3112, 'antonio': 3113, 'pushing': 3114, 'tom': 3115, 'robot': 3116, 'maybe': 3117, 'helicopter': 3118, 'genesis': 3119, 'crashed': 3120, 'capsule': 3121, 'nasa': 3122, 'bird': 3123, 'amd': 3124, 'assault': 3125, 'blog': 3126, 'captain': 3127, 'verdana': 3128, 'sans': 3129, 'serif': 3130, 'arial': 3131, 'helvetica': 3132, 'color': 3133, 'washingtonpost': 3134, 'font': 3135, 'sp': 3136, 'quite': 3137, 'spam': 3138, 'discovery': 3139, 'planet': 3140, 'love': 3141, 'virtual': 3142, 'tune': 3143, 'downloading': 3144, 'itunes': 3145, 'voip': 3146, 'thrown': 3147, 'shuttle': 3148, 'rocket': 3149, 'iran': 3150, 'refuse': 3151, 'us': 3152, 'tiny': 3153, 'fault': 3154, 'kenyan': 3155, 'kyoto': 3156, 'kenya': 3157, 'maathai': 3158, 'protocol': 3159, 'climate': 3160, 'entry': 3161, 'cybersecurity': 3162, 'abruptly': 3163, 'firefox': 3164, 'mozilla': 3165, 'roll': 3166, 'code': 3167, 'harvard': 3168, 'stolen': 3169, 'trojan': 3170, 'horse': 3171, 'text': 3172, 'imac': 3173, 'expo': 3174, 'hacker': 3175, 'artist': 3176, 'cultural': 3177, 'playstation': 3178, 'explorer': 3179, 'o': 3180, 'sql': 3181, 'rep': 3182, 'determined': 3183, 'basic': 3184, 'bowl': 3185, 'medal': 3186, 'athlete': 3187, 'anyone': 3188, 'xbox': 3189, 'andreas': 3190, 'cassini': 3191, 'saturn': 3192, 'fbi': 3193, 'cyber': 3194, 'audio': 3195, 'orbit': 3196, 'walking': 3197, 'maccentral': 3198, 'bright': 3199, 'gay': 3200, 'sex': 3201, 'infoworld': 3202, 'sasser': 3203, 'teenager': 3204, 'rolled': 3205, 'msn': 3206, 'keefe': 3207, 'cancel': 3208, 'shoot': 3209, 'murder': 3210, 'orange': 3211, 'becoming': 3212, 'solar': 3213, 'soviet': 3214, 'longhorn': 3215, 'gadget': 3216, 'emc': 3217, 'grid': 3218, 'arctic': 3219, 'hornet': 3220, 'palm': 3221, 'vulnerability': 3222, 'permission': 3223, 'cloning': 3224, 'ancient': 3225, 'explosion': 3226, 'inclusion': 3227, 'computerworld': 3228, 'disk': 3229, 'gb': 3230, 'gary': 3231, 'religious': 3232, 'pirate': 3233, 'attacker': 3234, 'trick': 3235, 'taipei': 3236, 'psp': 3237, 'beta': 3238, 'tycoon': 3239, 'dave': 3240, 'mountain': 3241, 'experiment': 3242, 'alabama': 3243, 'knee': 3244, 'piracy': 3245, 'leg': 3246, 'violent': 3247, 'eclipse': 3248, 'evolution': 3249, 'vision': 3250, 'lsu': 3251, 'chancellor': 3252, 'ram': 3253, 'lake': 3254, 'phishing': 3255, 'chirac': 3256, 'jacques': 3257, 'pda': 3258, 'submarine': 3259, 'blunkett': 3260, 'memphis': 3261, 'ziff': 3262, 'davis': 3263, 'jihad': 3264, 'assistant': 3265, 'adapter': 3266, 'substance': 3267, 'claimed': 3268, 'killing': 3269, 'aiming': 3270, 'itanium': 3271, 'exploit': 3272, 'jpeg': 3273, 'eating': 3274, 'mph': 3275, 'tiger': 3276, 'burning': 3277, 'domain': 3278, 'relay': 3279, 'demonstration': 3280, 'powell': 3281, 'floor': 3282, 'blu': 3283, 'gen': 3284, 'captured': 3285, 'closest': 3286, 'curt': 3287, 'anderson': 3288, 'crush': 3289, 'columbia': 3290, 'contender': 3291, 'fame': 3292, 'bug': 3293, 'beach': 3294, 'valley': 3295, 'understand': 3296, 'helen': 3297, 'useful': 3298, 'ambition': 3299, 'movement': 3300, 'combat': 3301, 'baby': 3302, 'jamaica': 3303, 'briton': 3304, 'surface': 3305, 'elephant': 3306, 'ron': 3307, 'broken': 3308, 'pentium': 3309, 'czech': 3310, 'creator': 3311, 'shawn': 3312, 'ie': 3313, 'embrace': 3314, 'draft': 3315, 'landmark': 3316, 'ghz': 3317, 'beckham': 3318, 'football': 3319, 'hill': 3320, 'mike': 3321, 'remote': 3322, 'soyuz': 3323, 'chris': 3324, 'cheney': 3325, 'bomb': 3326, 'williams': 3327, 'sure': 3328, 'becomes': 3329, 'unix': 3330, 'blade': 3331, 'km': 3332, 'appearance': 3333, 'astronomer': 3334, 'gov': 3335, 'formally': 3336, 'unable': 3337, 'enable': 3338, 'wing': 3339, 'banning': 3340, 'africa': 3341, 'tennis': 3342, 'championship': 3343, 'capable': 3344, 'tournament': 3345, 'gartner': 3346, 'organic': 3347, 'explain': 3348, 'featuring': 3349, 'alien': 3350, 'pleads': 3351, 'identified': 3352, 'oregon': 3353, 'girl': 3354, 'female': 3355, 'incident': 3356, 'ferrari': 3357, 'jailed': 3358, 'jeremy': 3359, 'scholar': 3360, 'jacksonville': 3361, 'rfid': 3362, 'wildlife': 3363, 'bryant': 3364, 'nba': 3365, 'kobe': 3366, 'starter': 3367, 'kim': 3368, 'sized': 3369, 'doping': 3370, 'couple': 3371, 'kazaa': 3372, 'shared': 3373, 'dolphin': 3374, 'volcano': 3375, 'evacuation': 3376, 'nearby': 3377, 'village': 3378, 'bull': 3379, 'chad': 3380, 'hosting': 3381, 'fish': 3382, 'opteron': 3383, 'killer': 3384, 'whale': 3385, 'allen': 3386, 'peru': 3387, 'blame': 3388, 'spaceshipone': 3389, 'elected': 3390, 'netscape': 3391, 'atomic': 3392, 'hawk': 3393, 'upper': 3394, 'thailand': 3395, 'madrid': 3396, 'epidemic': 3397, 'strained': 3398, 'dan': 3399, 'tropical': 3400, 'scored': 3401, 'victor': 3402, 'interior': 3403, 'squad': 3404, 'ravaged': 3405, 'wayne': 3406, 'crowded': 3407, 'unmanned': 3408, 'skull': 3409, 'xinhua': 3410, 'yard': 3411, 'strain': 3412, 'symbian': 3413, 'bluetooth': 3414, 'brave': 3415, 'nice': 3416, 'tsunami': 3417, 'router': 3418, 'band': 3419, 'techweb': 3420, 'musician': 3421, 'piston': 3422, 'abbott': 3423, 'lycos': 3424, 'bone': 3425, 'survived': 3426, 'theory': 3427, 'yankee': 3428, 'minute': 3429, 'tonight': 3430, 'bloody': 3431, 'ryan': 3432, 'specification': 3433, 'grizzly': 3434, 'iowa': 3435, 'unknown': 3436, 'crown': 3437, 'museum': 3438, 'northeastern': 3439, 'condemned': 3440, 'bus': 3441, 'arrive': 3442, 'viking': 3443, 'republic': 3444, 'anniversary': 3445, 'assassination': 3446, 'sporting': 3447, 'highly': 3448, 'sven': 3449, 'speedway': 3450, 'legend': 3451, 'drew': 3452, 'catcher': 3453, 'bangkok': 3454, 'recorder': 3455, 'dy': 3456, 'sco': 3457, 'utah': 3458, 'weight': 3459, 'rain': 3460, 'skype': 3461, 'angry': 3462, 'hopeful': 3463, 'christian': 3464, 'protester': 3465, 'quake': 3466, 'freedom': 3467, 'sitting': 3468, 'mystery': 3469, 'louisville': 3470, 'swimming': 3471, 'murdered': 3472, 'lunar': 3473, 'seed': 3474, 'spy': 3475, 'exploded': 3476, 'nick': 3477, 'alexander': 3478, 'punishment': 3479, 'seized': 3480, 'sweep': 3481, 'clinton': 3482, 'battleground': 3483, 'arrives': 3484, 'rare': 3485, 'tim': 3486, 'nascar': 3487, 'celebration': 3488, 'flood': 3489, 'dismiss': 3490, 'swept': 3491, 'boycott': 3492, 'raid': 3493, 'humanitarian': 3494, 'activist': 3495, 'convicted': 3496, 'islamabad': 3497, 'pakistani': 3498, 'showdown': 3499, 'pope': 3500, 'jackson': 3501, 'hostage': 3502, 'captive': 3503, 'bigley': 3504, 'beheading': 3505, 'cub': 3506, 'meter': 3507, 'supporter': 3508, 'alex': 3509, 'absence': 3510, 'shoulder': 3511, 'bag': 3512, 'busy': 3513, 'father': 3514, 'wood': 3515, 'steroid': 3516, 'patrick': 3517, 'cyprus': 3518, 'syria': 3519, 'filled': 3520, 'torture': 3521, 'injures': 3522, 'custody': 3523, 'stadium': 3524, 'indie': 3525, 'stripped': 3526, 'devastating': 3527, 'islamic': 3528, 'visit': 3529, 'par': 3530, 'arsenal': 3531, 'insurgent': 3532, 'baghdad': 3533, 'gunman': 3534, 'receiver': 3535, 'aftermath': 3536, 'angel': 3537, 'clinch': 3538, 'inning': 3539, 'scoring': 3540, 'anaheim': 3541, 'athletics': 3542, 'unbeaten': 3543, 'falcon': 3544, 'manchester': 3545, 'phelps': 3546, 'aaron': 3547, 'paralympics': 3548, 'teammate': 3549, 'colt': 3550, 'sri': 3551, 'lanka': 3552, 'defeated': 3553, 'prix': 3554, 'bernie': 3555, 'mauresmo': 3556, 'amelie': 3557, 'uefa': 3558, 'soccer': 3559, 'cink': 3560, 'visiting': 3561, 'barry': 3562, 'quarterback': 3563, 'raider': 3564, 'argentine': 3565, 'cuba': 3566, 'ichiro': 3567, 'mariner': 3568, 'jay': 3569, 'tampa': 3570, 'pitcher': 3571, 'rookie': 3572, 'basketball': 3573, 'pittsburgh': 3574, 'upset': 3575, 'tyler': 3576, 'lakers': 3577, 'baseman': 3578, 'valencia': 3579, 'ian': 3580, 'derek': 3581, 'tottenham': 3582, 'ranger': 3583, 'homer': 3584, 'striker': 3585, 'manning': 3586, 'peyton': 3587, 'marion': 3588, 'newcastle': 3589, 'opener': 3590, 'singh': 3591, 'touchdown': 3592, 'panther': 3593, 'slugger': 3594, 'qualifier': 3595, 'premiership': 3596, 'mets': 3597, 'schilling': 3598, 'diamondback': 3599, 'randy': 3600, 'moss': 3601, 'chelsea': 3602, 'juventus': 3603, 'rome': 3604, 'owen': 3605, 'english': 3606, 'midfielder': 3607, 'wenger': 3608, 'gunner': 3609, 'arsene': 3610, 'wicket': 3611, 'dodger': 3612, 'ticker': 3613, 'brawl': 3614, 'nhl': 3615, 'sharapova': 3616, 'maria': 3617, 'federer': 3618, 'busch': 3619, 'stockholm': 3620, 'defensive': 3621, 'steelers': 3622, 'playoff': 3623, 'rafael': 3624, 'pitched': 3625, 'jordan': 3626, 'wizard': 3627, 'packer': 3628, 'hamm': 3629, 'comeback': 3630, 'pga': 3631, 'golfer': 3632, 'semifinal': 3633, 'cricket': 3634, 'safin': 3635, 'marat': 3636, 'ncaa': 3637, 'defending': 3638, 'lara': 3639, 'bowler': 3640, 'brian': 3641, 'icc': 3642, 'trophy': 3643, 'denver': 3644, 'neal': 3645, 'nugget': 3646, 'matchup': 3647, 'formula': 3648, 'ferguson': 3649, 'agassi': 3650, 'raven': 3651, 'hockey': 3652, 'notre': 3653, 'dame': 3654, 'coaching': 3655, 'qualifying': 3656, 'plate': 3657, 'battled': 3658, 'oriole': 3659, 'astros': 3660, 'roger': 3661, 'clemens': 3662, 'questionable': 3663, 'er': 3664, 'glenn': 3665, 'robinson': 3666, 'garcia': 3667, 'langer': 3668, 'pedro': 3669, 'martinez': 3670, 'preseason': 3671, 'henman': 3672, 'davenport': 3673, 'defender': 3674, 'ml': 3675, 'inter': 3676, 'trainer': 3677, 'haas': 3678, 'schumacher': 3679, 'embassy': 3680, 'postseason': 3681, 'wale': 3682, 'boxing': 3683, 'hitter': 3684, 'seeded': 3685, 'bobby': 3686, 'shutout': 3687, 'jamal': 3688, 'quarterfinal': 3689, 'fenway': 3690, 'marlin': 3691, 'patriot': 3692, 'bronco': 3693, 'graeme': 3694, 'souness': 3695, 'clipper': 3696, 'cavalier': 3697, 'geiberger': 3698, 'skipper': 3699, 'pole': 3700, 'atp': 3701, 'colin': 3702, 'montgomerie': 3703, 'pacer': 3704, 'activated': 3705, 'carter': 3706, 'pennington': 3707, 'charger': 3708, 'renault': 3709, 'rodriguez': 3710, 'cycling': 3711, 'zimbabwe': 3712, 'racism': 3713, 'keith': 3714, 'berth': 3715, 'ortiz': 3716, 'secured': 3717, 'bangladesh': 3718, 'kurt': 3719, 'thierry': 3720, 'ankle': 3721, 'ramirez': 3722, 'retires': 3723, 'auburn': 3724, 'portsmouth': 3725, 'vijay': 3726, 'earnhardt': 3727, 'rotation': 3728, 'jason': 3729, 'rushed': 3730, 'torn': 3731, 'avoided': 3732, 'rugby': 3733, 'mvp': 3734, 'raptor': 3735, 'hewitt': 3736, 'lleyton': 3737, 'withdraw': 3738, 'roddick': 3739, 'ibrahim': 3740, 'injuring': 3741, 'trafford': 3742, 'seahawks': 3743, 'phillies': 3744, 'portland': 3745, 'marriage': 3746, 'arab': 3747, 'sprinter': 3748, 'ole': 3749, 'serena': 3750, 'tape': 3751, 'benitez': 3752, 'greene': 3753, 'hamstring': 3754, 'bcs': 3755, 'rape': 3756, 'jockey': 3757, 'darren': 3758, 'birdie': 3759, 'doubtful': 3760, 'barbados': 3761, 'ukraine': 3762, 'gymnastics': 3763, 'linebacker': 3764, 'belarus': 3765, 'possession': 3766, 'catholic': 3767, 'fighter': 3768, 'sorry': 3769, 'villa': 3770, 'cornerback': 3771, 'dominican': 3772, 'rooney': 3773, 'tension': 3774, 'matt': 3775, 'corruption': 3776, 'kidnapper': 3777, 'kidnapped': 3778, 'abducted': 3779, 'khan': 3780, 'hendrick': 3781, 'returning': 3782, 'relative': 3783, 'videotape': 3784, 'diplomatic': 3785, 'erupted': 3786, 'serb': 3787, 'muslim': 3788, 'massacre': 3789, 'calm': 3790, 'shooting': 3791, 'chen': 3792, 'afghan': 3793, 'riot': 3794, 'bomber': 3795, 'sadr': 3796, 'militiaman': 3797, 'shrine': 3798, 'shi': 3799, 'ite': 3800, 'ali': 3801, 'mosque': 3802, 'cleric': 3803, 'sudan': 3804, 'detained': 3805, 'hassan': 3806, 'palestinian': 3807, 'militant': 3808, 'checkpoint': 3809, 'afghanistan': 3810, 'arafat': 3811, 'yasser': 3812, 'kabul': 3813, 'allawi': 3814, 'saddam': 3815, 'hussein': 3816, 'asylum': 3817, 'chechen': 3818, 'sudanese': 3819, 'darfur': 3820, 'blair': 3821, 'jazeera': 3822, 'wounding': 3823, 'karzai': 3824, 'hamid': 3825, 'compound': 3826, 'bali': 3827, 'jewish': 3828, 'haiti': 3829, 'sharon': 3830, 'typhoon': 3831, 'parliament': 3832, 'pyongyang': 3833, 'warlord': 3834, 'detainee': 3835, 'ariel': 3836, 'fallujah': 3837, 'egyptian': 3838, 'democracy': 3839, 'nepalese': 3840, 'congo': 3841, 'survivor': 3842, 'prisoner': 3843, 'thai': 3844, 'beslan': 3845, 'kashmir': 3846, 'policeman': 3847, 'jerusalem': 3848, 'mosul': 3849, 'anwar': 3850, 'syrian': 3851, 'hamas': 3852, 'dialogue': 3853, 'shiite': 3854, 'muqtada': 3855, 'chechnya': 3856, 'pervez': 3857, 'musharraf': 3858, 'iranian': 3859, 'tehran': 3860, 'manmohan': 3861, 'insurgency': 3862, 'kidnapping': 3863, 'bin': 3864, 'guinea': 3865, 'mbeki': 3866, 'qaida': 3867, 'margaret': 3868, 'milosevic': 3869, 'hague': 3870, 'yugoslav': 3871, 'slobodan': 3872, 'guantanamo': 3873, 'parliamentary': 3874, 'settler': 3875, 'khartoum': 3876, 'guerrilla': 3877, 'separatist': 3878, 'rocked': 3879, 'envoy': 3880, 'falluja': 3881, 'landslide': 3882, 'qaeda': 3883, 'sunni': 3884, 'ambassador': 3885, 'peacekeeper': 3886, 'kofi': 3887, 'annan': 3888, 'stronghold': 3889, 'nairobi': 3890, 'ghraib': 3891, 'ethnic': 3892, 'deserter': 3893, 'foreigner': 3894, 'cambodia': 3895, 'norodom': 3896, 'abuja': 3897, 'nuke': 3898, 'lebanese': 3899, 'lebanon': 3900, 'convoy': 3901, 'shaukat': 3902, 'aziz': 3903, 'nato': 3904, 'mortar': 3905, 'pullout': 3906, 'taliban': 3907, 'fischer': 3908, 'deadliest': 3909, 'enrichment': 3910, 'ukrainian': 3911, 'samarra': 3912}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.news_vocab._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.category_vocab._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._max_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_for_fine_tune(embedding_dim, hidden_dim, output_dim, num_layers, bidirectional, pretrained_embeddings, emb_freeze, batch_size):\n",
    "    set_seed_everywhere(args.seed, args.cuda, args.mps)\n",
    "        \n",
    "    args.batch_size = batch_size\n",
    "    classifier = NewsClassifier(embedding_dim=embedding_dim,          # e.g, 100\n",
    "                                num_embeddings=len(vectorizer.news_vocab),  # e.g., 3409\n",
    "                                output_dim=output_dim,\n",
    "                                hidden_dim=hidden_dim,\n",
    "                                num_layers=num_layers,\n",
    "                                bidirectional=bidirectional,\n",
    "                                pretrained_embeddings=pretrained_embeddings,\n",
    "                                emb_freeze=emb_freeze)\n",
    "    \n",
    "    if pretrained_embeddings is None:\n",
    "        is_pretrained_embeddings = False\n",
    "    else:\n",
    "        is_pretrained_embeddings = True\n",
    "        \n",
    "    classifier = classifier.to(args.device)\n",
    "    dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "        \n",
    "    loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "    train_state = make_train_state(args)\n",
    "\n",
    "    epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "    dataset.set_split('train')\n",
    "    train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "    dataset.set_split('val')\n",
    "    val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "    try:\n",
    "        for epoch_index in range(args.num_epochs):\n",
    "            train_state['epoch_index'] = epoch_index\n",
    "\n",
    "            # Iterate over training dataset\n",
    "\n",
    "            # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "\n",
    "            dataset.set_split('train')\n",
    "            batch_generator = generate_batches(dataset, \n",
    "                                            batch_size=args.batch_size, \n",
    "                                            device=args.device)\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            classifier.train()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "                # the training routine is these 5 steps:\n",
    "\n",
    "                # --------------------------------------\n",
    "                # step 1. zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # step 2. compute the output\n",
    "                y_pred = classifier(batch_dict['x_data']) # (batch, seq_len) -> (batch, num_classes)\n",
    "\n",
    "                # step 3. compute the loss\n",
    "                loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "                loss_t = loss.item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # step 4. use loss to produce gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # step 5. use optimizer to take gradient step\n",
    "                optimizer.step()\n",
    "                # -----------------------------------------\n",
    "                # compute the accuracy\n",
    "                acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "                # update bar\n",
    "                train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                    epoch=epoch_index)\n",
    "                train_bar.update()\n",
    "\n",
    "            train_state['train_loss'].append(running_loss)\n",
    "            train_state['train_acc'].append(running_acc)\n",
    "\n",
    "            # Iterate over val dataset\n",
    "\n",
    "            # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "            dataset.set_split('val')\n",
    "            batch_generator = generate_batches(dataset, \n",
    "                                            batch_size=args.batch_size, \n",
    "                                            device=args.device)\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "            classifier.eval()\n",
    "\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "                # compute the output\n",
    "                y_pred =  classifier(batch_dict['x_data'])\n",
    "\n",
    "                # step 3. compute the loss\n",
    "                loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "                loss_t = loss.item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # compute the accuracy\n",
    "                acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "                val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                epoch=epoch_index)\n",
    "                val_bar.update()\n",
    "\n",
    "            train_state['val_loss'].append(running_loss)\n",
    "            train_state['val_acc'].append(running_acc)\n",
    "\n",
    "            train_state = update_train_state(args=args, model=classifier,\n",
    "                                            train_state=train_state)\n",
    "\n",
    "            scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "            if train_state['stop_early']:\n",
    "                break\n",
    "\n",
    "            train_bar.n = 0\n",
    "            val_bar.n = 0\n",
    "            epoch_bar.update()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Exiting loop\")\n",
    "    \n",
    "    acc = train_state['train_acc']\n",
    "    val_acc = train_state['val_acc']\n",
    "    loss = train_state['train_loss']\n",
    "    val_loss = train_state['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    # compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "    classifier.load_state_dict(torch.load(train_state['model_filename'])) # load the best model\n",
    "\n",
    "    classifier = classifier.to(args.device)\n",
    "    dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "    dataset.set_split('test')\n",
    "    batch_generator = generate_batches(dataset, \n",
    "                                    batch_size=args.batch_size, \n",
    "                                    device=args.device)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    classifier.eval()\n",
    "\n",
    "    y_pred_list = []         # store predicted values for confusion matrix\n",
    "    y_category_list = []  # ground truth value\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # compute the output\n",
    "        y_pred =  classifier(batch_dict['x_data'])\n",
    "        \n",
    "        # store predicted values and ground truth values for calculating confusion matrix\n",
    "        y_pred_list.extend(y_pred.max(dim=1)[1].cpu().numpy())\n",
    "        y_category_list.extend(batch_dict['y_target'].cpu().numpy())\n",
    "        \n",
    "        # compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        # compute the accuracy\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "    train_state['test_loss'] = running_loss\n",
    "    train_state['test_acc'] = running_acc\n",
    "    \n",
    "    return [embedding_dim, hidden_dim, num_layers, bidirectional, is_pretrained_embeddings, emb_freeze, batch_size, train_state['val_loss'][-1], train_state['val_acc'][-1], train_state['test_loss'], train_state['test_acc']]\n",
    "\n",
    "def simple_grid_search(embedding_dim_values, hidden_dim_values, num_layers_values, bidirectional_values, batch_size_values, pretrained_embeddings_values, emb_freeze_values):    \n",
    "    output_dim_value = 4\n",
    "    \n",
    "    print(\"embedding_dim_values:\", embedding_dim_values)\n",
    "    print(\"hidden_dim_values:\", hidden_dim_values)\n",
    "    print(\"batch_size_values: \", batch_size_values)\n",
    "    print(\"num_layers_values: \", num_layers_values)\n",
    "    print(\"bidirectional_values: \", bidirectional_values)\n",
    "    \n",
    "    \n",
    "    best_by_val_loss = []\n",
    "    best_by_val_acc = []\n",
    "    best_by_test_loss = []\n",
    "    best_by_test_acc = []\n",
    "    \n",
    "    log_path = 'Log_LSTM_News_Category.txt'\n",
    "    if os.path.exists(log_path):\n",
    "        os.remove(log_path)\n",
    "        \n",
    "    with open(log_path, 'a') as log:\n",
    "        for pretrained_embeddings_value in pretrained_embeddings_values:\n",
    "            if pretrained_embeddings_value is not None:\n",
    "                print(\"------------Use Pretrain------------\")\n",
    "                log.write(\"------------Use Pretrain------------\\n\")\n",
    "                for emb_freeze_value in emb_freeze_values:\n",
    "                    for bidirectional_value in bidirectional_values:\n",
    "                        for hidden_dim_value in hidden_dim_values:\n",
    "                            for num_layers_value in num_layers_values:\n",
    "                                for batch_size_value in batch_size_values:\n",
    "                                    print(f\"------args-----\\nbidirectional: {bidirectional_value} | hidden_dim: {hidden_dim_value} | num_layers: {num_layers_value} | batch_size: {batch_size_value} | emb_freeze: {emb_freeze_value}\")\n",
    "                                    log.write(f\"------args-----\\nbidirectional: {bidirectional_value} | hidden_dim: {hidden_dim_value} | num_layers: {num_layers_value} | batch_size: {batch_size_value} | emb_freeze: {emb_freeze_value}\\n\")\n",
    "                                    start_time = time.time()\n",
    "                                    result = train_for_fine_tune(100, hidden_dim_value, output_dim_value, num_layers_value, bidirectional_value, pretrained_embeddings_value, emb_freeze_value, batch_size_value)\n",
    "                                    end_time = time.time()\n",
    "                                    torch.cuda.empty_cache()\n",
    "                                    if best_by_val_loss == [] or best_by_val_loss[7] > result[7]:\n",
    "                                        best_by_val_loss = result\n",
    "                                    if best_by_val_acc == [] or best_by_val_acc[8] < result[8]:\n",
    "                                        best_by_val_acc = result\n",
    "                                    if best_by_test_loss == [] or best_by_test_loss[9] > result[9]:\n",
    "                                        best_by_test_loss = result\n",
    "                                    if best_by_test_acc == [] or best_by_test_acc[10] < result[10]:\n",
    "                                        best_by_test_acc = result\n",
    "                                    elapsed_time = end_time - start_time\n",
    "                                    print(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\")\n",
    "                                    print(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\")\n",
    "                                    log.write(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\\n\")\n",
    "                                    log.write(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\\n\")\n",
    "            else:\n",
    "                print(\"------Not Use Pretrain------\")\n",
    "                log.write(\"------------Not Use Pretrain------------\\n\")\n",
    "                for bidirectional_value in bidirectional_values:\n",
    "                    for embedding_dim_value in embedding_dim_values:\n",
    "                        for hidden_dim_value in hidden_dim_values:\n",
    "                            for num_layers_value in num_layers_values:\n",
    "                                for batch_size_value in batch_size_values:\n",
    "                                    print(f\"------args-----\\nbidirectional: {bidirectional_value} | embedding_dim: {embedding_dim_value} | hidden_dim: {hidden_dim_value} | num_layers: {num_layers_value} | batch_size: {batch_size_value}\")\n",
    "                                    log.write(f\"------args-----\\nbidirectional: {bidirectional_value} | embedding_dim: {embedding_dim_value} | hidden_dim: {hidden_dim_value} | num_layers: {num_layers_value} | batch_size: {batch_size_value}\\n\")\n",
    "                                    start_time = time.time()\n",
    "                                    result = train_for_fine_tune(embedding_dim_value, hidden_dim_value, output_dim_value, num_layers_value, bidirectional_value, pretrained_embeddings_value, True, batch_size_value)\n",
    "                                    end_time = time.time()\n",
    "                                    torch.cuda.empty_cache()\n",
    "                                    if best_by_val_loss == [] or best_by_val_loss[7] > result[7]:\n",
    "                                        best_by_val_loss = result\n",
    "                                    if best_by_val_acc == [] or best_by_val_acc[8] < result[8]:\n",
    "                                        best_by_val_acc = result\n",
    "                                    if best_by_test_loss == [] or best_by_test_loss[9] > result[9]:\n",
    "                                        best_by_test_loss = result\n",
    "                                    if best_by_test_acc == [] or best_by_test_acc[10] < result[10]:\n",
    "                                        best_by_test_acc = result\n",
    "                                    elapsed_time = end_time - start_time\n",
    "                                    print(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\")\n",
    "                                    print(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\")\n",
    "                                    log.write(f\"------perf.-----\\nval_loss: {result[7]} | val_acc: {result[8]}\\ntest_loss: {result[9]} | test_acc: {result[10]}\\n\")\n",
    "                                    log.write(f\"took {elapsed_time:.2f} seconds.\\nbest by va_loss: {best_by_val_loss[:7]} | best by va_acc: {best_by_val_acc[:7]}\\nbest by te_loss: {best_by_test_loss[:7]} | best by te_acc: {best_by_test_acc[:7]}\\n\\n\")\n",
    "\n",
    "        print(\"--------------Best Val Loss--------------\")\n",
    "        print(f\"embedding_dim: {best_by_val_loss[0]}\\nhidden_dim: {best_by_val_loss[1]}\\nnum_layers: {best_by_val_loss[2]}\\nbidirectional: {best_by_val_loss[3]}\\nis_pretrained_embeddings: {best_by_val_loss[4]}\\nemb_freeze: {best_by_val_loss[5]}\\nbatch_sizeï¼š{best_by_val_loss[6]}\\n\")\n",
    "        \n",
    "        print(\"--------------Best Val Acc--------------\")\n",
    "        print(f\"embedding_dim: {best_by_val_acc[0]}\\nhidden_dim: {best_by_val_acc[1]}\\nnum_layers: {best_by_val_acc[2]}\\nbidirectional: {best_by_val_acc[3]}\\nis_pretrained_embeddings: {best_by_val_acc[4]}\\nemb_freeze: {best_by_val_acc[5]}\\nbatch_sizeï¼š{best_by_val_acc[6]}\\n\")\n",
    "        \n",
    "        print(\"--------------Best Test Loss--------------\")\n",
    "        print(f\"embedding_dim: {best_by_test_loss[0]}\\nhidden_dim: {best_by_test_loss[1]}\\nnum_layers: {best_by_test_loss[2]}\\nbidirectional: {best_by_test_loss[3]}\\nis_pretrained_embeddings: {best_by_test_loss[4]}\\nemb_freeze: {best_by_test_loss[5]}\\nbatch_sizeï¼š{best_by_test_loss[6]}\\n\")\n",
    "        \n",
    "        print(\"--------------Best Test Acc--------------\")\n",
    "        print(f\"embedding_dim: {best_by_test_acc[0]}\\nhidden_dim: {best_by_test_acc[1]}\\nnum_layers: {best_by_test_acc[2]}\\nbidirectional: {best_by_test_acc[3]}\\nis_pretrained_embeddings: {best_by_test_acc[4]}\\nemb_freeze: {best_by_test_acc[5]}\\nbatch_sizeï¼š{best_by_test_acc[6]}\\n\")\n",
    "\n",
    "        log.write(\"--------------Best Val Loss--------------\\n\")\n",
    "        log.write(f\"embedding_dim: {best_by_val_loss[0]}\\nhidden_dim: {best_by_val_loss[1]}\\nnum_layers: {best_by_val_loss[2]}\\nbidirectional: {best_by_val_loss[3]}\\nis_pretrained_embeddings: {best_by_val_loss[4]}\\nemb_freeze: {best_by_val_loss[5]}\\nbatch_sizeï¼š{best_by_val_loss[6]}\\n\\n\")\n",
    "        \n",
    "        log.write(\"--------------Best Val Acc--------------\\n\")\n",
    "        log.write(f\"embedding_dim: {best_by_val_acc[0]}\\nhidden_dim: {best_by_val_acc[1]}\\nnum_layers: {best_by_val_acc[2]}\\nbidirectional: {best_by_val_acc[3]}\\nis_pretrained_embeddings: {best_by_val_acc[4]}\\nemb_freeze: {best_by_val_acc[5]}\\nbatch_sizeï¼š{best_by_val_acc[6]}\\n\\n\")\n",
    "        \n",
    "        log.write(\"--------------Best Test Loss--------------\\n\")\n",
    "        log.write(f\"embedding_dim: {best_by_test_loss[0]}\\nhidden_dim: {best_by_test_loss[1]}\\nnum_layers: {best_by_test_loss[2]}\\nbidirectional: {best_by_test_loss[3]}\\nis_pretrained_embeddings: {best_by_test_loss[4]}\\nemb_freeze: {best_by_test_loss[5]}\\nbatch_sizeï¼š{best_by_test_loss[6]}\\n\\n\")\n",
    "        \n",
    "        log.write(\"--------------Best Test Acc--------------\\n\")\n",
    "        log.write(f\"embedding_dim: {best_by_test_acc[0]}\\nhidden_dim: {best_by_test_acc[1]}\\nnum_layers: {best_by_test_acc[2]}\\nbidirectional: {best_by_test_acc[3]}\\nis_pretrained_embeddings: {best_by_test_acc[4]}\\nemb_freeze: {best_by_test_acc[5]}\\nbatch_sizeï¼š{best_by_test_acc[6]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim_values = [i for i in range(64, 161, 32)]\n",
    "hidden_dim_values = [i for i in range(64, 513, 64)]\n",
    "batch_size_values = [i for i in range(64, 193, 32)]\n",
    "num_layers_values = [1, 2, 3]\n",
    "bidirectional_values = [True]\n",
    "pretrained_embeddings_values = [embeddings]\n",
    "emb_freeze_values = [False]\n",
    "\n",
    "run = False\n",
    "if run:\n",
    "    simple_grid_search(embedding_dim_values, hidden_dim_values, num_layers_values, bidirectional_values, batch_size_values, pretrained_embeddings_values, emb_freeze_values)\n",
    "\n",
    "    args.embedding_dim=100\n",
    "    args.hidden_dim=384\n",
    "    args.num_layers=3\n",
    "    args.bidirectional = True\n",
    "    args.use_glove=True\n",
    "    args.emb_freeze=False\n",
    "    args.batch_size=64\n",
    "\n",
    "    if args.use_glove:\n",
    "        words = vectorizer.news_vocab._token_to_idx.keys()  # 3409 unique words\n",
    "        embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath,     # embeddings: (3409, 100)\n",
    "                                        words=words)\n",
    "        print(\"Using pre-trained embeddings\")\n",
    "    else:\n",
    "        print(\"Not using pre-trained embeddings\")\n",
    "        embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NewsClassifier(embedding_dim=args.embedding_dim,          # e.g, 100\n",
    "                            num_embeddings=len(vectorizer.news_vocab),  # e.g., 3409\n",
    "                            output_dim=args.output_dim,\n",
    "                            hidden_dim=args.hidden_dim,\n",
    "                            num_layers=args.num_layers,\n",
    "                            bidirectional=args.bidirectional,\n",
    "                            pretrained_embeddings=embeddings,\n",
    "                            emb_freeze=args.emb_freeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f989a5ecac45f9b6be55be4da180d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a38428dc4d43d98883185883aa2edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1766dceac894ca4b6874c34ba1310ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------\n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(batch_dict['x_data']) # (batch, seq_len) -> (batch, num_classes)\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                                  epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "            # compute the output\n",
    "            y_pred =  classifier(batch_dict['x_data'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename'])) # load the best model\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_category_list = []  # ground truth value\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_data'])\n",
    "    \n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_list.extend(y_pred.max(dim=1)[1].cpu().numpy())\n",
    "    y_category_list.extend(batch_dict['y_target'].cpu().numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3735694626444264;\n",
      "Test Accuracy: 88.59649122807018\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business', 'Sci/Tech', 'Sports', 'World']\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "for i in range(len(dataset._vectorizer.category_vocab)):\n",
    "    classes.append(dataset._vectorizer.category_vocab.lookup_index(i))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True       Business  Sci/Tech  Sports  World\n",
      "Predicted                                   \n",
      "Business        378        35       7     30\n",
      "Sci/Tech         49       406       4     16\n",
      "Sports            7         6     433     12\n",
      "World            22        10      10    399\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_category_list, y_pred_list)\n",
    "cm_df = pd.DataFrame(cm.T, index=classes, columns=classes)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       456\n",
      "           1       0.85      0.89      0.87       457\n",
      "           2       0.95      0.95      0.95       454\n",
      "           3       0.90      0.87      0.89       457\n",
      "\n",
      "    accuracy                           0.89      1824\n",
      "   macro avg       0.89      0.89      0.89      1824\n",
      "weighted avg       0.89      0.89      0.89      1824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_category_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the reviews\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(title, classifier, vectorizer, max_length):\n",
    "    \"\"\"Predict a News category for a new title\n",
    "    \n",
    "    Args:\n",
    "        title (str): a raw title string\n",
    "        classifier (NewsClassifier): an instance of the trained classifier\n",
    "        vectorizer (NewsVectorizer): the corresponding vectorizer\n",
    "        max_length (int): the max sequence length\n",
    "            Note: CNNs are sensitive to the input data tensor size. \n",
    "                  This ensures to keep it the same size as the training data\n",
    "    \"\"\"\n",
    "    title = preprocess_text(title)\n",
    "    vectorized_title = \\\n",
    "        torch.tensor(vectorizer.vectorize(title, vector_length=max_length))\n",
    "    result = classifier(vectorized_title.unsqueeze(0))\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    predicted_category = vectorizer.category_vocab.lookup_index(indices.item())\n",
    "\n",
    "    return {'category': predicted_category, \n",
    "            'probability': probability_values.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples():\n",
    "    samples = {}\n",
    "    for cat in dataset.val_df.category.unique():\n",
    "        samples[cat] = dataset.val_df.text[dataset.val_df.category==cat].tolist()[:5]\n",
    "    return samples\n",
    "\n",
    "val_samples = get_samples() # first 5 titles of each category from validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Category: Business\n",
      "==============================\n",
      "Prediction: Business (p=3.72)\n",
      "\t + Sample: sony group buy group buy mgm buy mgm consortium mgm consortium led consortium led sony led sony corp sony corp agreed corp agreed principle agreed principle acquire principle acquire famed acquire famed hollywood famed hollywood studio hollywood studio metro studio metro goldwyn metro goldwyn mayer goldwyn mayer inc mayer inc nearly inc nearly billion nearly billion mgm billion mgm said mgm said late said late yesterday\n",
      "Prediction: Business (p=3.68)\n",
      "\t + Sample: pilgrim baxter founder baxter founder pay founder pay washington pay washington two washington two founder two founder pilgrim founder pilgrim baxter pilgrim baxter mutual baxter mutual fund mutual fund family fund family agreed family agreed pay agreed pay million pay million settle million settle regulator settle regulator charge regulator charge improper charge improper trading improper trading benefit trading benefit friend benefit friend expense friend expense longer expense longer term longer term shareholder term shareholder authority shareholder authority said authority said yesterday\n",
      "Prediction: Sci/Tech (p=1.57)\n",
      "\t + Sample: loss making smart making smart doomed smart doomed head doomed head smart head smart car smart car denies car denies rumour denies rumour loss rumour loss making loss making firm making firm may firm may sold may sold even sold even closed even closed parent closed parent group parent group daimlerchrysler\n",
      "Prediction: Business (p=3.75)\n",
      "\t + Sample: united seek cut seek cut labor cut labor elsewhere labor elsewhere united elsewhere united airline united airline say airline say need say need even need even labor even labor cut labor cut anticipated cut anticipated get anticipated get bankruptcy get bankruptcy united bankruptcy united told united told bankruptcy told bankruptcy court bankruptcy court judge court judge chicago judge chicago today chicago today intends today intends start intends start talk start talk union talk union next union next month next month new month new round new round cost round cost saving\n",
      "Prediction: Business (p=4.09)\n",
      "\t + Sample: oil price jump price jump u jump u report u report lower report lower supply lower supply oil supply oil future oil future price future price bolted price bolted percent bolted percent higher percent higher yesterday higher yesterday climbing yesterday climbing barrel climbing barrel u barrel u government u government data government data showed data showed slight showed slight decline slight decline crude decline crude heating crude heating oil heating oil supply\n",
      "------------------------------\n",
      "\n",
      "True Category: Sci/Tech\n",
      "==============================\n",
      "Prediction: Business (p=2.63)\n",
      "\t + Sample: china blasted piracy blasted piracy lax piracy lax enforcement lax enforcement intellectual enforcement intellectual property intellectual property law property law hurt law hurt business hurt business investment business investment group investment group charge\n",
      "Prediction: Sci/Tech (p=3.54)\n",
      "\t + Sample: company put loyalty put loyalty test loyalty test cisco test cisco ibm cisco ibm microsoft ibm microsoft sap microsoft sap loyal sap loyal customer loyal customer according customer according report according report released report released today released today fact today fact biggest fact biggest successful biggest successful vendor\n",
      "Prediction: Business (p=3.52)\n",
      "\t + Sample: mobile margin fall margin fall telstra fall telstra telstra telstra telstra chief telstra chief financial chief financial officer financial officer john officer john stanhope john stanhope admitted stanhope admitted telstra admitted telstra margin telstra margin billion margin billion year billion year mobile year mobile phone mobile phone business phone business shrink business shrink year shrink year face year face increased face increased price increased price competition price competition growing competition growing cost growing cost acquiring cost acquiring new acquiring new customer\n",
      "Prediction: Business (p=2.82)\n",
      "\t + Sample: peoplesoft ibm strike ibm strike middleware strike middleware alliance middleware alliance peoplesoft alliance peoplesoft inc peoplesoft inc deepening inc deepening tie deepening tie ibm tie ibm corp ibm corp announcing corp announcing tuesday announcing tuesday sale tuesday sale development sale development partnership development partnership called partnership called significant called significant enterprise significant enterprise application enterprise application alliance application alliance company alliance company history\n",
      "Prediction: Sci/Tech (p=4.43)\n",
      "\t + Sample: apple sue web sue web leak web leak advance leak advance product advance product reuters product reuters reuters reuters reuters apple reuters apple computer apple computer inc computer inc suing inc suing anonymous suing anonymous people anonymous people leaked people leaked detail leaked detail new detail new product new product posting product posting information posting information internet information internet court internet court document court document showed document showed friday\n",
      "------------------------------\n",
      "\n",
      "True Category: Sports\n",
      "==============================\n",
      "Prediction: Sports (p=3.68)\n",
      "\t + Sample: mcnair injures sternum injures sternum jaguar sternum jaguar ap jaguar ap ap ap ap steve ap steve mcnair steve mcnair nfl mcnair nfl co nfl co mvp co mvp bruised mvp bruised sternum bruised sternum sunday sternum sunday admitted sunday admitted hospital admitted hospital night\n",
      "Prediction: Sports (p=4.58)\n",
      "\t + Sample: urso suspended fa suspended fa football fa football association football association handed association handed referee handed referee andy referee andy urso andy urso day urso day suspension day suspension following suspension following failure following failure give failure give barry give barry ferguson barry ferguson marching ferguson marching order marching order southampton order southampton august\n",
      "Prediction: Sports (p=3.77)\n",
      "\t + Sample: greek prosecutor expected prosecutor expected rule expected rule olympic rule olympic pair olympic pair greek pair greek prosecutor greek prosecutor expected prosecutor expected wednesday expected wednesday announce wednesday announce result announce result investigation result investigation whether investigation whether country whether country top country top sprinter top sprinter faked sprinter faked road faked road accident road accident doping accident doping scandal doping scandal rocked scandal rocked greece rocked greece plagued greece plagued athens plagued athens olympics\n",
      "Prediction: Sports (p=4.02)\n",
      "\t + Sample: familiar brave tune brave tune postseason tune postseason dirge postseason dirge end dirge end long end long season long season grueling season grueling playoff grueling playoff series playoff series manager series manager often manager often point often point weary point weary optimist weary optimist toward optimist toward hill toward hill place hill place bullpen place bullpen high bullpen high alert\n",
      "Prediction: Sports (p=3.56)\n",
      "\t + Sample: australia give neighbour give neighbour mercy neighbour mercy australia mercy australia wrapped australia wrapped win wrapped win series win series beating series beating new beating new zealand new zealand run zealand run fifth run fifth day fifth day second day second final second final cricket final cricket test cricket test tuesday\n",
      "------------------------------\n",
      "\n",
      "True Category: World\n",
      "==============================\n",
      "Prediction: World (p=4.66)\n",
      "\t + Sample: austria extradite turkish extradite turkish underworld turkish underworld figure underworld figure vienna figure vienna reuters vienna reuters convicted reuters convicted turkish convicted turkish underworld turkish underworld bos underworld bos alaattin bos alaattin cakici alaattin cakici sought cakici sought charge sought charge corruption charge corruption extortion corruption extortion extradited extortion extradited austria extradited austria turkey austria turkey district turkey district court district court ruled court ruled monday\n",
      "Prediction: World (p=3.09)\n",
      "\t + Sample: french court rule court rule sikh rule sikh boy sikh boy french boy french court french court rule court rule whether rule whether new whether new law new law ban law ban three ban three sikh three sikh boy sikh boy wearing boy wearing turban wearing turban school\n",
      "Prediction: World (p=0.68)\n",
      "\t + Sample: holiday stamp issued stamp issued oct issued oct ap oct ap ap ap ap holiday ap holiday postage holiday postage stamp postage stamp celebrating stamp celebrating christmas celebrating christmas hanukkah christmas hanukkah kwanzaa hanukkah kwanzaa issued kwanzaa issued next issued next month next month u month u postal u postal service postal service announced service announced monday\n",
      "Prediction: World (p=6.06)\n",
      "\t + Sample: protester harry israel harry israel parliament israel parliament gaza parliament gaza vote gaza vote jerusalem vote jerusalem reuters jerusalem reuters thousand reuters thousand rightist thousand rightist israeli rightist israeli accused israeli accused prime accused prime minister prime minister ariel minister ariel sharon ariel sharon treason sharon treason tuesday treason tuesday parliament tuesday parliament looked parliament looked set looked set approve set approve first approve first pullout first pullout settler pullout settler occupied settler occupied land occupied land palestinian land palestinian want palestinian want part want part future part future state\n",
      "Prediction: World (p=4.85)\n",
      "\t + Sample: plane crash venezuelan crash venezuelan mountain venezuelan mountain killing mountain killing military killing military plane military plane crashed plane crashed mountain crashed mountain central mountain central venezuela central venezuela killing venezuela killing people killing people including people including five including five child five child air child air force air force rescue force rescue team rescue team said team said statement\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#title = input(\"Enter a news title to classify: \")\n",
    "classifier = classifier.to(\"cpu\")\n",
    "\n",
    "for truth, sample_group in val_samples.items():\n",
    "    print(f\"True Category: {truth}\")\n",
    "    print(\"=\"*30)\n",
    "    for sample in sample_group:\n",
    "        prediction = predict_category(sample, classifier, \n",
    "                                      vectorizer, dataset._max_seq_length)\n",
    "        print(\"Prediction: {} (p={:0.2f})\".format(prediction['category'],\n",
    "                                                  prediction['probability']))\n",
    "        print(\"\\t + Sample: {}\".format(sample))\n",
    "    print(\"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": "5",
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
